{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89762a9a",
   "metadata": {},
   "source": [
    "# NLTK Complete Guide - Section 2: Text Processing Fundamentals\n",
    "\n",
    "This notebook covers:\n",
    "- Working with Text\n",
    "- NLTK Text Object\n",
    "- Loading Sample Texts\n",
    "- Text Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42379cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.text import Text\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dfad84",
   "metadata": {},
   "source": [
    "## 2.1 Working with Text\n",
    "\n",
    "Basic string operations on text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b73cbd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Natural Language Processing (NLP) is a field of artificial intelligence \n",
      "that gives computers the ability to understand text and spoken words.\n",
      "\n",
      "Length: 142 characters\n",
      "Word count (simple): 21\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Natural Language Processing (NLP) is a field of artificial intelligence \n",
    "that gives computers the ability to understand text and spoken words.\"\"\"\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(text)\n",
    "print(f\"\\nLength: {len(text)} characters\")\n",
    "print(f\"Word count (simple): {len(text.split())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7615cf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase:\n",
      "NATURAL LANGUAGE PROCESSING (NLP) IS A FIELD OF ARTIFICIAL INTELLIGENCE \n",
      "THAT GIVES COMPUTERS THE ABILITY TO UNDERSTAND TEXT AND SPOKEN WORDS.\n",
      "\n",
      "Lowercase:\n",
      "natural language processing (nlp) is a field of artificial intelligence \n",
      "that gives computers the ability to understand text and spoken words.\n"
     ]
    }
   ],
   "source": [
    "# Case transformations\n",
    "print(\"Uppercase:\")\n",
    "print(text.upper())\n",
    "\n",
    "print(\"\\nLowercase:\")\n",
    "print(text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d9dbe",
   "metadata": {},
   "source": [
    "## 2.2 NLTK Text Object\n",
    "\n",
    "The `Text` class provides useful methods for text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e0298b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 51\n",
      "Unique tokens: 37\n"
     ]
    }
   ],
   "source": [
    "# Create NLTK Text object\n",
    "sample_text = \"\"\"Natural Language Processing enables computers to understand human language.\n",
    "Language processing involves many complex tasks. Processing text requires \n",
    "understanding grammar and semantics. Computers can now process language effectively.\n",
    "Natural language understanding is a key challenge in artificial intelligence.\n",
    "Language models have revolutionized natural language processing.\"\"\"\n",
    "\n",
    "tokens = word_tokenize(sample_text)\n",
    "nltk_text = Text(tokens)\n",
    "\n",
    "print(f\"Total tokens: {len(nltk_text)}\")\n",
    "print(f\"Unique tokens: {len(set(nltk_text))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ac97d",
   "metadata": {},
   "source": [
    "### Concordance\n",
    "Shows a word in its context (surrounding words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f7e41df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance for 'language':\n",
      "Displaying 5 of 7 matches:\n",
      "                  Natural Language Processing enables comput\n",
      "uters to understand human language . Language processing inv\n",
      "derstand human language . Language processing involves many \n",
      "Computers can now process language effectively . Natural lan\n",
      "age effectively . Natural language understanding is a key ch\n"
     ]
    }
   ],
   "source": [
    "# Concordance - shows word in context\n",
    "print(\"Concordance for 'language':\")\n",
    "nltk_text.concordance(\"language\", width=60, lines=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29e9adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance for 'processing':\n",
      "Displaying 4 of 4 matches:\n",
      "        Natural Language Processing enables computers to und\n",
      "uman language . Language processing involves many complex ta\n",
      "ves many complex tasks . Processing text requires understand\n",
      "ionized natural language processing .\n"
     ]
    }
   ],
   "source": [
    "print(\"Concordance for 'processing':\")\n",
    "nltk_text.concordance(\"processing\", width=60, lines=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bcba32",
   "metadata": {},
   "source": [
    "### Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "391857b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'language' appears: 4 times\n",
      "'processing' appears: 2 times\n",
      "'Natural' appears: 2 times\n"
     ]
    }
   ],
   "source": [
    "# Count specific words\n",
    "print(f\"'language' appears: {nltk_text.count('language')} times\")\n",
    "print(f\"'processing' appears: {nltk_text.count('processing')} times\")\n",
    "print(f\"'Natural' appears: {nltk_text.count('Natural')} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0c038",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd255c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 most common words:\n",
      "------------------------------\n",
      ".                    6\n",
      "language             4\n",
      "Language             3\n",
      "Natural              2\n",
      "Processing           2\n",
      "processing           2\n",
      "understanding        2\n",
      "enables              1\n",
      "computers            1\n",
      "to                   1\n",
      "understand           1\n",
      "human                1\n",
      "involves             1\n",
      "many                 1\n",
      "complex              1\n"
     ]
    }
   ],
   "source": [
    "# Get vocabulary with frequencies\n",
    "vocab = nltk_text.vocab()\n",
    "\n",
    "print(\"Top 15 most common words:\")\n",
    "print(\"-\" * 30)\n",
    "for word, count in vocab.most_common(15):\n",
    "    print(f\"{word:<20} {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81398c4b",
   "metadata": {},
   "source": [
    "### Finding Similar Words\n",
    "Words that appear in similar contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64ef124c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'cat':\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "# Create a larger text for better similar word detection\n",
    "larger_text = \"\"\"The cat sat on the mat. The dog sat on the rug. \n",
    "The cat chased the mouse. The dog chased the cat.\n",
    "A happy cat is a good cat. A happy dog is a good dog.\n",
    "The cat sleeps on the bed. The dog sleeps on the floor.\n",
    "My cat likes fish. My dog likes meat.\"\"\"\n",
    "\n",
    "tokens_large = word_tokenize(larger_text.lower())\n",
    "text_large = Text(tokens_large)\n",
    "\n",
    "print(\"Words similar to 'cat':\")\n",
    "text_large.similar(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a858d1",
   "metadata": {},
   "source": [
    "### How `similar()` Works\n",
    "\n",
    "The `similar()` function finds words that share **the same surrounding context** (words before and after).\n",
    "\n",
    "**Algorithm:**\n",
    "1. For each word, record its context: `(word_before, word_after)`\n",
    "2. Build an index: `context â†’ [words that appear in this context]`\n",
    "3. For a query word, find all its contexts, then find other words sharing those contexts\n",
    "\n",
    "**Limitations:**\n",
    "- Needs **repeated patterns** - words must appear multiple times in similar positions\n",
    "- **Small text** = poor results (not enough context examples)\n",
    "- **Unique contexts** = no similar words found\n",
    "- **Sentence boundaries** break context chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "741cd105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "GOOD CASE: Many repeated patterns\n",
      "==================================================\n",
      "Tokens: 114, Unique: 22\n",
      "\n",
      "Words similar to 'cat':\n",
      "dog rabbit\n",
      "\n",
      "Words similar to 'dog':\n",
      "cat rabbit\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# GOOD CASE: Repeated patterns, shared contexts\n",
    "# ============================================\n",
    "good_text = \"\"\"\n",
    "The cat sat on the mat. The dog sat on the mat. The rabbit sat on the mat.\n",
    "The cat ran to the park. The dog ran to the park. The rabbit ran to the park.\n",
    "The cat ate the food. The dog ate the food. The rabbit ate the food.\n",
    "The cat slept on the bed. The dog slept on the bed. The rabbit slept on the bed.\n",
    "A happy cat is cute. A happy dog is cute. A happy rabbit is cute.\n",
    "My cat loves toys. My dog loves toys. My rabbit loves toys.\n",
    "\"\"\"\n",
    "\n",
    "good_tokens = word_tokenize(good_text.lower())\n",
    "good_nltk = Text(good_tokens)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"GOOD CASE: Many repeated patterns\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Tokens: {len(good_tokens)}, Unique: {len(set(good_tokens))}\")\n",
    "print(\"\\nWords similar to 'cat':\")\n",
    "good_nltk.similar(\"cat\")\n",
    "print(\"\\nWords similar to 'dog':\")\n",
    "good_nltk.similar(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a911f27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "BAD CASE 1: Corpus too small\n",
      "==================================================\n",
      "Tokens: 7, Unique: 6\n",
      "\n",
      "Words similar to 'cat':\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BAD CASE 1: Too small corpus\n",
    "# ============================================\n",
    "small_text = \"\"\"The cat sat on the mat.\"\"\"\n",
    "\n",
    "small_tokens = word_tokenize(small_text.lower())\n",
    "small_nltk = Text(small_tokens)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"BAD CASE 1: Corpus too small\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Tokens: {len(small_tokens)}, Unique: {len(set(small_tokens))}\")\n",
    "print(\"\\nWords similar to 'cat':\")\n",
    "small_nltk.similar(\"cat\")  # Returns nothing - not enough data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bb8df43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "BAD CASE 2: All unique contexts (no patterns)\n",
      "==================================================\n",
      "Tokens: 38, Unique: 29\n",
      "\n",
      "Words similar to 'elephant':\n",
      "\n",
      "\n",
      "Words similar to 'submarine':\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BAD CASE 2: Unique contexts (no shared patterns)\n",
    "# ============================================\n",
    "unique_text = \"\"\"\n",
    "The elephant trumpeted loudly in the jungle.\n",
    "A submarine dove deep into the ocean.\n",
    "The astronaut floated weightlessly in space.\n",
    "My computer crashed unexpectedly yesterday morning.\n",
    "The chef prepared delicious spaghetti for dinner.\n",
    "\"\"\"\n",
    "\n",
    "unique_tokens = word_tokenize(unique_text.lower())\n",
    "unique_nltk = Text(unique_tokens)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"BAD CASE 2: All unique contexts (no patterns)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Tokens: {len(unique_tokens)}, Unique: {len(set(unique_tokens))}\")\n",
    "print(\"\\nWords similar to 'elephant':\")\n",
    "unique_nltk.similar(\"elephant\")  # No results - appears in unique context\n",
    "print(\"\\nWords similar to 'submarine':\")\n",
    "unique_nltk.similar(\"submarine\")  # No results - no shared context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8efaba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "BAD CASE 3: Each animal appears only once\n",
      "==================================================\n",
      "Tokens: 42, Unique: 25\n",
      "\n",
      "Words similar to 'cat':\n",
      "\n",
      "\n",
      "Words similar to 'bird':\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BAD CASE 3: Words appear only once\n",
    "# ============================================\n",
    "once_text = \"\"\"\n",
    "The cat played in the garden. A dog barked at the mailman.\n",
    "The bird flew over the house. A fish swam in the pond.\n",
    "The horse galloped across the field. A cow grazed in the meadow.\n",
    "\"\"\"\n",
    "\n",
    "once_tokens = word_tokenize(once_text.lower())\n",
    "once_nltk = Text(once_tokens)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"BAD CASE 3: Each animal appears only once\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Tokens: {len(once_tokens)}, Unique: {len(set(once_tokens))}\")\n",
    "print(\"\\nWords similar to 'cat':\")\n",
    "once_nltk.similar(\"cat\")  # Poor results - cat only appears once\n",
    "print(\"\\nWords similar to 'bird':\")\n",
    "once_nltk.similar(\"bird\")  # Poor results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff4555da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GOOD: Multiple shared contexts\n",
      "============================================================\n",
      "Contexts for 'cat':\n",
      "  'the' ___ 'sat'\n",
      "  'the' ___ 'slept'\n",
      "  'the' ___ 'ate'\n",
      "  'the' ___ 'ran'\n",
      "  'happy' ___ 'is'\n",
      "  'my' ___ 'loves'\n",
      "\n",
      "Words sharing contexts with 'cat':\n",
      "  'dog' shares 6 context(s): {('the', 'sat'), ('the', 'slept'), ('the', 'ate'), ('the', 'ran'), ('happy', 'is'), ('my', 'loves')}\n",
      "  'rabbit' shares 6 context(s): {('the', 'sat'), ('the', 'slept'), ('the', 'ate'), ('the', 'ran'), ('happy', 'is'), ('my', 'loves')}\n",
      "\n",
      "============================================================\n",
      "BAD: No shared contexts\n",
      "============================================================\n",
      "Contexts for 'elephant':\n",
      "  'the' ___ 'trumpeted'\n",
      "\n",
      "Words sharing contexts with 'elephant':\n",
      "  (none found - this is why similar() returns nothing!)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Understanding the context index (what similar() uses)\n",
    "# ============================================\n",
    "from collections import defaultdict\n",
    "\n",
    "def show_context_index(text, target_word):\n",
    "    \"\"\"Visualize how similar() builds its context index\"\"\"\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Build context index (simplified version of what NLTK does)\n",
    "    word_contexts = defaultdict(set)\n",
    "    \n",
    "    for i in range(1, len(tokens) - 1):\n",
    "        word = tokens[i]\n",
    "        context = (tokens[i-1], tokens[i+1])  # (word_before, word_after)\n",
    "        word_contexts[word].add(context)\n",
    "    \n",
    "    print(f\"Contexts for '{target_word}':\")\n",
    "    if target_word in word_contexts:\n",
    "        for ctx in word_contexts[target_word]:\n",
    "            print(f\"  '{ctx[0]}' ___ '{ctx[1]}'\")\n",
    "    else:\n",
    "        print(\"  (not found)\")\n",
    "    \n",
    "    # Find words with shared contexts\n",
    "    target_contexts = word_contexts.get(target_word, set())\n",
    "    similar_words = []\n",
    "    \n",
    "    for word, contexts in word_contexts.items():\n",
    "        if word != target_word:\n",
    "            shared = contexts & target_contexts\n",
    "            if shared:\n",
    "                similar_words.append((word, len(shared), shared))\n",
    "    \n",
    "    print(f\"\\nWords sharing contexts with '{target_word}':\")\n",
    "    if similar_words:\n",
    "        for word, count, shared in sorted(similar_words, key=lambda x: -x[1]):\n",
    "            print(f\"  '{word}' shares {count} context(s): {shared}\")\n",
    "    else:\n",
    "        print(\"  (none found - this is why similar() returns nothing!)\")\n",
    "\n",
    "# Demonstrate with good case\n",
    "print(\"=\" * 60)\n",
    "print(\"GOOD: Multiple shared contexts\")\n",
    "print(\"=\" * 60)\n",
    "show_context_index(good_text, \"cat\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BAD: No shared contexts\")  \n",
    "print(\"=\" * 60)\n",
    "show_context_index(unique_text, \"elephant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f583d",
   "metadata": {},
   "source": [
    "### Common Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99db0df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common contexts for 'cat' and 'dog':\n",
      "the_sat the_chased happy_is the_sleeps my_likes\n"
     ]
    }
   ],
   "source": [
    "print(\"Common contexts for 'cat' and 'dog':\")\n",
    "text_large.common_contexts([\"cat\", \"dog\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4f8af",
   "metadata": {},
   "source": [
    "### Dispersion Plot\n",
    "Visualize where words appear throughout the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5032439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dispersion plot (requires matplotlib)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_large.dispersion_plot([\"cat\", \"dog\", \"sat\", \"chased\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f9d0f0",
   "metadata": {},
   "source": [
    "## 2.3 Loading Sample Texts\n",
    "\n",
    "NLTK comes with many built-in corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a655e79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download book corpus if needed\n",
    "nltk.download('gutenberg', quiet=True)\n",
    "nltk.download('brown', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3a56de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Gutenberg texts:\n",
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# Available texts in Gutenberg corpus\n",
    "print(\"Available Gutenberg texts:\")\n",
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a960e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma by Jane Austen\n",
      "Total characters: 887,071\n",
      "\n",
      "First 500 characters:\n",
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died t\n"
     ]
    }
   ],
   "source": [
    "# Load a specific text\n",
    "emma_text = gutenberg.raw('austen-emma.txt')\n",
    "print(f\"Emma by Jane Austen\")\n",
    "print(f\"Total characters: {len(emma_text):,}\")\n",
    "print(f\"\\nFirst 500 characters:\")\n",
    "print(emma_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efef6469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 192,427\n",
      "Total sentences: 7,752\n",
      "\n",
      "First 20 words: ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich']\n",
      "\n",
      "First sentence: ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']']\n"
     ]
    }
   ],
   "source": [
    "# Get words and sentences\n",
    "emma_words = gutenberg.words('austen-emma.txt')\n",
    "emma_sents = gutenberg.sents('austen-emma.txt')\n",
    "\n",
    "print(f\"Total words: {len(emma_words):,}\")\n",
    "print(f\"Total sentences: {len(emma_sents):,}\")\n",
    "print(f\"\\nFirst 20 words: {list(emma_words[:20])}\")\n",
    "print(f\"\\nFirst sentence: {emma_sents[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528a7b2",
   "metadata": {},
   "source": [
    "### Gutenberg Corpus Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcfe1b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File                                     Chars      Words    Sents   Avg Word   Avg Sent\n",
      "-------------------------------------------------------------------------------------\n",
      "austen-emma.txt                        887,071    192,427    7,752        4.6       24.8\n",
      "austen-persuasion.txt                  466,292     98,171    3,747        4.7       26.2\n",
      "austen-sense.txt                       673,022    141,576    4,999        4.8       28.3\n",
      "bible-kjv.txt                        4,332,554  1,010,654   30,103        4.3       33.6\n",
      "blake-poems.txt                         38,153      8,354      438        4.6       19.1\n",
      "bryant-stories.txt                     249,439     55,563    2,863        4.5       19.4\n",
      "burgess-busterbrown.txt                 84,663     18,963    1,054        4.5       18.0\n",
      "carroll-alice.txt                      144,395     34,110    1,703        4.2       20.0\n",
      "chesterton-ball.txt                    457,450     96,996    4,779        4.7       20.3\n",
      "chesterton-brown.txt                   406,629     86,063    3,806        4.7       22.6\n",
      "chesterton-thursday.txt                320,525     69,213    3,742        4.6       18.5\n",
      "edgeworth-parents.txt                  935,158    210,663   10,230        4.4       20.6\n",
      "melville-moby_dick.txt               1,242,990    260,819   10,059        4.8       25.9\n",
      "milton-paradise.txt                    468,220     96,825    1,851        4.8       52.3\n",
      "shakespeare-caesar.txt                 112,310     25,833    2,163        4.3       11.9\n",
      "shakespeare-hamlet.txt                 162,881     37,360    3,106        4.4       12.0\n",
      "shakespeare-macbeth.txt                100,351     23,140    1,907        4.3       12.1\n",
      "whitman-leaves.txt                     711,215    154,883    4,250        4.6       36.4\n"
     ]
    }
   ],
   "source": [
    "# Statistics for all Gutenberg texts\n",
    "print(f\"{'File':<35} {'Chars':>10} {'Words':>10} {'Sents':>8} {'Avg Word':>10} {'Avg Sent':>10}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for fileid in gutenberg.fileids():\n",
    "    num_chars = len(gutenberg.raw(fileid))\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    avg_word_len = num_chars / num_words\n",
    "    avg_sent_len = num_words / num_sents\n",
    "    \n",
    "    print(f\"{fileid:<35} {num_chars:>10,} {num_words:>10,} {num_sents:>8,} {avg_word_len:>10.1f} {avg_sent_len:>10.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e302d42",
   "metadata": {},
   "source": [
    "### Brown Corpus (Categorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "067bb683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brown corpus categories:\n",
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "# Brown corpus categories\n",
    "print(\"Brown corpus categories:\")\n",
    "print(brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd8b25e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News category: 100,554 words\n",
      "First 20 words: ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that']\n"
     ]
    }
   ],
   "source": [
    "# Get words from a specific category\n",
    "news_words = brown.words(categories='news')\n",
    "print(f\"News category: {len(news_words):,} words\")\n",
    "print(f\"First 20 words: {list(news_words[:20])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0effe82",
   "metadata": {},
   "source": [
    "## 2.4 Text Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8ce2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_statistics(text):\n",
    "    \"\"\"Calculate comprehensive text statistics\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Basic counts\n",
    "    char_count = len(text)\n",
    "    word_count = len(tokens)\n",
    "    sent_count = len(sentences)\n",
    "    unique_words = len(set(t.lower() for t in tokens if t.isalpha()))\n",
    "    \n",
    "    # Averages\n",
    "    avg_word_len = sum(len(w) for w in tokens if w.isalpha()) / len([w for w in tokens if w.isalpha()])\n",
    "    avg_sent_len = word_count / sent_count\n",
    "    \n",
    "    # Lexical diversity\n",
    "    alpha_tokens = [t.lower() for t in tokens if t.isalpha()]\n",
    "    lexical_diversity = len(set(alpha_tokens)) / len(alpha_tokens)\n",
    "    \n",
    "    return {\n",
    "        'characters': char_count,\n",
    "        'words': word_count,\n",
    "        'sentences': sent_count,\n",
    "        'unique_words': unique_words,\n",
    "        'avg_word_length': avg_word_len,\n",
    "        'avg_sentence_length': avg_sent_len,\n",
    "        'lexical_diversity': lexical_diversity\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "752049b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Statistics\n",
      "========================================\n",
      "Characters                328\n",
      "Words                     53\n",
      "Sentences                 5\n",
      "Unique Words              37\n",
      "Avg Word Length           6.57\n",
      "Avg Sentence Length       10.60\n",
      "Lexical Diversity         0.88\n"
     ]
    }
   ],
   "source": [
    "sample = \"\"\"Natural Language Processing (NLP) is a field of artificial intelligence.\n",
    "It enables computers to understand, interpret, and generate human language.\n",
    "NLP combines computational linguistics with machine learning.\n",
    "Applications include translation, sentiment analysis, and chatbots.\n",
    "Modern NLP uses deep learning for better results.\"\"\"\n",
    "\n",
    "stats = text_statistics(sample)\n",
    "\n",
    "print(\"Text Statistics\")\n",
    "print(\"=\" * 40)\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key.replace('_', ' ').title():<25} {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{key.replace('_', ' ').title():<25} {value:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1bb36",
   "metadata": {},
   "source": [
    "### Lexical Diversity Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f00f316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Diversity by Genre (first 1000 words)\n",
      "----------------------------------------\n",
      "News                 44.71%\n",
      "Romance              43.22%\n",
      "Science Fiction      45.91%\n"
     ]
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    \"\"\"Calculate lexical diversity (unique words / total words)\"\"\"\n",
    "    tokens = [t.lower() for t in word_tokenize(text) if t.isalpha()]\n",
    "    return len(set(tokens)) / len(tokens)\n",
    "\n",
    "# Compare texts\n",
    "texts = {\n",
    "    'News': ' '.join(brown.words(categories='news')[:1000]),\n",
    "    'Romance': ' '.join(brown.words(categories='romance')[:1000]),\n",
    "    'Science Fiction': ' '.join(brown.words(categories='science_fiction')[:1000]),\n",
    "}\n",
    "\n",
    "print(\"Lexical Diversity by Genre (first 1000 words)\")\n",
    "print(\"-\" * 40)\n",
    "for genre, text in texts.items():\n",
    "    div = lexical_diversity(text)\n",
    "    print(f\"{genre:<20} {div:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227613c8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `Text(tokens)` | Create NLTK Text object |\n",
    "| `.concordance(word)` | Show word in context |\n",
    "| `.similar(word)` | Find words in similar contexts |\n",
    "| `.common_contexts([w1, w2])` | Find shared contexts |\n",
    "| `.dispersion_plot(words)` | Visualize word positions |\n",
    "| `.vocab()` | Get frequency distribution |\n",
    "| `.count(word)` | Count word occurrences |\n",
    "\n",
    "### Built-in Corpora\n",
    "- `gutenberg` - Classic literature\n",
    "- `brown` - Categorized text (news, romance, etc.)\n",
    "- `reuters` - News articles\n",
    "- `movie_reviews` - Movie reviews (positive/negative)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
