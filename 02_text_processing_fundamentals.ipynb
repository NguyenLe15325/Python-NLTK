{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89762a9a",
   "metadata": {},
   "source": [
    "# NLTK Complete Guide - Section 2: Text Processing Fundamentals\n",
    "\n",
    "This notebook covers:\n",
    "- Working with Text\n",
    "- NLTK Text Object\n",
    "- Loading Sample Texts\n",
    "- Text Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42379cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.text import Text\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dfad84",
   "metadata": {},
   "source": [
    "## 2.1 Working with Text\n",
    "\n",
    "Basic string operations on text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b73cbd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Natural Language Processing (NLP) is a field of artificial intelligence \n",
      "that gives computers the ability to understand text and spoken words.\n",
      "\n",
      "Length: 142 characters\n",
      "Word count (simple): 21\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Natural Language Processing (NLP) is a field of artificial intelligence \n",
    "that gives computers the ability to understand text and spoken words.\"\"\"\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(text)\n",
    "print(f\"\\nLength: {len(text)} characters\")\n",
    "print(f\"Word count (simple): {len(text.split())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7615cf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase:\n",
      "NATURAL LANGUAGE PROCESSING (NLP) IS A FIELD OF ARTIFICIAL INTELLIGENCE \n",
      "THAT GIVES COMPUTERS THE ABILITY TO UNDERSTAND TEXT AND SPOKEN WORDS.\n",
      "\n",
      "Lowercase:\n",
      "natural language processing (nlp) is a field of artificial intelligence \n",
      "that gives computers the ability to understand text and spoken words.\n"
     ]
    }
   ],
   "source": [
    "# Case transformations\n",
    "print(\"Uppercase:\")\n",
    "print(text.upper())\n",
    "\n",
    "print(\"\\nLowercase:\")\n",
    "print(text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d9dbe",
   "metadata": {},
   "source": [
    "## 2.2 NLTK Text Object\n",
    "\n",
    "The `Text` class provides useful methods for text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e0298b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 51\n",
      "Unique tokens: 37\n"
     ]
    }
   ],
   "source": [
    "# Create NLTK Text object\n",
    "sample_text = \"\"\"Natural Language Processing enables computers to understand human language.\n",
    "Language processing involves many complex tasks. Processing text requires \n",
    "understanding grammar and semantics. Computers can now process language effectively.\n",
    "Natural language understanding is a key challenge in artificial intelligence.\n",
    "Language models have revolutionized natural language processing.\"\"\"\n",
    "\n",
    "tokens = word_tokenize(sample_text)\n",
    "nltk_text = Text(tokens)\n",
    "\n",
    "print(f\"Total tokens: {len(nltk_text)}\")\n",
    "print(f\"Unique tokens: {len(set(nltk_text))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ac97d",
   "metadata": {},
   "source": [
    "### Concordance\n",
    "Shows a word in its context (surrounding words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f7e41df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance for 'language':\n",
      "Displaying 5 of 7 matches:\n",
      "                  Natural Language Processing enables comput\n",
      "uters to understand human language . Language processing inv\n",
      "derstand human language . Language processing involves many \n",
      "Computers can now process language effectively . Natural lan\n",
      "age effectively . Natural language understanding is a key ch\n"
     ]
    }
   ],
   "source": [
    "# Concordance - shows word in context\n",
    "print(\"Concordance for 'language':\")\n",
    "nltk_text.concordance(\"language\", width=60, lines=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29e9adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance for 'processing':\n",
      "Displaying 4 of 4 matches:\n",
      "        Natural Language Processing enables computers to und\n",
      "uman language . Language processing involves many complex ta\n",
      "ves many complex tasks . Processing text requires understand\n",
      "ionized natural language processing .\n"
     ]
    }
   ],
   "source": [
    "print(\"Concordance for 'processing':\")\n",
    "nltk_text.concordance(\"processing\", width=60, lines=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bcba32",
   "metadata": {},
   "source": [
    "### Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "391857b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'language' appears: 4 times\n",
      "'processing' appears: 2 times\n",
      "'Natural' appears: 2 times\n"
     ]
    }
   ],
   "source": [
    "# Count specific words\n",
    "print(f\"'language' appears: {nltk_text.count('language')} times\")\n",
    "print(f\"'processing' appears: {nltk_text.count('processing')} times\")\n",
    "print(f\"'Natural' appears: {nltk_text.count('Natural')} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0c038",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd255c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 most common words:\n",
      "------------------------------\n",
      ".                    6\n",
      "language             4\n",
      "Language             3\n",
      "Natural              2\n",
      "Processing           2\n",
      "processing           2\n",
      "understanding        2\n",
      "enables              1\n",
      "computers            1\n",
      "to                   1\n",
      "understand           1\n",
      "human                1\n",
      "involves             1\n",
      "many                 1\n",
      "complex              1\n"
     ]
    }
   ],
   "source": [
    "# Get vocabulary with frequencies\n",
    "vocab = nltk_text.vocab()\n",
    "\n",
    "print(\"Top 15 most common words:\")\n",
    "print(\"-\" * 30)\n",
    "for word, count in vocab.most_common(15):\n",
    "    print(f\"{word:<20} {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81398c4b",
   "metadata": {},
   "source": [
    "### Finding Similar Words\n",
    "Words that appear in similar contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64ef124c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'cat':\n",
      "dog\n",
      "Words similar to 'mouse':\n",
      "mat rug bed\n",
      "Words similar to 'rug':\n",
      "mat mouse bed\n"
     ]
    }
   ],
   "source": [
    "# Create a larger text for better similar word detection\n",
    "larger_text = \"\"\"The cat sat on the mat. The dog sat on the rug. \n",
    "The cat chased the mouse. The dog chased the cat.\n",
    "A happy cat is a good cat. A happy dog is a good dog.\n",
    "The cat sleeps on the bed. The dog sleeps on the floor.\n",
    "My cat likes fish. My dog likes meat.\"\"\"\n",
    "\n",
    "tokens_large = word_tokenize(larger_text.lower())\n",
    "text_large = Text(tokens_large)\n",
    "\n",
    "print(\"Words similar to 'cat':\")\n",
    "text_large.similar(\"cat\")\n",
    "\n",
    "print(\"Words similar to 'mouse':\")\n",
    "text_large.similar(\"mouse\")\n",
    "\n",
    "print(\"Words similar to 'rug':\")\n",
    "text_large.similar(\"rug\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a858d1",
   "metadata": {},
   "source": [
    "### How `similar()` Works\n",
    "\n",
    "The `similar()` function finds words that share **the same surrounding context** (words before and after).\n",
    "\n",
    "**Algorithm:**\n",
    "1. For each word, record its context: `(word_before, word_after)`\n",
    "2. Build an index: `context â†’ [words that appear in this context]`\n",
    "3. For a query word, find all its contexts, then find other words sharing those contexts\n",
    "\n",
    "**Limitations:**\n",
    "- Needs **repeated patterns** - words must appear multiple times in similar positions\n",
    "- **Small text** = poor results (not enough context examples)\n",
    "- **Unique contexts** = no similar words found\n",
    "- **Sentence boundaries** break context chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "741cd105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "GOOD CASE: Many repeated patterns\n",
      "==================================================\n",
      "Tokens: 114, Unique: 22\n",
      "\n",
      "Words similar to 'cat':\n",
      "dog rabbit\n",
      "\n",
      "Words similar to 'dog':\n",
      "cat rabbit\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# GOOD CASE: Repeated patterns, shared contexts\n",
    "# ============================================\n",
    "good_text = \"\"\"\n",
    "The cat sat on the mat. The dog sat on the mat. The rabbit sat on the mat.\n",
    "The cat ran to the park. The dog ran to the park. The rabbit ran to the park.\n",
    "The cat ate the food. The dog ate the food. The rabbit ate the food.\n",
    "The cat slept on the bed. The dog slept on the bed. The rabbit slept on the bed.\n",
    "A happy cat is cute. A happy dog is cute. A happy rabbit is cute.\n",
    "My cat loves toys. My dog loves toys. My rabbit loves toys.\n",
    "\"\"\"\n",
    "\n",
    "good_tokens = word_tokenize(good_text.lower())\n",
    "good_nltk = Text(good_tokens)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"GOOD CASE: Many repeated patterns\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Tokens: {len(good_tokens)}, Unique: {len(set(good_tokens))}\")\n",
    "print(\"\\nWords similar to 'cat':\")\n",
    "good_nltk.similar(\"cat\")\n",
    "print(\"\\nWords similar to 'dog':\")\n",
    "good_nltk.similar(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a911f27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "BAD CASE 1: Corpus too small\n",
      "==================================================\n",
      "Tokens: 7, Unique: 6\n",
      "\n",
      "Words similar to 'cat':\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BAD CASE 1: Too small corpus\n",
    "# ============================================\n",
    "small_text = \"\"\"The cat sat on the mat.\"\"\"\n",
    "\n",
    "small_tokens = word_tokenize(small_text.lower())\n",
    "small_nltk = Text(small_tokens)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"BAD CASE 1: Corpus too small\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Tokens: {len(small_tokens)}, Unique: {len(set(small_tokens))}\")\n",
    "print(\"\\nWords similar to 'cat':\")\n",
    "small_nltk.similar(\"cat\")  # Returns nothing - not enough data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb8df43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "BAD CASE 2: All unique contexts (no patterns)\n",
      "==================================================\n",
      "Tokens: 38, Unique: 29\n",
      "\n",
      "Words similar to 'elephant':\n",
      "\n",
      "\n",
      "Words similar to 'submarine':\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BAD CASE 2: Unique contexts (no shared patterns)\n",
    "# ============================================\n",
    "unique_text = \"\"\"\n",
    "The elephant trumpeted loudly in the jungle.\n",
    "A submarine dove deep into the ocean.\n",
    "The astronaut floated weightlessly in space.\n",
    "My computer crashed unexpectedly yesterday morning.\n",
    "The chef prepared delicious spaghetti for dinner.\n",
    "\"\"\"\n",
    "\n",
    "unique_tokens = word_tokenize(unique_text.lower())\n",
    "unique_nltk = Text(unique_tokens)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"BAD CASE 2: All unique contexts (no patterns)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Tokens: {len(unique_tokens)}, Unique: {len(set(unique_tokens))}\")\n",
    "print(\"\\nWords similar to 'elephant':\")\n",
    "unique_nltk.similar(\"elephant\")  # No results - appears in unique context\n",
    "print(\"\\nWords similar to 'submarine':\")\n",
    "unique_nltk.similar(\"submarine\")  # No results - no shared context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8efaba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "BAD CASE 3: Each animal appears only once\n",
      "==================================================\n",
      "Tokens: 42, Unique: 25\n",
      "\n",
      "Words similar to 'cat':\n",
      "\n",
      "\n",
      "Words similar to 'bird':\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BAD CASE 3: Words appear only once\n",
    "# ============================================\n",
    "once_text = \"\"\"\n",
    "The cat played in the garden. A dog barked at the mailman.\n",
    "The bird flew over the house. A fish swam in the pond.\n",
    "The horse galloped across the field. A cow grazed in the meadow.\n",
    "\"\"\"\n",
    "\n",
    "once_tokens = word_tokenize(once_text.lower())\n",
    "once_nltk = Text(once_tokens)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"BAD CASE 3: Each animal appears only once\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Tokens: {len(once_tokens)}, Unique: {len(set(once_tokens))}\")\n",
    "print(\"\\nWords similar to 'cat':\")\n",
    "once_nltk.similar(\"cat\")  # Poor results - cat only appears once\n",
    "print(\"\\nWords similar to 'bird':\")\n",
    "once_nltk.similar(\"bird\")  # Poor results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4555da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Understanding the context index (what similar() uses)\n",
    "# ============================================\n",
    "from collections import defaultdict\n",
    "\n",
    "def show_context_index(text, target_word):\n",
    "    \"\"\"Visualize how similar() builds its context index\"\"\"\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Build context index (simplified version of what NLTK does)\n",
    "    word_contexts = defaultdict(set)\n",
    "    \n",
    "    for i in range(1, len(tokens) - 1):\n",
    "        word = tokens[i]\n",
    "        context = (tokens[i-1], tokens[i+1])  # (word_before, word_after)\n",
    "        word_contexts[word].add(context)\n",
    "    \n",
    "    print(f\"Contexts for '{target_word}':\")\n",
    "    if target_word in word_contexts:\n",
    "        for ctx in word_contexts[target_word]:\n",
    "            print(f\"  '{ctx[0]}' ___ '{ctx[1]}'\")\n",
    "    else:\n",
    "        print(\"  (not found)\")\n",
    "    \n",
    "    # Find words with shared contexts\n",
    "    target_contexts = word_contexts.get(target_word, set())\n",
    "    similar_words = []\n",
    "    \n",
    "    for word, contexts in word_contexts.items():\n",
    "        if word != target_word:\n",
    "            shared = contexts & target_contexts\n",
    "            if shared:\n",
    "                similar_words.append((word, len(shared), shared))\n",
    "    \n",
    "    print(f\"\\nWords sharing contexts with '{target_word}':\")\n",
    "    if similar_words:\n",
    "        for word, count, shared in sorted(similar_words, key=lambda x: -x[1]):\n",
    "            print(f\"  '{word}' shares {count} context(s): {shared}\")\n",
    "    else:\n",
    "        print(\"  (none found - this is why similar() returns nothing!)\")\n",
    "\n",
    "# Demonstrate with good case\n",
    "print(\"=\" * 60)\n",
    "print(\"GOOD: Multiple shared contexts\")\n",
    "print(\"=\" * 60)\n",
    "show_context_index(good_text, \"cat\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BAD: No shared contexts\")  \n",
    "print(\"=\" * 60)\n",
    "show_context_index(unique_text, \"elephant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baabba46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words similar to 'dog':\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(\"Words similar to 'dog':\")\n",
    "text_large.similar(\"dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f583d",
   "metadata": {},
   "source": [
    "### Common Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99db0df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Common contexts for 'cat' and 'dog':\")\n",
    "text_large.common_contexts([\"cat\", \"dog\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4f8af",
   "metadata": {},
   "source": [
    "### Dispersion Plot\n",
    "Visualize where words appear throughout the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5032439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispersion plot (requires matplotlib)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_large.dispersion_plot([\"cat\", \"dog\", \"sat\", \"chased\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f9d0f0",
   "metadata": {},
   "source": [
    "## 2.3 Loading Sample Texts\n",
    "\n",
    "NLTK comes with many built-in corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a655e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download book corpus if needed\n",
    "nltk.download('gutenberg', quiet=True)\n",
    "nltk.download('brown', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a56de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# Available texts in Gutenberg corpus\n",
    "print(\"Available Gutenberg texts:\")\n",
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a960e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a specific text\n",
    "emma_text = gutenberg.raw('austen-emma.txt')\n",
    "print(f\"Emma by Jane Austen\")\n",
    "print(f\"Total characters: {len(emma_text):,}\")\n",
    "print(f\"\\nFirst 500 characters:\")\n",
    "print(emma_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words and sentences\n",
    "emma_words = gutenberg.words('austen-emma.txt')\n",
    "emma_sents = gutenberg.sents('austen-emma.txt')\n",
    "\n",
    "print(f\"Total words: {len(emma_words):,}\")\n",
    "print(f\"Total sentences: {len(emma_sents):,}\")\n",
    "print(f\"\\nFirst 20 words: {list(emma_words[:20])}\")\n",
    "print(f\"\\nFirst sentence: {emma_sents[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528a7b2",
   "metadata": {},
   "source": [
    "### Gutenberg Corpus Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfe1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics for all Gutenberg texts\n",
    "print(f\"{'File':<35} {'Chars':>10} {'Words':>10} {'Sents':>8} {'Avg Word':>10} {'Avg Sent':>10}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for fileid in gutenberg.fileids():\n",
    "    num_chars = len(gutenberg.raw(fileid))\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    avg_word_len = num_chars / num_words\n",
    "    avg_sent_len = num_words / num_sents\n",
    "    \n",
    "    print(f\"{fileid:<35} {num_chars:>10,} {num_words:>10,} {num_sents:>8,} {avg_word_len:>10.1f} {avg_sent_len:>10.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e302d42",
   "metadata": {},
   "source": [
    "### Brown Corpus (Categorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067bb683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "# Brown corpus categories\n",
    "print(\"Brown corpus categories:\")\n",
    "print(brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words from a specific category\n",
    "news_words = brown.words(categories='news')\n",
    "print(f\"News category: {len(news_words):,} words\")\n",
    "print(f\"First 20 words: {list(news_words[:20])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0effe82",
   "metadata": {},
   "source": [
    "## 2.4 Text Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_statistics(text):\n",
    "    \"\"\"Calculate comprehensive text statistics\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Basic counts\n",
    "    char_count = len(text)\n",
    "    word_count = len(tokens)\n",
    "    sent_count = len(sentences)\n",
    "    unique_words = len(set(t.lower() for t in tokens if t.isalpha()))\n",
    "    \n",
    "    # Averages\n",
    "    avg_word_len = sum(len(w) for w in tokens if w.isalpha()) / len([w for w in tokens if w.isalpha()])\n",
    "    avg_sent_len = word_count / sent_count\n",
    "    \n",
    "    # Lexical diversity\n",
    "    alpha_tokens = [t.lower() for t in tokens if t.isalpha()]\n",
    "    lexical_diversity = len(set(alpha_tokens)) / len(alpha_tokens)\n",
    "    \n",
    "    return {\n",
    "        'characters': char_count,\n",
    "        'words': word_count,\n",
    "        'sentences': sent_count,\n",
    "        'unique_words': unique_words,\n",
    "        'avg_word_length': avg_word_len,\n",
    "        'avg_sentence_length': avg_sent_len,\n",
    "        'lexical_diversity': lexical_diversity\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752049b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"Natural Language Processing (NLP) is a field of artificial intelligence.\n",
    "It enables computers to understand, interpret, and generate human language.\n",
    "NLP combines computational linguistics with machine learning.\n",
    "Applications include translation, sentiment analysis, and chatbots.\n",
    "Modern NLP uses deep learning for better results.\"\"\"\n",
    "\n",
    "stats = text_statistics(sample)\n",
    "\n",
    "print(\"Text Statistics\")\n",
    "print(\"=\" * 40)\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key.replace('_', ' ').title():<25} {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{key.replace('_', ' ').title():<25} {value:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1bb36",
   "metadata": {},
   "source": [
    "### Lexical Diversity Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f00f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    \"\"\"Calculate lexical diversity (unique words / total words)\"\"\"\n",
    "    tokens = [t.lower() for t in word_tokenize(text) if t.isalpha()]\n",
    "    return len(set(tokens)) / len(tokens)\n",
    "\n",
    "# Compare texts\n",
    "texts = {\n",
    "    'News': ' '.join(brown.words(categories='news')[:1000]),\n",
    "    'Romance': ' '.join(brown.words(categories='romance')[:1000]),\n",
    "    'Science Fiction': ' '.join(brown.words(categories='science_fiction')[:1000]),\n",
    "}\n",
    "\n",
    "print(\"Lexical Diversity by Genre (first 1000 words)\")\n",
    "print(\"-\" * 40)\n",
    "for genre, text in texts.items():\n",
    "    div = lexical_diversity(text)\n",
    "    print(f\"{genre:<20} {div:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227613c8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `Text(tokens)` | Create NLTK Text object |\n",
    "| `.concordance(word)` | Show word in context |\n",
    "| `.similar(word)` | Find words in similar contexts |\n",
    "| `.common_contexts([w1, w2])` | Find shared contexts |\n",
    "| `.dispersion_plot(words)` | Visualize word positions |\n",
    "| `.vocab()` | Get frequency distribution |\n",
    "| `.count(word)` | Count word occurrences |\n",
    "\n",
    "### Built-in Corpora\n",
    "- `gutenberg` - Classic literature\n",
    "- `brown` - Categorized text (news, romance, etc.)\n",
    "- `reuters` - News articles\n",
    "- `movie_reviews` - Movie reviews (positive/negative)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
