{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89762a9a",
   "metadata": {},
   "source": [
    "# NLTK Complete Guide - Section 2: Text Processing Fundamentals\n",
    "\n",
    "This notebook covers:\n",
    "- Working with Text\n",
    "- NLTK Text Object\n",
    "- Loading Sample Texts\n",
    "- Text Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42379cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.text import Text\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dfad84",
   "metadata": {},
   "source": [
    "## 2.1 Working with Text\n",
    "\n",
    "Basic string operations on text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73cbd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Natural Language Processing (NLP) is a field of artificial intelligence \n",
    "that gives computers the ability to understand text and spoken words.\"\"\"\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(text)\n",
    "print(f\"\\nLength: {len(text)} characters\")\n",
    "print(f\"Word count (simple): {len(text.split())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case transformations\n",
    "print(\"Uppercase:\")\n",
    "print(text.upper())\n",
    "\n",
    "print(\"\\nLowercase:\")\n",
    "print(text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d9dbe",
   "metadata": {},
   "source": [
    "## 2.2 NLTK Text Object\n",
    "\n",
    "The `Text` class provides useful methods for text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0298b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NLTK Text object\n",
    "sample_text = \"\"\"Natural Language Processing enables computers to understand human language.\n",
    "Language processing involves many complex tasks. Processing text requires \n",
    "understanding grammar and semantics. Computers can now process language effectively.\n",
    "Natural language understanding is a key challenge in artificial intelligence.\n",
    "Language models have revolutionized natural language processing.\"\"\"\n",
    "\n",
    "tokens = word_tokenize(sample_text)\n",
    "nltk_text = Text(tokens)\n",
    "\n",
    "print(f\"Total tokens: {len(nltk_text)}\")\n",
    "print(f\"Unique tokens: {len(set(nltk_text))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ac97d",
   "metadata": {},
   "source": [
    "### Concordance\n",
    "Shows a word in its context (surrounding words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concordance - shows word in context\n",
    "print(\"Concordance for 'language':\")\n",
    "nltk_text.concordance(\"language\", width=60, lines=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e9adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Concordance for 'processing':\")\n",
    "nltk_text.concordance(\"processing\", width=60, lines=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bcba32",
   "metadata": {},
   "source": [
    "### Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391857b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count specific words\n",
    "print(f\"'language' appears: {nltk_text.count('language')} times\")\n",
    "print(f\"'processing' appears: {nltk_text.count('processing')} times\")\n",
    "print(f\"'Natural' appears: {nltk_text.count('Natural')} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0c038",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd255c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vocabulary with frequencies\n",
    "vocab = nltk_text.vocab()\n",
    "\n",
    "print(\"Top 15 most common words:\")\n",
    "print(\"-\" * 30)\n",
    "for word, count in vocab.most_common(15):\n",
    "    print(f\"{word:<20} {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81398c4b",
   "metadata": {},
   "source": [
    "### Finding Similar Words\n",
    "Words that appear in similar contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger text for better similar word detection\n",
    "larger_text = \"\"\"The cat sat on the mat. The dog sat on the rug. \n",
    "The cat chased the mouse. The dog chased the cat.\n",
    "A happy cat is a good cat. A happy dog is a good dog.\n",
    "The cat sleeps on the bed. The dog sleeps on the floor.\n",
    "My cat likes fish. My dog likes meat.\"\"\"\n",
    "\n",
    "tokens_large = word_tokenize(larger_text.lower())\n",
    "text_large = Text(tokens_large)\n",
    "\n",
    "print(\"Words similar to 'cat':\")\n",
    "text_large.similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baabba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Words similar to 'dog':\")\n",
    "text_large.similar(\"dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f583d",
   "metadata": {},
   "source": [
    "### Common Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99db0df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Common contexts for 'cat' and 'dog':\")\n",
    "text_large.common_contexts([\"cat\", \"dog\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4f8af",
   "metadata": {},
   "source": [
    "### Dispersion Plot\n",
    "Visualize where words appear throughout the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5032439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispersion plot (requires matplotlib)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_large.dispersion_plot([\"cat\", \"dog\", \"sat\", \"chased\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f9d0f0",
   "metadata": {},
   "source": [
    "## 2.3 Loading Sample Texts\n",
    "\n",
    "NLTK comes with many built-in corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a655e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download book corpus if needed\n",
    "nltk.download('gutenberg', quiet=True)\n",
    "nltk.download('brown', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a56de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# Available texts in Gutenberg corpus\n",
    "print(\"Available Gutenberg texts:\")\n",
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a960e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a specific text\n",
    "emma_text = gutenberg.raw('austen-emma.txt')\n",
    "print(f\"Emma by Jane Austen\")\n",
    "print(f\"Total characters: {len(emma_text):,}\")\n",
    "print(f\"\\nFirst 500 characters:\")\n",
    "print(emma_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words and sentences\n",
    "emma_words = gutenberg.words('austen-emma.txt')\n",
    "emma_sents = gutenberg.sents('austen-emma.txt')\n",
    "\n",
    "print(f\"Total words: {len(emma_words):,}\")\n",
    "print(f\"Total sentences: {len(emma_sents):,}\")\n",
    "print(f\"\\nFirst 20 words: {list(emma_words[:20])}\")\n",
    "print(f\"\\nFirst sentence: {emma_sents[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528a7b2",
   "metadata": {},
   "source": [
    "### Gutenberg Corpus Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfe1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics for all Gutenberg texts\n",
    "print(f\"{'File':<35} {'Chars':>10} {'Words':>10} {'Sents':>8} {'Avg Word':>10} {'Avg Sent':>10}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for fileid in gutenberg.fileids():\n",
    "    num_chars = len(gutenberg.raw(fileid))\n",
    "    num_words = len(gutenberg.words(fileid))\n",
    "    num_sents = len(gutenberg.sents(fileid))\n",
    "    avg_word_len = num_chars / num_words\n",
    "    avg_sent_len = num_words / num_sents\n",
    "    \n",
    "    print(f\"{fileid:<35} {num_chars:>10,} {num_words:>10,} {num_sents:>8,} {avg_word_len:>10.1f} {avg_sent_len:>10.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e302d42",
   "metadata": {},
   "source": [
    "### Brown Corpus (Categorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067bb683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "# Brown corpus categories\n",
    "print(\"Brown corpus categories:\")\n",
    "print(brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words from a specific category\n",
    "news_words = brown.words(categories='news')\n",
    "print(f\"News category: {len(news_words):,} words\")\n",
    "print(f\"First 20 words: {list(news_words[:20])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0effe82",
   "metadata": {},
   "source": [
    "## 2.4 Text Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_statistics(text):\n",
    "    \"\"\"Calculate comprehensive text statistics\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Basic counts\n",
    "    char_count = len(text)\n",
    "    word_count = len(tokens)\n",
    "    sent_count = len(sentences)\n",
    "    unique_words = len(set(t.lower() for t in tokens if t.isalpha()))\n",
    "    \n",
    "    # Averages\n",
    "    avg_word_len = sum(len(w) for w in tokens if w.isalpha()) / len([w for w in tokens if w.isalpha()])\n",
    "    avg_sent_len = word_count / sent_count\n",
    "    \n",
    "    # Lexical diversity\n",
    "    alpha_tokens = [t.lower() for t in tokens if t.isalpha()]\n",
    "    lexical_diversity = len(set(alpha_tokens)) / len(alpha_tokens)\n",
    "    \n",
    "    return {\n",
    "        'characters': char_count,\n",
    "        'words': word_count,\n",
    "        'sentences': sent_count,\n",
    "        'unique_words': unique_words,\n",
    "        'avg_word_length': avg_word_len,\n",
    "        'avg_sentence_length': avg_sent_len,\n",
    "        'lexical_diversity': lexical_diversity\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752049b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"Natural Language Processing (NLP) is a field of artificial intelligence.\n",
    "It enables computers to understand, interpret, and generate human language.\n",
    "NLP combines computational linguistics with machine learning.\n",
    "Applications include translation, sentiment analysis, and chatbots.\n",
    "Modern NLP uses deep learning for better results.\"\"\"\n",
    "\n",
    "stats = text_statistics(sample)\n",
    "\n",
    "print(\"Text Statistics\")\n",
    "print(\"=\" * 40)\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key.replace('_', ' ').title():<25} {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{key.replace('_', ' ').title():<25} {value:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1bb36",
   "metadata": {},
   "source": [
    "### Lexical Diversity Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f00f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    \"\"\"Calculate lexical diversity (unique words / total words)\"\"\"\n",
    "    tokens = [t.lower() for t in word_tokenize(text) if t.isalpha()]\n",
    "    return len(set(tokens)) / len(tokens)\n",
    "\n",
    "# Compare texts\n",
    "texts = {\n",
    "    'News': ' '.join(brown.words(categories='news')[:1000]),\n",
    "    'Romance': ' '.join(brown.words(categories='romance')[:1000]),\n",
    "    'Science Fiction': ' '.join(brown.words(categories='science_fiction')[:1000]),\n",
    "}\n",
    "\n",
    "print(\"Lexical Diversity by Genre (first 1000 words)\")\n",
    "print(\"-\" * 40)\n",
    "for genre, text in texts.items():\n",
    "    div = lexical_diversity(text)\n",
    "    print(f\"{genre:<20} {div:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227613c8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `Text(tokens)` | Create NLTK Text object |\n",
    "| `.concordance(word)` | Show word in context |\n",
    "| `.similar(word)` | Find words in similar contexts |\n",
    "| `.common_contexts([w1, w2])` | Find shared contexts |\n",
    "| `.dispersion_plot(words)` | Visualize word positions |\n",
    "| `.vocab()` | Get frequency distribution |\n",
    "| `.count(word)` | Count word occurrences |\n",
    "\n",
    "### Built-in Corpora\n",
    "- `gutenberg` - Classic literature\n",
    "- `brown` - Categorized text (news, romance, etc.)\n",
    "- `reuters` - News articles\n",
    "- `movie_reviews` - Movie reviews (positive/negative)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
