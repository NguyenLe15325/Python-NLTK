{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e24d6929",
   "metadata": {},
   "source": [
    "# NLTK Complete Guide - Section 5: Stemming\n",
    "\n",
    "This notebook covers:\n",
    "- Porter Stemmer\n",
    "- Lancaster Stemmer\n",
    "- Snowball Stemmer (Multi-language)\n",
    "- Regexp Stemmer\n",
    "- Comparing Stemmers\n",
    "- Practical Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2deb5a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer, RegexpStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ff6335",
   "metadata": {},
   "source": [
    "## What is Stemming?\n",
    "\n",
    "**Stemming** reduces words to their root/base form by removing suffixes.\n",
    "\n",
    "- `running` ‚Üí `run`\n",
    "- `studies` ‚Üí `studi`\n",
    "- `happiness` ‚Üí `happi`\n",
    "\n",
    "‚ö†Ô∏è **Note**: Stems are not always valid words!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addffd2c",
   "metadata": {},
   "source": [
    "## 5.1 Porter Stemmer\n",
    "\n",
    "Most widely used stemmer. Uses a series of rules to strip suffixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "838f1642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer Results\n",
      "===================================\n",
      "Word                 Stem           \n",
      "-----------------------------------\n",
      "running              run            \n",
      "runs                 run            \n",
      "runner               runner         \n",
      "ran                  ran            \n",
      "easily               easili         \n",
      "fairly               fairli         \n",
      "happily              happili        \n",
      "studies              studi          \n",
      "studying             studi          \n",
      "studied              studi          \n",
      "connection           connect        \n",
      "connected            connect        \n",
      "connecting           connect        \n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "words = [\n",
    "    \"running\", \"runs\", \"runner\", \"ran\",\n",
    "    \"easily\", \"fairly\", \"happily\",\n",
    "    \"studies\", \"studying\", \"studied\",\n",
    "    \"connection\", \"connected\", \"connecting\",\n",
    "]\n",
    "\n",
    "print(\"Porter Stemmer Results\")\n",
    "print(\"=\" * 35)\n",
    "print(f\"{'Word':<20} {'Stem':<15}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word:<20} {ps.stem(word):<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245b52af",
   "metadata": {},
   "source": [
    "### Porter Stemmer Rules Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1a79b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer - Common Rules\n",
      "==================================================\n",
      "\n",
      "Plural (-s, -es):\n",
      "  cats            ‚Üí cat\n",
      "  dogs            ‚Üí dog\n",
      "  boxes           ‚Üí box\n",
      "  churches        ‚Üí church\n",
      "\n",
      "Past tense (-ed):\n",
      "  walked          ‚Üí walk\n",
      "  jumped          ‚Üí jump\n",
      "  added           ‚Üí ad\n",
      "  needed          ‚Üí need\n",
      "\n",
      "Progressive (-ing):\n",
      "  running         ‚Üí run\n",
      "  walking         ‚Üí walk\n",
      "  sitting         ‚Üí sit\n",
      "  getting         ‚Üí get\n",
      "\n",
      "Adverbs (-ly):\n",
      "  quickly         ‚Üí quickli\n",
      "  happily         ‚Üí happili\n",
      "  easily          ‚Üí easili\n",
      "  angrily         ‚Üí angrili\n",
      "\n",
      "Nouns (-tion, -ment):\n",
      "  connection      ‚Üí connect\n",
      "  movement        ‚Üí movement\n",
      "  action          ‚Üí action\n",
      "  judgment        ‚Üí judgment\n"
     ]
    }
   ],
   "source": [
    "rules_demo = {\n",
    "    \"Plural (-s, -es)\": [\"cats\", \"dogs\", \"boxes\", \"churches\"],\n",
    "    \"Past tense (-ed)\": [\"walked\", \"jumped\", \"added\", \"needed\"],\n",
    "    \"Progressive (-ing)\": [\"running\", \"walking\", \"sitting\", \"getting\"],\n",
    "    \"Adverbs (-ly)\": [\"quickly\", \"happily\", \"easily\", \"angrily\"],\n",
    "    \"Nouns (-tion, -ment)\": [\"connection\", \"movement\", \"action\", \"judgment\"],\n",
    "}\n",
    "\n",
    "print(\"Porter Stemmer - Common Rules\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for rule, words in rules_demo.items():\n",
    "    print(f\"\\n{rule}:\")\n",
    "    for word in words:\n",
    "        print(f\"  {word:<15} ‚Üí {ps.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7ddf6",
   "metadata": {},
   "source": [
    "## 5.2 Lancaster Stemmer\n",
    "\n",
    "More aggressive than Porter. Often produces shorter stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f171d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancaster Stemmer Results\n",
      "===================================\n",
      "Word                 Stem           \n",
      "-----------------------------------\n",
      "running              run            \n",
      "maximum              maxim          \n",
      "presumably           presum         \n",
      "multiply             multiply       \n",
      "organization         org            \n",
      "generalization       gen            \n",
      "maximize             maxim          \n"
     ]
    }
   ],
   "source": [
    "ls = LancasterStemmer()\n",
    "\n",
    "words = [\n",
    "    \"running\", \"maximum\", \"presumably\", \"multiply\",\n",
    "    \"organization\", \"generalization\", \"maximize\",\n",
    "]\n",
    "\n",
    "print(\"Lancaster Stemmer Results\")\n",
    "print(\"=\" * 35)\n",
    "print(f\"{'Word':<20} {'Stem':<15}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word:<20} {ls.stem(word):<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba74d0",
   "metadata": {},
   "source": [
    "### Porter vs Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b396f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter vs Lancaster Comparison\n",
      "=======================================================\n",
      "Word               Porter          Lancaster       Diff\n",
      "-------------------------------------------------------\n",
      "running            run             run             \n",
      "maximum            maximum         maxim           *\n",
      "presumably         presum          presum          \n",
      "multiply           multipli        multiply        *\n",
      "generalization     gener           gen             *\n",
      "organization       organ           org             *\n",
      "loving             love            lov             *\n",
      "happiness          happi           happy           *\n",
      "connection         connect         connect         \n",
      "generate           gener           gen             *\n",
      "university         univers         univers         \n",
      "friendship         friendship      friend          *\n",
      "\n",
      "* = Different results\n",
      "üí° Lancaster is more aggressive, often shorter stems\n"
     ]
    }
   ],
   "source": [
    "words = [\n",
    "    \"running\", \"maximum\", \"presumably\", \"multiply\",\n",
    "    \"generalization\", \"organization\", \"loving\", \"happiness\",\n",
    "    \"connection\", \"generate\", \"university\", \"friendship\",\n",
    "]\n",
    "\n",
    "print(\"Porter vs Lancaster Comparison\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Word':<18} {'Porter':<15} {'Lancaster':<15} {'Diff'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for word in words:\n",
    "    porter = ps.stem(word)\n",
    "    lancaster = ls.stem(word)\n",
    "    diff = \"*\" if porter != lancaster else \"\"\n",
    "    print(f\"{word:<18} {porter:<15} {lancaster:<15} {diff}\")\n",
    "\n",
    "print(\"\\n* = Different results\")\n",
    "print(\"üí° Lancaster is more aggressive, often shorter stems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b86c587",
   "metadata": {},
   "source": [
    "## 5.3 Snowball Stemmer\n",
    "\n",
    "Improved Porter stemmer with multi-language support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa40ede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available languages:\n",
      "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
     ]
    }
   ],
   "source": [
    "# Available languages\n",
    "print(\"Available languages:\")\n",
    "print(SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1649c1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Snowball Stemmer:\n",
      "  running ‚Üí run\n",
      "  generously ‚Üí generous\n",
      "  happiness ‚Üí happi\n",
      "  beautiful ‚Üí beauti\n",
      "  organization ‚Üí organ\n"
     ]
    }
   ],
   "source": [
    "# English Snowball Stemmer\n",
    "ss = SnowballStemmer(\"english\")\n",
    "\n",
    "words = [\"running\", \"generously\", \"happiness\", \"beautiful\", \"organization\"]\n",
    "\n",
    "print(\"English Snowball Stemmer:\")\n",
    "for word in words:\n",
    "    print(f\"  {word} ‚Üí {ss.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c8a4c",
   "metadata": {},
   "source": [
    "### Multi-language Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "465f436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-language Snowball Stemming\n",
      "============================================================\n",
      "\n",
      "English:\n",
      "  running              ‚Üí run\n",
      "  happiness            ‚Üí happi\n",
      "  organization         ‚Üí organ\n",
      "\n",
      "Spanish:\n",
      "  corriendo            ‚Üí corr\n",
      "  felicidad            ‚Üí felic\n",
      "  organizaci√≥n         ‚Üí organiz\n",
      "\n",
      "French:\n",
      "  courant              ‚Üí cour\n",
      "  bonheur              ‚Üí bonheur\n",
      "  organisation         ‚Üí organis\n",
      "\n",
      "German:\n",
      "  laufend              ‚Üí laufend\n",
      "  Gl√ºck                ‚Üí gluck\n",
      "  Organisation         ‚Üí organisation\n",
      "\n",
      "Italian:\n",
      "  correndo             ‚Üí corr\n",
      "  felicit√†             ‚Üí felic\n",
      "  organizzazione       ‚Üí organizz\n"
     ]
    }
   ],
   "source": [
    "# Test words in different languages\n",
    "test_cases = {\n",
    "    \"english\": [\"running\", \"happiness\", \"organization\"],\n",
    "    \"spanish\": [\"corriendo\", \"felicidad\", \"organizaci√≥n\"],\n",
    "    \"french\": [\"courant\", \"bonheur\", \"organisation\"],\n",
    "    \"german\": [\"laufend\", \"Gl√ºck\", \"Organisation\"],\n",
    "    \"italian\": [\"correndo\", \"felicit√†\", \"organizzazione\"],\n",
    "}\n",
    "\n",
    "print(\"Multi-language Snowball Stemming\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for language, words in test_cases.items():\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    print(f\"\\n{language.capitalize()}:\")\n",
    "    for word in words:\n",
    "        print(f\"  {word:<20} ‚Üí {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43204ad1",
   "metadata": {},
   "source": [
    "## 5.4 Regexp Stemmer\n",
    "\n",
    "Create custom stemmers using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd803109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regexp Stemmer (removes -ing, -ed, -s)\n",
      "Pattern: 'ing$|ed$|s$', min_length=4\n",
      "----------------------------------------\n",
      "  running         ‚Üí runn\n",
      "  walked          ‚Üí walk\n",
      "  cats            ‚Üí cat\n",
      "  dogs            ‚Üí dog\n",
      "  jumping         ‚Üí jump\n",
      "  needed          ‚Üí need\n"
     ]
    }
   ],
   "source": [
    "# Basic suffix removal\n",
    "rs = RegexpStemmer('ing$|ed$|s$', min=4)\n",
    "\n",
    "words = [\"running\", \"walked\", \"cats\", \"dogs\", \"jumping\", \"needed\"]\n",
    "\n",
    "print(\"Regexp Stemmer (removes -ing, -ed, -s)\")\n",
    "print(f\"Pattern: 'ing$|ed$|s$', min_length=4\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for word in words:\n",
    "    print(f\"  {word:<15} ‚Üí {rs.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f5c1c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Regexp Stemmers\n",
      "==================================================\n",
      "\n",
      "Verbal suffixes (pattern: 'ing$|ed$|es$|s$'):\n",
      "  running         ‚Üí runn\n",
      "  walked          ‚Üí walk\n",
      "  boxes           ‚Üí box\n",
      "  plays           ‚Üí play\n",
      "\n",
      "Noun suffixes (pattern: 'tion$|ment$|ness$|ity$'):\n",
      "  connection      ‚Üí connec\n",
      "  movement        ‚Üí move\n",
      "  happiness       ‚Üí happi\n",
      "  ability         ‚Üí abil\n",
      "\n",
      "Adjective suffixes (pattern: 'able$|ible$|ful$|less$'):\n",
      "  readable        ‚Üí read\n",
      "  visible         ‚Üí vis\n",
      "  beautiful       ‚Üí beauti\n",
      "  careless        ‚Üí care\n",
      "\n",
      "Adverb suffixes (pattern: 'ly$'):\n",
      "  quickly         ‚Üí quick\n",
      "  happily         ‚Üí happi\n",
      "  slowly          ‚Üí slow\n",
      "  carefully       ‚Üí careful\n"
     ]
    }
   ],
   "source": [
    "# Custom patterns for different word types\n",
    "patterns = {\n",
    "    \"Verbal\": ('ing$|ed$|es$|s$', 3, [\"running\", \"walked\", \"boxes\", \"plays\"]),\n",
    "    \"Noun\": ('tion$|ment$|ness$|ity$', 4, [\"connection\", \"movement\", \"happiness\", \"ability\"]),\n",
    "    \"Adjective\": ('able$|ible$|ful$|less$', 4, [\"readable\", \"visible\", \"beautiful\", \"careless\"]),\n",
    "    \"Adverb\": ('ly$', 4, [\"quickly\", \"happily\", \"slowly\", \"carefully\"]),\n",
    "}\n",
    "\n",
    "print(\"Custom Regexp Stemmers\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, (pattern, min_len, words) in patterns.items():\n",
    "    stemmer = RegexpStemmer(pattern, min=min_len)\n",
    "    print(f\"\\n{name} suffixes (pattern: '{pattern}'):\")\n",
    "    for word in words:\n",
    "        print(f\"  {word:<15} ‚Üí {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe5c482",
   "metadata": {},
   "source": [
    "## 5.5 Comparing All Stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51129ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Stemmers Comparison\n",
      "===========================================================================\n",
      "Word             Porter       Lancaster    Snowball     Regexp      \n",
      "---------------------------------------------------------------------------\n",
      "programming      program      program      program      programm    \n",
      "programmer       programm     program      programm     programmer  \n",
      "programmed       program      program      program      programm    \n",
      "organization     organ        org          organ        organiza    \n",
      "organized        organ        org          organ        organiz     \n",
      "organizing       organ        org          organ        organiz     \n",
      "beautiful        beauti       beauty       beauti       beautiful   \n",
      "beautifully      beauti       beauty       beauti       beautifully \n",
      "beauty           beauti       beauty       beauti       beauty      \n",
      "happiness        happi        happy        happi        happines    \n",
      "happy            happi        happy        happi        happy       \n",
      "happily          happili      happy        happili      happily     \n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "ls = LancasterStemmer()\n",
    "ss = SnowballStemmer(\"english\")\n",
    "rs = RegexpStemmer('ing$|ed$|s$|able$|tion$', min=4)\n",
    "\n",
    "words = [\n",
    "    \"programming\", \"programmer\", \"programmed\",\n",
    "    \"organization\", \"organized\", \"organizing\",\n",
    "    \"beautiful\", \"beautifully\", \"beauty\",\n",
    "    \"happiness\", \"happy\", \"happily\",\n",
    "]\n",
    "\n",
    "print(\"All Stemmers Comparison\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Word':<16} {'Porter':<12} {'Lancaster':<12} {'Snowball':<12} {'Regexp':<12}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for word in words:\n",
    "    print(f\"{word:<16} {ps.stem(word):<12} {ls.stem(word):<12} {ss.stem(word):<12} {rs.stem(word):<12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b0851",
   "metadata": {},
   "source": [
    "### Consistency Test\n",
    "\n",
    "Do words with the same meaning get the same stem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a90612ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmer Consistency Test\n",
      "============================================================\n",
      "\n",
      "Word family: ['run', 'running', 'runs', 'runner', 'ran']\n",
      "  Porter     ‚Üí {'runner', 'run', 'ran'}  ‚ö†Ô∏è 3 different stems\n",
      "  Lancaster  ‚Üí {'ran', 'run'}  ‚ö†Ô∏è 2 different stems\n",
      "  Snowball   ‚Üí {'runner', 'run', 'ran'}  ‚ö†Ô∏è 3 different stems\n",
      "\n",
      "Word family: ['connect', 'connection', 'connected', 'connecting']\n",
      "  Porter     ‚Üí {'connect'}  ‚úÖ Consistent\n",
      "  Lancaster  ‚Üí {'connect'}  ‚úÖ Consistent\n",
      "  Snowball   ‚Üí {'connect'}  ‚úÖ Consistent\n",
      "\n",
      "Word family: ['happy', 'happiness', 'happily', 'happier']\n",
      "  Porter     ‚Üí {'happili', 'happi', 'happier'}  ‚ö†Ô∏è 3 different stems\n",
      "  Lancaster  ‚Üí {'happy'}  ‚úÖ Consistent\n",
      "  Snowball   ‚Üí {'happili', 'happi', 'happier'}  ‚ö†Ô∏è 3 different stems\n",
      "\n",
      "Word family: ['beauty', 'beautiful', 'beautifully', 'beautify']\n",
      "  Porter     ‚Üí {'beautifi', 'beauti'}  ‚ö†Ô∏è 2 different stems\n",
      "  Lancaster  ‚Üí {'beauty', 'beaut'}  ‚ö†Ô∏è 2 different stems\n",
      "  Snowball   ‚Üí {'beautifi', 'beauti'}  ‚ö†Ô∏è 2 different stems\n"
     ]
    }
   ],
   "source": [
    "word_families = [\n",
    "    [\"run\", \"running\", \"runs\", \"runner\", \"ran\"],\n",
    "    [\"connect\", \"connection\", \"connected\", \"connecting\"],\n",
    "    [\"happy\", \"happiness\", \"happily\", \"happier\"],\n",
    "    [\"beauty\", \"beautiful\", \"beautifully\", \"beautify\"],\n",
    "]\n",
    "\n",
    "print(\"Stemmer Consistency Test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for family in word_families:\n",
    "    print(f\"\\nWord family: {family}\")\n",
    "    \n",
    "    for name, stemmer in [(\"Porter\", ps), (\"Lancaster\", ls), (\"Snowball\", ss)]:\n",
    "        stems = [stemmer.stem(word) for word in family]\n",
    "        unique_stems = set(stems)\n",
    "        is_consistent = len(unique_stems) == 1\n",
    "        status = \"‚úÖ Consistent\" if is_consistent else f\"‚ö†Ô∏è {len(unique_stems)} different stems\"\n",
    "        print(f\"  {name:<10} ‚Üí {unique_stems}  {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f017e066",
   "metadata": {},
   "source": [
    "## 5.6 Practical Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f303742d",
   "metadata": {},
   "source": [
    "### Stemming a Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81f308e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Stemming\n",
      "============================================================\n",
      "\n",
      "Original: The cats are running and jumping happily.\n",
      "Stemmed:  the cat are run and jump happili\n",
      "\n",
      "Original: She was studying programming and organizing her notes.\n",
      "Stemmed:  she wa studi program and organ her note\n",
      "\n",
      "Original: The beautiful organization connected many communities.\n",
      "Stemmed:  the beauti organ connect mani commun\n"
     ]
    }
   ],
   "source": [
    "def stem_sentence(sentence, stemmer=None):\n",
    "    \"\"\"Stem all words in a sentence\"\"\"\n",
    "    if stemmer is None:\n",
    "        stemmer = PorterStemmer()\n",
    "    \n",
    "    tokens = word_tokenize(sentence.lower())\n",
    "    stemmed = [stemmer.stem(t) for t in tokens if t.isalpha()]\n",
    "    return stemmed\n",
    "\n",
    "sentences = [\n",
    "    \"The cats are running and jumping happily.\",\n",
    "    \"She was studying programming and organizing her notes.\",\n",
    "    \"The beautiful organization connected many communities.\",\n",
    "]\n",
    "\n",
    "print(\"Sentence Stemming\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sentence in sentences:\n",
    "    stemmed = stem_sentence(sentence)\n",
    "    print(f\"\\nOriginal: {sentence}\")\n",
    "    print(f\"Stemmed:  {' '.join(stemmed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0866c8b",
   "metadata": {},
   "source": [
    "### Stemming for Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7495ad73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query: 'run' (stem: 'run')\n",
      "\n",
      "Matching documents:\n",
      "--------------------------------------------------\n",
      "\n",
      "‚úÖ Doc 1: The runner was running in the marathon.\n",
      "   Matched words: ['running']\n",
      "\n",
      "‚úÖ Doc 2: She runs every morning before work.\n",
      "   Matched words: ['runs']\n",
      "\n",
      "‚úÖ Doc 3: Running is good exercise for runners.\n",
      "   Matched words: ['running']\n",
      "\n",
      "‚ùå Doc 4: The car drove quickly down the street.\n"
     ]
    }
   ],
   "source": [
    "# Documents\n",
    "documents = [\n",
    "    \"The runner was running in the marathon.\",\n",
    "    \"She runs every morning before work.\",\n",
    "    \"Running is good exercise for runners.\",\n",
    "    \"The car drove quickly down the street.\",\n",
    "]\n",
    "\n",
    "# Search query\n",
    "query = \"run\"\n",
    "query_stem = ps.stem(query)\n",
    "\n",
    "print(f\"Search query: '{query}' (stem: '{query_stem}')\")\n",
    "print(\"\\nMatching documents:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    tokens = word_tokenize(doc.lower())\n",
    "    stems = [ps.stem(t) for t in tokens if t.isalpha()]\n",
    "    \n",
    "    if query_stem in stems:\n",
    "        # Find which words matched\n",
    "        matched = [t for t in tokens if t.isalpha() and ps.stem(t) == query_stem]\n",
    "        print(f\"\\n‚úÖ Doc {i}: {doc}\")\n",
    "        print(f\"   Matched words: {matched}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Doc {i}: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83bcc26",
   "metadata": {},
   "source": [
    "## 5.7 Stemmer Utility Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b84c3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stemmer:\n",
    "    \"\"\"Utility class for stemming operations\"\"\"\n",
    "    \n",
    "    STEMMERS = {\n",
    "        'porter': PorterStemmer,\n",
    "        'lancaster': LancasterStemmer,\n",
    "        'snowball': lambda: SnowballStemmer('english'),\n",
    "    }\n",
    "    \n",
    "    def __init__(self, stemmer_type='porter'):\n",
    "        if stemmer_type not in self.STEMMERS:\n",
    "            raise ValueError(f\"Unknown stemmer: {stemmer_type}\")\n",
    "        \n",
    "        creator = self.STEMMERS[stemmer_type]\n",
    "        self.stemmer = creator() if callable(creator) else creator\n",
    "        self.stemmer_type = stemmer_type\n",
    "    \n",
    "    def stem(self, word):\n",
    "        \"\"\"Stem a single word\"\"\"\n",
    "        return self.stemmer.stem(word)\n",
    "    \n",
    "    def stem_words(self, words):\n",
    "        \"\"\"Stem a list of words\"\"\"\n",
    "        return [self.stemmer.stem(w) for w in words]\n",
    "    \n",
    "    def stem_text(self, text):\n",
    "        \"\"\"Tokenize and stem text\"\"\"\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        return [self.stemmer.stem(t) for t in tokens if t.isalpha()]\n",
    "    \n",
    "    def stem_documents(self, documents):\n",
    "        \"\"\"Stem multiple documents\"\"\"\n",
    "        return [self.stem_text(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d49a98c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The programmers are programming different programs.\n",
      "\n",
      "Porter     ‚Üí ['the', 'programm', 'are', 'program', 'differ', 'program']\n",
      "Lancaster  ‚Üí ['the', 'program', 'ar', 'program', 'diff', 'program']\n",
      "Snowball   ‚Üí ['the', 'programm', 'are', 'program', 'differ', 'program']\n"
     ]
    }
   ],
   "source": [
    "# Use the utility class\n",
    "text = \"The programmers are programming different programs.\"\n",
    "\n",
    "print(f\"Text: {text}\\n\")\n",
    "\n",
    "for stype in ['porter', 'lancaster', 'snowball']:\n",
    "    stemmer = Stemmer(stype)\n",
    "    result = stemmer.stem_text(text)\n",
    "    print(f\"{stype.capitalize():<10} ‚Üí {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d1149e",
   "metadata": {},
   "source": [
    "## 5.8 When to Use Stemming\n",
    "\n",
    "### ‚úÖ Good Use Cases\n",
    "\n",
    "| Use Case | Why |\n",
    "|----------|-----|\n",
    "| **Information Retrieval / Search** | Match different word forms to same concept |\n",
    "| **Text Classification** | Reduce vocabulary size |\n",
    "| **Document Clustering** | Group similar documents |\n",
    "| **Quick Prototyping** | Faster than lemmatization |\n",
    "\n",
    "### ‚ùå Not Recommended For\n",
    "\n",
    "| Use Case | Why Not |\n",
    "|----------|--------|\n",
    "| **Sentiment Analysis** | Loses nuance (\"happy\" vs \"happily\") |\n",
    "| **Machine Translation** | Need exact word forms |\n",
    "| **Text Generation** | Stems aren't valid words |\n",
    "| **Named Entity Recognition** | Proper nouns shouldn't be stemmed |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006cc8c3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Stemmer | Aggressiveness | Speed | Multi-language |\n",
    "|---------|---------------|-------|----------------|\n",
    "| **Porter** | Medium | Fast | No |\n",
    "| **Lancaster** | High | Fast | No |\n",
    "| **Snowball** | Medium | Fast | Yes |\n",
    "| **Regexp** | Custom | Very Fast | Custom |\n",
    "\n",
    "### Quick Reference\n",
    "```python\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "ls = LancasterStemmer()\n",
    "ss = SnowballStemmer('english')\n",
    "\n",
    "ps.stem('running')  # 'run'\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
