{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60e5a230",
   "metadata": {},
   "source": [
    "# NLTK Complete Guide - Section 6: Lemmatization\n",
    "\n",
    "This notebook covers:\n",
    "- What is Lemmatization?\n",
    "- WordNet Lemmatizer\n",
    "- POS-aware Lemmatization\n",
    "- Stemming vs Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e29f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db5ce9",
   "metadata": {},
   "source": [
    "## 6.1 What is Lemmatization?\n",
    "\n",
    "**Lemmatization** reduces words to their dictionary form (lemma).\n",
    "\n",
    "| Word | Stem (Porter) | Lemma |\n",
    "|------|---------------|-------|\n",
    "| running | run | running/run |\n",
    "| better | better | good |\n",
    "| studies | studi | study |\n",
    "| geese | gees | goose |\n",
    "\n",
    "✅ **Lemmas are valid words** (unlike stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Basic lemmatization (defaults to noun)\n",
    "words = [\"cats\", \"dogs\", \"children\", \"mice\", \"geese\", \"feet\"]\n",
    "\n",
    "print(\"Basic Lemmatization (as nouns)\")\n",
    "print(\"=\" * 35)\n",
    "for word in words:\n",
    "    lemma = lemmatizer.lemmatize(word)\n",
    "    print(f\"{word:<15} → {lemma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4429e72d",
   "metadata": {},
   "source": [
    "## 6.2 Part of Speech Matters!\n",
    "\n",
    "Lemmatization needs the correct POS to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c5443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without POS (default = noun)\n",
    "word = \"running\"\n",
    "\n",
    "print(f\"Word: '{word}'\")\n",
    "print(f\"  As noun (default): {lemmatizer.lemmatize(word)}\")\n",
    "print(f\"  As verb:           {lemmatizer.lemmatize(word, pos='v')}\")\n",
    "print(f\"  As adjective:      {lemmatizer.lemmatize(word, pos='a')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261c730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More examples with POS\n",
    "examples = [\n",
    "    (\"running\", \"v\"),   # verb\n",
    "    (\"better\", \"a\"),    # adjective\n",
    "    (\"studies\", \"n\"),   # noun\n",
    "    (\"studies\", \"v\"),   # verb\n",
    "    (\"quickly\", \"r\"),   # adverb\n",
    "]\n",
    "\n",
    "print(\"POS-specific Lemmatization\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"{'Word':<15} {'POS':<10} {'Lemma':<15}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "pos_names = {'n': 'noun', 'v': 'verb', 'a': 'adjective', 'r': 'adverb'}\n",
    "\n",
    "for word, pos in examples:\n",
    "    lemma = lemmatizer.lemmatize(word, pos=pos)\n",
    "    print(f\"{word:<15} {pos_names[pos]:<10} {lemma:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a9abe1",
   "metadata": {},
   "source": [
    "## 6.3 WordNet POS Tags\n",
    "\n",
    "WordNet uses specific POS tags:\n",
    "- `n` = Noun\n",
    "- `v` = Verb\n",
    "- `a` = Adjective\n",
    "- `r` = Adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"Convert TreeBank POS tag to WordNet POS tag\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ      # 'a'\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB     # 'v'\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN     # 'n'\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV      # 'r'\n",
    "    else:\n",
    "        return wordnet.NOUN     # Default to noun\n",
    "\n",
    "# Test the conversion\n",
    "treebank_tags = ['NN', 'NNS', 'VB', 'VBG', 'JJ', 'JJR', 'RB', 'DT']\n",
    "\n",
    "print(\"TreeBank to WordNet POS Conversion\")\n",
    "print(\"-\" * 35)\n",
    "for tag in treebank_tags:\n",
    "    wn_tag = get_wordnet_pos(tag)\n",
    "    print(f\"{tag:<8} → {wn_tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad122b3",
   "metadata": {},
   "source": [
    "## 6.4 Automatic POS-aware Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edfd03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(sentence):\n",
    "    \"\"\"Lemmatize a sentence with automatic POS detection\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(sentence)\n",
    "    \n",
    "    # POS tag\n",
    "    tagged = pos_tag(tokens)\n",
    "    \n",
    "    # Lemmatize with correct POS\n",
    "    lemmas = []\n",
    "    for word, tag in tagged:\n",
    "        wn_pos = get_wordnet_pos(tag)\n",
    "        lemma = lemmatizer.lemmatize(word.lower(), pos=wn_pos)\n",
    "        lemmas.append(lemma)\n",
    "    \n",
    "    return lemmas, tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21889dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "\n",
    "lemmas, tagged = lemmatize_sentence(sentence)\n",
    "\n",
    "print(f\"Sentence: {sentence}\\n\")\n",
    "print(f\"{'Word':<12} {'POS':<6} {'Lemma':<12}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for (word, tag), lemma in zip(tagged, lemmas):\n",
    "    print(f\"{word:<12} {tag:<6} {lemma:<12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b0c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More examples\n",
    "sentences = [\n",
    "    \"The dogs are running quickly through the fields.\",\n",
    "    \"She studies better when the weather is good.\",\n",
    "    \"The children were playing happily in the garden.\",\n",
    "    \"He has been running marathons for years.\",\n",
    "]\n",
    "\n",
    "print(\"Sentence Lemmatization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sent in sentences:\n",
    "    lemmas, _ = lemmatize_sentence(sent)\n",
    "    print(f\"\\nOriginal:   {sent}\")\n",
    "    print(f\"Lemmatized: {' '.join(lemmas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1c5c96",
   "metadata": {},
   "source": [
    "## 6.5 Stemming vs Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b884c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words_with_pos = [\n",
    "    (\"running\", \"v\"),\n",
    "    (\"runs\", \"v\"),\n",
    "    (\"better\", \"a\"),\n",
    "    (\"studies\", \"v\"),\n",
    "    (\"studying\", \"v\"),\n",
    "    (\"feet\", \"n\"),\n",
    "    (\"geese\", \"n\"),\n",
    "    (\"happiness\", \"n\"),\n",
    "    (\"happily\", \"r\"),\n",
    "    (\"organization\", \"n\"),\n",
    "]\n",
    "\n",
    "print(\"Stemming vs Lemmatization\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Word':<15} {'Stem':<12} {'Lemma':<12} {'Valid?'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for word, pos in words_with_pos:\n",
    "    stem = ps.stem(word)\n",
    "    lemma = lemmatizer.lemmatize(word, pos=pos)\n",
    "    \n",
    "    # Check if stem is valid word (simple check using wordnet)\n",
    "    stem_valid = \"✅\" if wordnet.synsets(stem) else \"❌\"\n",
    "    lemma_valid = \"✅\" if wordnet.synsets(lemma) else \"❌\"\n",
    "    \n",
    "    print(f\"{word:<15} {stem:<12} {lemma:<12} Stem:{stem_valid} Lemma:{lemma_valid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce0253",
   "metadata": {},
   "source": [
    "### Key Differences\n",
    "\n",
    "| Aspect | Stemming | Lemmatization |\n",
    "|--------|----------|---------------|\n",
    "| **Output** | Root form (may not be valid word) | Dictionary form (valid word) |\n",
    "| **Speed** | Faster | Slower |\n",
    "| **Accuracy** | Less accurate | More accurate |\n",
    "| **Requires** | Just the word | Word + POS tag |\n",
    "| **\"better\"** | better | good |\n",
    "| **\"studies\"** | studi | study |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfce632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special cases where lemmatization excels\n",
    "special_cases = [\n",
    "    (\"better\", \"a\", \"good\"),      # Comparative adjective\n",
    "    (\"best\", \"a\", \"good\"),        # Superlative adjective\n",
    "    (\"worse\", \"a\", \"bad\"),        # Comparative\n",
    "    (\"went\", \"v\", \"go\"),          # Irregular past\n",
    "    (\"mice\", \"n\", \"mouse\"),       # Irregular plural\n",
    "    (\"geese\", \"n\", \"goose\"),      # Irregular plural\n",
    "    (\"feet\", \"n\", \"foot\"),        # Irregular plural\n",
    "    (\"children\", \"n\", \"child\"),   # Irregular plural\n",
    "]\n",
    "\n",
    "print(\"Special Cases (Lemmatization Wins!)\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Word':<12} {'Stem':<12} {'Lemma':<12} {'Expected':<12}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for word, pos, expected in special_cases:\n",
    "    stem = ps.stem(word)\n",
    "    lemma = lemmatizer.lemmatize(word, pos=pos)\n",
    "    match = \"✅\" if lemma == expected else \"❌\"\n",
    "    print(f\"{word:<12} {stem:<12} {lemma:<12} {expected:<12} {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c685fa91",
   "metadata": {},
   "source": [
    "## 6.6 Practical Lemmatization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf1e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "class TextLemmatizer:\n",
    "    \"\"\"Complete lemmatization pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, remove_stopwords=True, lowercase=True):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english')) if remove_stopwords else set()\n",
    "        self.lowercase = lowercase\n",
    "    \n",
    "    def get_wordnet_pos(self, tag):\n",
    "        \"\"\"Convert TreeBank tag to WordNet tag\"\"\"\n",
    "        if tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "    def lemmatize(self, text):\n",
    "        \"\"\"Lemmatize text with full pipeline\"\"\"\n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # POS tag\n",
    "        tagged = pos_tag(tokens)\n",
    "        \n",
    "        # Lemmatize\n",
    "        lemmas = []\n",
    "        for word, tag in tagged:\n",
    "            # Skip punctuation and stopwords\n",
    "            if word in string.punctuation:\n",
    "                continue\n",
    "            \n",
    "            word_lower = word.lower() if self.lowercase else word\n",
    "            \n",
    "            if word_lower in self.stop_words:\n",
    "                continue\n",
    "            \n",
    "            wn_pos = self.get_wordnet_pos(tag)\n",
    "            lemma = self.lemmatizer.lemmatize(word_lower, pos=wn_pos)\n",
    "            lemmas.append(lemma)\n",
    "        \n",
    "        return lemmas\n",
    "    \n",
    "    def lemmatize_batch(self, texts):\n",
    "        \"\"\"Lemmatize multiple texts\"\"\"\n",
    "        return [self.lemmatize(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a05ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pipeline\n",
    "lemmatizer_pipeline = TextLemmatizer(remove_stopwords=True)\n",
    "\n",
    "texts = [\n",
    "    \"The cats are running quickly through the beautiful gardens.\",\n",
    "    \"She has been studying machine learning for several years.\",\n",
    "    \"The children were happily playing with their new toys.\",\n",
    "]\n",
    "\n",
    "print(\"Lemmatization Pipeline Results\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for text in texts:\n",
    "    lemmas = lemmatizer_pipeline.lemmatize(text)\n",
    "    print(f\"\\nOriginal:   {text}\")\n",
    "    print(f\"Lemmatized: {lemmas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e12c2",
   "metadata": {},
   "source": [
    "## 6.7 When to Use What?\n",
    "\n",
    "### Use Stemming When:\n",
    "- Speed is critical\n",
    "- Working with search/IR systems\n",
    "- Exact word form doesn't matter\n",
    "- Quick prototyping\n",
    "\n",
    "### Use Lemmatization When:\n",
    "- Accuracy is important\n",
    "- Working with chatbots/NLU\n",
    "- Need valid dictionary words\n",
    "- Doing sentiment analysis\n",
    "- Text generation tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04af54f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Method | Code |\n",
    "|--------|------|\n",
    "| Create lemmatizer | `WordNetLemmatizer()` |\n",
    "| Lemmatize (noun) | `lemmatizer.lemmatize(word)` |\n",
    "| Lemmatize (verb) | `lemmatizer.lemmatize(word, pos='v')` |\n",
    "| Lemmatize (adj) | `lemmatizer.lemmatize(word, pos='a')` |\n",
    "| Lemmatize (adv) | `lemmatizer.lemmatize(word, pos='r')` |\n",
    "\n",
    "### WordNet POS Tags\n",
    "- `wordnet.NOUN` or `'n'`\n",
    "- `wordnet.VERB` or `'v'`\n",
    "- `wordnet.ADJ` or `'a'`\n",
    "- `wordnet.ADV` or `'r'`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
