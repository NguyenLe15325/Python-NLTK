{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89c8955",
   "metadata": {},
   "source": [
    "# NLTK Complete Guide - Section 7: Part-of-Speech (POS) Tagging\n",
    "\n",
    "This notebook covers:\n",
    "- What is POS Tagging?\n",
    "- NLTK POS Taggers\n",
    "- Penn Treebank Tag Set\n",
    "- Custom Taggers\n",
    "- Practical Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9b81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('tagsets', quiet=True)\n",
    "nltk.download('universal_tagset', quiet=True)\n",
    "nltk.download('brown', quiet=True)\n",
    "\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879207b0",
   "metadata": {},
   "source": [
    "## 7.1 What is POS Tagging?\n",
    "\n",
    "**Part-of-Speech (POS) Tagging** assigns grammatical categories to words:\n",
    "- Noun, Verb, Adjective, Adverb\n",
    "- Pronoun, Preposition, Conjunction\n",
    "- And more specific subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff8eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Tokenize and tag\n",
    "tokens = word_tokenize(sentence)\n",
    "tagged = pos_tag(tokens)\n",
    "\n",
    "print(f\"Sentence: {sentence}\\n\")\n",
    "print(\"POS Tags:\")\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85427d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print\n",
    "print(f\"{'Word':<12} {'Tag':<6} {'Description'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "tag_descriptions = {\n",
    "    'DT': 'Determiner',\n",
    "    'JJ': 'Adjective',\n",
    "    'NN': 'Noun (singular)',\n",
    "    'NNS': 'Noun (plural)',\n",
    "    'VBZ': 'Verb (3rd person singular)',\n",
    "    'IN': 'Preposition',\n",
    "    '.': 'Punctuation',\n",
    "}\n",
    "\n",
    "for word, tag in tagged:\n",
    "    desc = tag_descriptions.get(tag, 'Other')\n",
    "    print(f\"{word:<12} {tag:<6} {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a4c23b",
   "metadata": {},
   "source": [
    "## 7.2 Penn Treebank Tag Set\n",
    "\n",
    "NLTK uses the Penn Treebank tagset by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602e41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common POS tags\n",
    "common_tags = {\n",
    "    # Nouns\n",
    "    'NN': 'Noun, singular (dog, city)',\n",
    "    'NNS': 'Noun, plural (dogs, cities)',\n",
    "    'NNP': 'Proper noun, singular (John, London)',\n",
    "    'NNPS': 'Proper noun, plural (Americans)',\n",
    "    \n",
    "    # Verbs\n",
    "    'VB': 'Verb, base form (run, eat)',\n",
    "    'VBD': 'Verb, past tense (ran, ate)',\n",
    "    'VBG': 'Verb, gerund (running, eating)',\n",
    "    'VBN': 'Verb, past participle (eaten, written)',\n",
    "    'VBP': 'Verb, non-3rd person (run, eat)',\n",
    "    'VBZ': 'Verb, 3rd person singular (runs, eats)',\n",
    "    \n",
    "    # Adjectives\n",
    "    'JJ': 'Adjective (big, green)',\n",
    "    'JJR': 'Adjective, comparative (bigger)',\n",
    "    'JJS': 'Adjective, superlative (biggest)',\n",
    "    \n",
    "    # Adverbs\n",
    "    'RB': 'Adverb (quickly, very)',\n",
    "    'RBR': 'Adverb, comparative (faster)',\n",
    "    'RBS': 'Adverb, superlative (fastest)',\n",
    "    \n",
    "    # Others\n",
    "    'PRP': 'Personal pronoun (I, you, he)',\n",
    "    'PRP$': 'Possessive pronoun (my, your)',\n",
    "    'DT': 'Determiner (the, a, an)',\n",
    "    'IN': 'Preposition (in, on, at)',\n",
    "    'CC': 'Coordinating conjunction (and, or)',\n",
    "    'TO': 'to',\n",
    "    'MD': 'Modal (can, will, should)',\n",
    "}\n",
    "\n",
    "print(\"Common Penn Treebank POS Tags\")\n",
    "print(\"=\" * 60)\n",
    "for tag, description in common_tags.items():\n",
    "    print(f\"{tag:<6} {description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9694476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get help on a specific tag\n",
    "nltk.help.upenn_tagset('VBG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06acb7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All noun tags\n",
    "nltk.help.upenn_tagset('NN.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc86843",
   "metadata": {},
   "source": [
    "## 7.3 Universal Tagset\n",
    "\n",
    "Simplified tagset that works across languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5b7ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "tokens = word_tokenize(sentence)\n",
    "\n",
    "# Default (Penn Treebank)\n",
    "penn_tags = pos_tag(tokens)\n",
    "\n",
    "# Universal tagset\n",
    "universal_tags = pos_tag(tokens, tagset='universal')\n",
    "\n",
    "print(f\"{'Word':<12} {'Penn':<8} {'Universal':<10}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for (word, penn), (_, univ) in zip(penn_tags, universal_tags):\n",
    "    print(f\"{word:<12} {penn:<8} {univ:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f5f710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal tags\n",
    "universal_tagset = {\n",
    "    'NOUN': 'Nouns',\n",
    "    'VERB': 'Verbs',\n",
    "    'ADJ': 'Adjectives',\n",
    "    'ADV': 'Adverbs',\n",
    "    'PRON': 'Pronouns',\n",
    "    'DET': 'Determiners',\n",
    "    'ADP': 'Adpositions (prepositions)',\n",
    "    'NUM': 'Numbers',\n",
    "    'CONJ': 'Conjunctions',\n",
    "    'PRT': 'Particles',\n",
    "    '.': 'Punctuation',\n",
    "    'X': 'Other',\n",
    "}\n",
    "\n",
    "print(\"Universal Tagset\")\n",
    "print(\"=\" * 40)\n",
    "for tag, desc in universal_tagset.items():\n",
    "    print(f\"{tag:<8} {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa792027",
   "metadata": {},
   "source": [
    "## 7.4 Tagging Multiple Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e50080",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Natural language processing is fascinating.\n",
    "It enables computers to understand human language.\n",
    "Many applications use NLP today.\"\"\"\n",
    "\n",
    "# Method 1: Tag sentence by sentence\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "print(\"Method 1: Individual sentences\")\n",
    "print(\"=\" * 50)\n",
    "for sent in sentences:\n",
    "    tokens = word_tokenize(sent)\n",
    "    tagged = pos_tag(tokens)\n",
    "    print(f\"\\n{sent}\")\n",
    "    print(f\"Tags: {tagged}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d478701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Batch tagging (more efficient)\n",
    "tokenized_sents = [word_tokenize(s) for s in sentences]\n",
    "tagged_sents = pos_tag_sents(tokenized_sents)\n",
    "\n",
    "print(\"Method 2: Batch tagging (pos_tag_sents)\")\n",
    "print(\"=\" * 50)\n",
    "for i, tagged in enumerate(tagged_sents, 1):\n",
    "    print(f\"\\nSentence {i}: {tagged}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e5eeb",
   "metadata": {},
   "source": [
    "## 7.5 Context-Dependent POS\n",
    "\n",
    "The same word can have different POS tags depending on context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973df61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"book\" as noun vs verb\n",
    "sentences = [\n",
    "    \"I read a book.\",           # book = noun\n",
    "    \"Please book a table.\",     # book = verb\n",
    "]\n",
    "\n",
    "print(\"'book' in different contexts:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for sent in sentences:\n",
    "    tokens = word_tokenize(sent)\n",
    "    tagged = pos_tag(tokens)\n",
    "    book_tag = [t for w, t in tagged if w.lower() == 'book'][0]\n",
    "    print(f\"{sent:<30} book = {book_tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea491b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More examples of context-dependent tags\n",
    "ambiguous_examples = [\n",
    "    (\"I run every day.\", \"run\"),\n",
    "    (\"The run was exhausting.\", \"run\"),\n",
    "    (\"She can fish.\", \"fish\"),\n",
    "    (\"I caught a fish.\", \"fish\"),\n",
    "    (\"Light the candle.\", \"light\"),\n",
    "    (\"The light is bright.\", \"light\"),\n",
    "    (\"This box is light.\", \"light\"),\n",
    "]\n",
    "\n",
    "print(\"Context-Dependent POS Tags\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Sentence':<35} {'Word':<8} {'Tag'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for sent, target_word in ambiguous_examples:\n",
    "    tokens = word_tokenize(sent)\n",
    "    tagged = pos_tag(tokens)\n",
    "    word_tag = [t for w, t in tagged if w.lower() == target_word][0]\n",
    "    print(f\"{sent:<35} {target_word:<8} {word_tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904e5f2a",
   "metadata": {},
   "source": [
    "## 7.6 Extracting Words by POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_by_pos(text, target_tags):\n",
    "    \"\"\"Extract words with specific POS tags\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "    return [word for word, tag in tagged if tag in target_tags]\n",
    "\n",
    "text = \"\"\"The beautiful princess quickly ran through the dark forest.\n",
    "She was searching for her magical golden crown.\"\"\"\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "\n",
    "# Extract different parts of speech\n",
    "nouns = extract_by_pos(text, ['NN', 'NNS', 'NNP', 'NNPS'])\n",
    "verbs = extract_by_pos(text, ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'])\n",
    "adjectives = extract_by_pos(text, ['JJ', 'JJR', 'JJS'])\n",
    "adverbs = extract_by_pos(text, ['RB', 'RBR', 'RBS'])\n",
    "\n",
    "print(f\"\\nNouns: {nouns}\")\n",
    "print(f\"Verbs: {verbs}\")\n",
    "print(f\"Adjectives: {adjectives}\")\n",
    "print(f\"Adverbs: {adverbs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS distribution\n",
    "from collections import Counter\n",
    "\n",
    "def pos_distribution(text):\n",
    "    \"\"\"Get distribution of POS tags\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "    return Counter(tag for word, tag in tagged)\n",
    "\n",
    "text = \"\"\"Machine learning is transforming how computers understand and process \n",
    "human language. Natural language processing applications are becoming \n",
    "increasingly sophisticated and accurate.\"\"\"\n",
    "\n",
    "dist = pos_distribution(text)\n",
    "\n",
    "print(\"POS Tag Distribution\")\n",
    "print(\"=\" * 30)\n",
    "for tag, count in dist.most_common():\n",
    "    print(f\"{tag:<6} {count:>3} {'â–ˆ' * count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6038703",
   "metadata": {},
   "source": [
    "## 7.7 Custom POS Taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Get tagged sentences from Brown corpus\n",
    "brown_tagged = brown.tagged_sents(categories='news')\n",
    "\n",
    "# Split into train/test\n",
    "train_size = int(len(brown_tagged) * 0.8)\n",
    "train_sents = brown_tagged[:train_size]\n",
    "test_sents = brown_tagged[train_size:]\n",
    "\n",
    "print(f\"Training sentences: {len(train_sents)}\")\n",
    "print(f\"Test sentences: {len(test_sents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d43d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Tagger (assigns same tag to everything)\n",
    "default_tagger = DefaultTagger('NN')\n",
    "print(f\"Default Tagger accuracy: {default_tagger.accuracy(test_sents):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unigram Tagger (learns most common tag for each word)\n",
    "unigram_tagger = UnigramTagger(train_sents, backoff=default_tagger)\n",
    "print(f\"Unigram Tagger accuracy: {unigram_tagger.accuracy(test_sents):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ace359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram Tagger (considers previous word)\n",
    "bigram_tagger = BigramTagger(train_sents, backoff=unigram_tagger)\n",
    "print(f\"Bigram Tagger accuracy: {bigram_tagger.accuracy(test_sents):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60900df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigram Tagger (considers two previous words)\n",
    "trigram_tagger = TrigramTagger(train_sents, backoff=bigram_tagger)\n",
    "print(f\"Trigram Tagger accuracy: {trigram_tagger.accuracy(test_sents):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc09506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all taggers\n",
    "print(\"\\nTagger Comparison\")\n",
    "print(\"=\" * 35)\n",
    "taggers = [\n",
    "    (\"Default\", default_tagger),\n",
    "    (\"Unigram\", unigram_tagger),\n",
    "    (\"Bigram\", bigram_tagger),\n",
    "    (\"Trigram\", trigram_tagger),\n",
    "]\n",
    "\n",
    "for name, tagger in taggers:\n",
    "    acc = tagger.accuracy(test_sents)\n",
    "    print(f\"{name:<10} {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e50d2",
   "metadata": {},
   "source": [
    "## 7.8 Practical Application: Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8119087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text):\n",
    "    \"\"\"Comprehensive text analysis using POS tagging\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "    \n",
    "    # Count by category\n",
    "    categories = {\n",
    "        'Nouns': ['NN', 'NNS', 'NNP', 'NNPS'],\n",
    "        'Verbs': ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'],\n",
    "        'Adjectives': ['JJ', 'JJR', 'JJS'],\n",
    "        'Adverbs': ['RB', 'RBR', 'RBS'],\n",
    "        'Pronouns': ['PRP', 'PRP$', 'WP', 'WP$'],\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for category, tags in categories.items():\n",
    "        words = [w for w, t in tagged if t in tags]\n",
    "        results[category] = {\n",
    "            'count': len(words),\n",
    "            'words': words\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "text = \"\"\"The ambitious young scientist quickly discovered a remarkable \n",
    "breakthrough in artificial intelligence. She carefully analyzed the complex \n",
    "data and brilliantly solved the challenging problem.\"\"\"\n",
    "\n",
    "print(f\"Text: {text}\\n\")\n",
    "\n",
    "analysis = analyze_text(text)\n",
    "\n",
    "print(\"Text Analysis\")\n",
    "print(\"=\" * 50)\n",
    "for category, data in analysis.items():\n",
    "    print(f\"\\n{category} ({data['count']}):\")\n",
    "    print(f\"  {data['words']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac7898e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `pos_tag(tokens)` | Tag a list of tokens |\n",
    "| `pos_tag(tokens, tagset='universal')` | Use universal tagset |\n",
    "| `pos_tag_sents(list_of_sents)` | Batch tag multiple sentences |\n",
    "| `nltk.help.upenn_tagset('TAG')` | Get tag description |\n",
    "\n",
    "### Common Tags\n",
    "- **Nouns**: NN, NNS, NNP, NNPS\n",
    "- **Verbs**: VB, VBD, VBG, VBN, VBP, VBZ\n",
    "- **Adjectives**: JJ, JJR, JJS\n",
    "- **Adverbs**: RB, RBR, RBS"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
