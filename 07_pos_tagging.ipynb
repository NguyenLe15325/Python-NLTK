{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89c8955",
   "metadata": {},
   "source": [
    "# NLTK Complete Guide - Section 7: Part-of-Speech (POS) Tagging\n",
    "\n",
    "This notebook covers:\n",
    "- What is POS Tagging?\n",
    "- NLTK POS Taggers\n",
    "- Penn Treebank Tag Set\n",
    "- Custom Taggers\n",
    "- Practical Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9b81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('tagsets', quiet=True)\n",
    "nltk.download('universal_tagset', quiet=True)\n",
    "nltk.download('brown', quiet=True)\n",
    "\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879207b0",
   "metadata": {},
   "source": [
    "## 7.1 What is POS Tagging?\n",
    "\n",
    "**Part-of-Speech (POS) Tagging** assigns grammatical categories to words:\n",
    "- Noun, Verb, Adjective, Adverb\n",
    "- Pronoun, Preposition, Conjunction\n",
    "- And more specific subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff8eea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The quick brown fox jumps over the lazy dog.\n",
      "\n",
      "POS Tags:\n",
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Tokenize and tag\n",
    "tokens = word_tokenize(sentence)\n",
    "tagged = pos_tag(tokens)\n",
    "\n",
    "print(f\"Sentence: {sentence}\\n\")\n",
    "print(\"POS Tags:\")\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85427d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word         Tag    Description\n",
      "--------------------------------------------------\n",
      "The          DT     Determiner\n",
      "quick        JJ     Adjective\n",
      "brown        NN     Noun (singular)\n",
      "fox          NN     Noun (singular)\n",
      "jumps        VBZ    Verb (3rd person singular)\n",
      "over         IN     Preposition\n",
      "the          DT     Determiner\n",
      "lazy         JJ     Adjective\n",
      "dog          NN     Noun (singular)\n",
      ".            .      Punctuation\n"
     ]
    }
   ],
   "source": [
    "# Pretty print\n",
    "print(f\"{'Word':<12} {'Tag':<6} {'Description'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "tag_descriptions = {\n",
    "    'DT': 'Determiner',\n",
    "    'JJ': 'Adjective',\n",
    "    'NN': 'Noun (singular)',\n",
    "    'NNS': 'Noun (plural)',\n",
    "    'VBZ': 'Verb (3rd person singular)',\n",
    "    'IN': 'Preposition',\n",
    "    '.': 'Punctuation',\n",
    "}\n",
    "\n",
    "for word, tag in tagged:\n",
    "    desc = tag_descriptions.get(tag, 'Other')\n",
    "    print(f\"{word:<12} {tag:<6} {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a4c23b",
   "metadata": {},
   "source": [
    "## 7.2 Penn Treebank Tag Set\n",
    "\n",
    "NLTK uses the Penn Treebank tagset by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4602e41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Penn Treebank POS Tags\n",
      "============================================================\n",
      "NN     Noun, singular (dog, city)\n",
      "NNS    Noun, plural (dogs, cities)\n",
      "NNP    Proper noun, singular (John, London)\n",
      "NNPS   Proper noun, plural (Americans)\n",
      "VB     Verb, base form (run, eat)\n",
      "VBD    Verb, past tense (ran, ate)\n",
      "VBG    Verb, gerund (running, eating)\n",
      "VBN    Verb, past participle (eaten, written)\n",
      "VBP    Verb, non-3rd person (run, eat)\n",
      "VBZ    Verb, 3rd person singular (runs, eats)\n",
      "JJ     Adjective (big, green)\n",
      "JJR    Adjective, comparative (bigger)\n",
      "JJS    Adjective, superlative (biggest)\n",
      "RB     Adverb (quickly, very)\n",
      "RBR    Adverb, comparative (faster)\n",
      "RBS    Adverb, superlative (fastest)\n",
      "PRP    Personal pronoun (I, you, he)\n",
      "PRP$   Possessive pronoun (my, your)\n",
      "DT     Determiner (the, a, an)\n",
      "IN     Preposition (in, on, at)\n",
      "CC     Coordinating conjunction (and, or)\n",
      "TO     to\n",
      "MD     Modal (can, will, should)\n"
     ]
    }
   ],
   "source": [
    "# Common POS tags\n",
    "common_tags = {\n",
    "    # Nouns\n",
    "    'NN': 'Noun, singular (dog, city)',\n",
    "    'NNS': 'Noun, plural (dogs, cities)',\n",
    "    'NNP': 'Proper noun, singular (John, London)',\n",
    "    'NNPS': 'Proper noun, plural (Americans)',\n",
    "    \n",
    "    # Verbs\n",
    "    'VB': 'Verb, base form (run, eat)',\n",
    "    'VBD': 'Verb, past tense (ran, ate)',\n",
    "    'VBG': 'Verb, gerund (running, eating)',\n",
    "    'VBN': 'Verb, past participle (eaten, written)',\n",
    "    'VBP': 'Verb, non-3rd person (run, eat)',\n",
    "    'VBZ': 'Verb, 3rd person singular (runs, eats)',\n",
    "    \n",
    "    # Adjectives\n",
    "    'JJ': 'Adjective (big, green)',\n",
    "    'JJR': 'Adjective, comparative (bigger)',\n",
    "    'JJS': 'Adjective, superlative (biggest)',\n",
    "    \n",
    "    # Adverbs\n",
    "    'RB': 'Adverb (quickly, very)',\n",
    "    'RBR': 'Adverb, comparative (faster)',\n",
    "    'RBS': 'Adverb, superlative (fastest)',\n",
    "    \n",
    "    # Others\n",
    "    'PRP': 'Personal pronoun (I, you, he)',\n",
    "    'PRP$': 'Possessive pronoun (my, your)',\n",
    "    'DT': 'Determiner (the, a, an)',\n",
    "    'IN': 'Preposition (in, on, at)',\n",
    "    'CC': 'Coordinating conjunction (and, or)',\n",
    "    'TO': 'to',\n",
    "    'MD': 'Modal (can, will, should)',\n",
    "}\n",
    "\n",
    "print(\"Common Penn Treebank POS Tags\")\n",
    "print(\"=\" * 60)\n",
    "for tag, description in common_tags.items():\n",
    "    print(f\"{tag:<6} {description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9694476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n"
     ]
    }
   ],
   "source": [
    "# Get help on a specific tag\n",
    "nltk.help.upenn_tagset('VBG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06acb7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n"
     ]
    }
   ],
   "source": [
    "# All noun tags\n",
    "nltk.help.upenn_tagset('NN.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc86843",
   "metadata": {},
   "source": [
    "## 7.3 Universal Tagset\n",
    "\n",
    "Simplified tagset that works across languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5b7ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word         Penn     Universal \n",
      "-----------------------------------\n",
      "The          DT       DET       \n",
      "quick        JJ       ADJ       \n",
      "brown        NN       NOUN      \n",
      "fox          NN       NOUN      \n",
      "jumps        VBZ      VERB      \n",
      "over         IN       ADP       \n",
      "the          DT       DET       \n",
      "lazy         JJ       ADJ       \n",
      "dog          NN       NOUN      \n",
      ".            .        .         \n"
     ]
    }
   ],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "tokens = word_tokenize(sentence)\n",
    "\n",
    "# Default (Penn Treebank)\n",
    "penn_tags = pos_tag(tokens)\n",
    "\n",
    "# Universal tagset\n",
    "universal_tags = pos_tag(tokens, tagset='universal')\n",
    "\n",
    "print(f\"{'Word':<12} {'Penn':<8} {'Universal':<10}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for (word, penn), (_, univ) in zip(penn_tags, universal_tags):\n",
    "    print(f\"{word:<12} {penn:<8} {univ:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f5f710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universal Tagset\n",
      "========================================\n",
      "NOUN     Nouns\n",
      "VERB     Verbs\n",
      "ADJ      Adjectives\n",
      "ADV      Adverbs\n",
      "PRON     Pronouns\n",
      "DET      Determiners\n",
      "ADP      Adpositions (prepositions)\n",
      "NUM      Numbers\n",
      "CONJ     Conjunctions\n",
      "PRT      Particles\n",
      ".        Punctuation\n",
      "X        Other\n"
     ]
    }
   ],
   "source": [
    "# Universal tags\n",
    "universal_tagset = {\n",
    "    'NOUN': 'Nouns',\n",
    "    'VERB': 'Verbs',\n",
    "    'ADJ': 'Adjectives',\n",
    "    'ADV': 'Adverbs',\n",
    "    'PRON': 'Pronouns',\n",
    "    'DET': 'Determiners',\n",
    "    'ADP': 'Adpositions (prepositions)',\n",
    "    'NUM': 'Numbers',\n",
    "    'CONJ': 'Conjunctions',\n",
    "    'PRT': 'Particles',\n",
    "    '.': 'Punctuation',\n",
    "    'X': 'Other',\n",
    "}\n",
    "\n",
    "print(\"Universal Tagset\")\n",
    "print(\"=\" * 40)\n",
    "for tag, desc in universal_tagset.items():\n",
    "    print(f\"{tag:<8} {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa792027",
   "metadata": {},
   "source": [
    "## 7.4 Tagging Multiple Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44e50080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1: Individual sentences\n",
      "==================================================\n",
      "\n",
      "Natural language processing is fascinating.\n",
      "Tags: [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('is', 'VBZ'), ('fascinating', 'VBG'), ('.', '.')]\n",
      "\n",
      "It enables computers to understand human language.\n",
      "Tags: [('It', 'PRP'), ('enables', 'VBZ'), ('computers', 'NNS'), ('to', 'TO'), ('understand', 'VB'), ('human', 'JJ'), ('language', 'NN'), ('.', '.')]\n",
      "\n",
      "Many applications use NLP today.\n",
      "Tags: [('Many', 'JJ'), ('applications', 'NNS'), ('use', 'VBP'), ('NLP', 'NNP'), ('today', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Natural language processing is fascinating.\n",
    "It enables computers to understand human language.\n",
    "Many applications use NLP today.\"\"\"\n",
    "\n",
    "# Method 1: Tag sentence by sentence\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "print(\"Method 1: Individual sentences\")\n",
    "print(\"=\" * 50)\n",
    "for sent in sentences:\n",
    "    tokens = word_tokenize(sent)\n",
    "    tagged = pos_tag(tokens)\n",
    "    print(f\"\\n{sent}\")\n",
    "    print(f\"Tags: {tagged}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d478701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 2: Batch tagging (pos_tag_sents)\n",
      "==================================================\n",
      "\n",
      "Sentence 1: [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('is', 'VBZ'), ('fascinating', 'VBG'), ('.', '.')]\n",
      "\n",
      "Sentence 2: [('It', 'PRP'), ('enables', 'VBZ'), ('computers', 'NNS'), ('to', 'TO'), ('understand', 'VB'), ('human', 'JJ'), ('language', 'NN'), ('.', '.')]\n",
      "\n",
      "Sentence 3: [('Many', 'JJ'), ('applications', 'NNS'), ('use', 'VBP'), ('NLP', 'NNP'), ('today', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Batch tagging (more efficient)\n",
    "tokenized_sents = [word_tokenize(s) for s in sentences]\n",
    "tagged_sents = pos_tag_sents(tokenized_sents)\n",
    "\n",
    "print(\"Method 2: Batch tagging (pos_tag_sents)\")\n",
    "print(\"=\" * 50)\n",
    "for i, tagged in enumerate(tagged_sents, 1):\n",
    "    print(f\"\\nSentence {i}: {tagged}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e5eeb",
   "metadata": {},
   "source": [
    "## 7.5 Context-Dependent POS\n",
    "\n",
    "The same word can have different POS tags depending on context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "973df61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'book' in different contexts:\n",
      "----------------------------------------\n",
      "I read a book.                 book = NN\n",
      "Please book a table.           book = NN\n"
     ]
    }
   ],
   "source": [
    "# \"book\" as noun vs verb\n",
    "sentences = [\n",
    "    \"I read a book.\",           # book = noun\n",
    "    \"Please book a table.\",     # book = verb\n",
    "]\n",
    "\n",
    "print(\"'book' in different contexts:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for sent in sentences:\n",
    "    tokens = word_tokenize(sent)\n",
    "    tagged = pos_tag(tokens)\n",
    "    book_tag = [t for w, t in tagged if w.lower() == 'book'][0]\n",
    "    print(f\"{sent:<30} book = {book_tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea491b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context-Dependent POS Tags\n",
      "=======================================================\n",
      "Sentence                            Word     Tag\n",
      "-------------------------------------------------------\n",
      "I run every day.                    run      VBP\n",
      "The run was exhausting.             run      NN\n",
      "She can fish.                       fish     VB\n",
      "I caught a fish.                    fish     NN\n",
      "Light the candle.                   light    NNP\n",
      "The light is bright.                light    NN\n",
      "This box is light.                  light    JJ\n"
     ]
    }
   ],
   "source": [
    "# More examples of context-dependent tags\n",
    "ambiguous_examples = [\n",
    "    (\"I run every day.\", \"run\"),\n",
    "    (\"The run was exhausting.\", \"run\"),\n",
    "    (\"She can fish.\", \"fish\"),\n",
    "    (\"I caught a fish.\", \"fish\"),\n",
    "    (\"Light the candle.\", \"light\"),\n",
    "    (\"The light is bright.\", \"light\"),\n",
    "    (\"This box is light.\", \"light\"),\n",
    "]\n",
    "\n",
    "print(\"Context-Dependent POS Tags\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Sentence':<35} {'Word':<8} {'Tag'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for sent, target_word in ambiguous_examples:\n",
    "    tokens = word_tokenize(sent)\n",
    "    tagged = pos_tag(tokens)\n",
    "    word_tag = [t for w, t in tagged if w.lower() == target_word][0]\n",
    "    print(f\"{sent:<35} {target_word:<8} {word_tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f017e58",
   "metadata": {},
   "source": [
    "### âš ï¸ Note: Why Some Tags May Be Wrong\n",
    "\n",
    "You may notice that **\"Light the candle\"** tags `light` as `NNP` (proper noun) instead of `VB` (verb). This is a **tagger error** that reveals how POS tagging works under the hood.\n",
    "\n",
    "---\n",
    "\n",
    "## How POS Tagging Works Under the Hood\n",
    "\n",
    "### 1. **Statistical/Probabilistic Approach**\n",
    "\n",
    "NLTK's default tagger (`averaged_perceptron_tagger`) is a **machine learning model** trained on labeled data. It doesn't \"understand\" languageâ€”it makes **statistical predictions** based on patterns learned during training.\n",
    "\n",
    "The tagger calculates:\n",
    "```\n",
    "P(tag | word, context) = probability of a tag given the word and surrounding context\n",
    "```\n",
    "\n",
    "### 2. **Features Used by the Tagger**\n",
    "\n",
    "The perceptron tagger considers multiple **features**:\n",
    "\n",
    "| Feature | Example | Why It Matters |\n",
    "|---------|---------|----------------|\n",
    "| **Current word** | \"light\" | Some words strongly predict certain tags |\n",
    "| **Word suffix** | \"-ing\", \"-ed\", \"-ly\" | Suffixes indicate verb forms, adverbs |\n",
    "| **Word prefix** | \"un-\", \"pre-\" | Can indicate adjectives or verbs |\n",
    "| **Previous tag** | DT â†’ likely NN/JJ next | Tag sequences follow patterns |\n",
    "| **Previous word** | \"the\" before noun | Determiners precede nouns |\n",
    "| **Capitalization** | \"Light\" vs \"light\" | Capitals often indicate proper nouns |\n",
    "| **Word shape** | all caps, mixed case | Helps identify special tokens |\n",
    "\n",
    "### 3. **Why Errors Occur**\n",
    "\n",
    "**Problem 1: Capitalization Bias**\n",
    "- \"Light\" at sentence start is capitalized\n",
    "- Training data has many capitalized proper nouns (names, places)\n",
    "- Tagger may incorrectly associate capitalization with NNP\n",
    "\n",
    "**Problem 2: Ambiguity**\n",
    "- \"light\" can be: noun, verb, or adjective\n",
    "- Without strong contextual signals, the tagger guesses based on training statistics\n",
    "\n",
    "**Problem 3: Training Data Distribution**\n",
    "- If \"light\" appears more often as noun/adjective in training data\n",
    "- The model may be biased toward those tags\n",
    "\n",
    "### 4. **The Tagging Algorithm (Simplified)**\n",
    "\n",
    "```\n",
    "For each word in sentence:\n",
    "    1. Extract features (word, suffix, previous tag, etc.)\n",
    "    2. Calculate score for each possible tag\n",
    "    3. Select tag with highest score\n",
    "    4. Move to next word (using this tag as \"previous tag\")\n",
    "```\n",
    "\n",
    "This is a **greedy left-to-right** approachâ€”early mistakes can cascade!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f71fe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect of Capitalization on POS Tagging\n",
      "=======================================================\n",
      "Sentence                       Word       Tag    Expected\n",
      "-------------------------------------------------------\n",
      "Light the candle.              Light      NNP    VB âœ—\n",
      "light the candle.              light      NN     VB âœ—\n",
      "Please light the candle.       light      VBD    VB âœ—\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating why \"Light\" gets tagged as NNP\n",
    "\n",
    "# Case sensitivity matters!\n",
    "examples = [\n",
    "    \"Light the candle.\",      # Capitalized (sentence start)\n",
    "    \"light the candle.\",      # Lowercase\n",
    "    \"Please light the candle.\", # \"light\" not at start\n",
    "]\n",
    "\n",
    "print(\"Effect of Capitalization on POS Tagging\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Sentence':<30} {'Word':<10} {'Tag':<6} {'Expected'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for sent in examples:\n",
    "    tokens = word_tokenize(sent)\n",
    "    tagged = pos_tag(tokens)\n",
    "    \n",
    "    # Find 'light' tag\n",
    "    for word, tag in tagged:\n",
    "        if word.lower() == 'light':\n",
    "            expected = 'VB'\n",
    "            status = 'âœ“' if tag == 'VB' else 'âœ—'\n",
    "            print(f\"{sent:<30} {word:<10} {tag:<6} {expected} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfbe2c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How Context Influences POS Decisions\n",
      "=================================================================\n",
      "Sentence                       Target   Actual   Expected Match\n",
      "-----------------------------------------------------------------\n",
      "I will light the fire.         light    VB       VB       âœ“\n",
      "The light is dim.              light    NN       NN       âœ“\n",
      "It feels light.                light    NN       JJ       âœ—\n",
      "Turn on the light.             light    NN       NN       âœ“\n"
     ]
    }
   ],
   "source": [
    "# Looking at what features influence tagging decisions\n",
    "# Let's examine how context changes predictions\n",
    "\n",
    "print(\"How Context Influences POS Decisions\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "context_examples = [\n",
    "    # Different preceding words change the prediction\n",
    "    (\"I will light the fire.\", \"light\", \"VB\"),      # Modal 'will' â†’ verb expected\n",
    "    (\"The light is dim.\", \"light\", \"NN\"),           # Determiner 'the' â†’ noun expected  \n",
    "    (\"It feels light.\", \"light\", \"JJ\"),             # 'feels' + adj pattern\n",
    "    (\"Turn on the light.\", \"light\", \"NN\"),          # 'the' + noun pattern\n",
    "]\n",
    "\n",
    "print(f\"{'Sentence':<30} {'Target':<8} {'Actual':<8} {'Expected':<8} {'Match'}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for sent, target, expected in context_examples:\n",
    "    tokens = word_tokenize(sent)\n",
    "    tagged = pos_tag(tokens)\n",
    "    actual = [t for w, t in tagged if w.lower() == target.lower()][0]\n",
    "    match = 'âœ“' if actual == expected else 'âœ—'\n",
    "    print(f\"{sent:<30} {target:<8} {actual:<8} {expected:<8} {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17123c8b",
   "metadata": {},
   "source": [
    "### 5. **Understanding Tagger Limitations**\n",
    "\n",
    "| Limitation | Description | Example |\n",
    "|------------|-------------|---------|\n",
    "| **Sentence-initial capitalization** | Words at start look like proper nouns | \"Light the fire\" â†’ Light=NNP âœ— |\n",
    "| **Rare word forms** | Unseen words rely on suffix/shape | Neologisms may be mistagged |\n",
    "| **Garden path sentences** | Ambiguous structure confuses tagger | \"The horse raced past the barn fell\" |\n",
    "| **Domain mismatch** | Trained on news, tested on tweets | Technical jargon may fail |\n",
    "\n",
    "### 6. **Ways to Improve Accuracy**\n",
    "\n",
    "1. **Lowercase sentence-initial words** (if appropriate)\n",
    "2. **Use domain-specific models** for specialized text\n",
    "3. **Combine with other NLP** (NER, parsing) for disambiguation\n",
    "4. **Fine-tune on your data** for better domain accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81b1edf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Dive: Why 'light' is Hard to Tag Correctly\n",
      "=================================================================\n",
      "Sentence                       Actual   Expected\n",
      "-----------------------------------------------------------------\n",
      "Light the candle.              NNP      VB (imperative verb)\n",
      "light the candle.              NN       VB (imperative verb)\n",
      "Please light the candle.       VBD      VB (verb)\n",
      "Can you light the candle?      VB       VB (verb)\n",
      "I will light the candle.       VB       VB (verb)\n",
      "\n",
      "=================================================================\n",
      "KEY INSIGHT: The tagger struggles with IMPERATIVE sentences!\n",
      "Without a clear subject, it can't identify 'light' as a verb.\n",
      "Adding modal verbs (will, can) provides context â†’ correct VB tag.\n"
     ]
    }
   ],
   "source": [
    "# Examining the tagger's behavior more closely\n",
    "# The perceptron tagger has specific biases we can observe\n",
    "\n",
    "print(\"Deep Dive: Why 'light' is Hard to Tag Correctly\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "problematic = [\n",
    "    (\"Light the candle.\", \"light\", \"VB (imperative verb)\"),\n",
    "    (\"light the candle.\", \"light\", \"VB (imperative verb)\"),\n",
    "    (\"Please light the candle.\", \"light\", \"VB (verb)\"),\n",
    "    (\"Can you light the candle?\", \"light\", \"VB (verb)\"),\n",
    "    (\"I will light the candle.\", \"light\", \"VB (verb)\"),\n",
    "]\n",
    "\n",
    "print(f\"{'Sentence':<30} {'Actual':<8} {'Expected'}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for sent, target, expected in problematic:\n",
    "    tokens = word_tokenize(sent)\n",
    "    tagged = pos_tag(tokens)\n",
    "    actual = [t for w, t in tagged if w.lower() == target][0]\n",
    "    print(f\"{sent:<30} {actual:<8} {expected}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"KEY INSIGHT: The tagger struggles with IMPERATIVE sentences!\")\n",
    "print(\"Without a clear subject, it can't identify 'light' as a verb.\")\n",
    "print(\"Adding modal verbs (will, can) provides context â†’ correct VB tag.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19253a0b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Deep Dive: What the Tagger Actually Looks At\n",
    "\n",
    "### The Chicken-and-Egg Problem\n",
    "\n",
    "You might wonder: *\"If the tagger uses neighboring POS tags, but those neighbors are also ambiguous, how does it decide?\"*\n",
    "\n",
    "**Answer: It processes LEFT-TO-RIGHT and only uses PREVIOUS tags (already decided), never FUTURE tags.**\n",
    "\n",
    "```\n",
    "Sentence:  \"The    light    is    bright\"\n",
    "            â†“       â†“       â†“      â†“\n",
    "Step 1:    DT      ???     ???    ???   (tag \"The\" first)\n",
    "Step 2:    DT  â†’   NN      ???    ???   (use DT to help tag \"light\")\n",
    "Step 3:    DT      NN  â†’   VBZ    ???   (use NN to help tag \"is\")\n",
    "Step 4:    DT      NN      VBZ â†’  JJ    (use VBZ to help tag \"bright\")\n",
    "```\n",
    "\n",
    "This is called **greedy left-to-right decoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34890024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'Light the candle'\n",
      "================================================================================\n",
      "\n",
      "Step-by-step feature extraction (LEFT â†’ RIGHT):\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "STEP 1: Tagging word 'Light' at position 0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“‹ FEATURES EXTRACTED:\n",
      "\n",
      "  Word-based features:\n",
      "    word: 'Light'\n",
      "    word.lower(): 'light'\n",
      "    suffix(-3): 'ght'\n",
      "    prefix(3): 'Lig'\n",
      "\n",
      "  Shape features:\n",
      "    is_capitalized: True\n",
      "    is_all_caps: False\n",
      "    is_first_word: True\n",
      "\n",
      "  Context features (ALREADY KNOWN):\n",
      "    prev_word: '<START>'\n",
      "    prev_tag:  '<START>'  â† Already decided!\n",
      "    next_word: 'the' (word known, tag unknown)\n",
      "\n",
      "  ğŸ¯ PREDICTION: 'Light' â†’ NNP\n",
      "     Tags so far: [('Light', 'NNP')]\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "STEP 2: Tagging word 'the' at position 1\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“‹ FEATURES EXTRACTED:\n",
      "\n",
      "  Word-based features:\n",
      "    word: 'the'\n",
      "    word.lower(): 'the'\n",
      "    suffix(-3): 'the'\n",
      "    prefix(3): 'the'\n",
      "\n",
      "  Shape features:\n",
      "    is_capitalized: False\n",
      "    is_all_caps: False\n",
      "    is_first_word: False\n",
      "\n",
      "  Context features (ALREADY KNOWN):\n",
      "    prev_word: 'Light'\n",
      "    prev_tag:  'NNP'  â† Already decided!\n",
      "    next_word: 'candle' (word known, tag unknown)\n",
      "\n",
      "  ğŸ¯ PREDICTION: 'the' â†’ DT\n",
      "     Tags so far: [('Light', 'NNP'), ('the', 'DT')]\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "STEP 3: Tagging word 'candle' at position 2\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“‹ FEATURES EXTRACTED:\n",
      "\n",
      "  Word-based features:\n",
      "    word: 'candle'\n",
      "    word.lower(): 'candle'\n",
      "    suffix(-3): 'dle'\n",
      "    prefix(3): 'can'\n",
      "\n",
      "  Shape features:\n",
      "    is_capitalized: False\n",
      "    is_all_caps: False\n",
      "    is_first_word: False\n",
      "\n",
      "  Context features (ALREADY KNOWN):\n",
      "    prev_word: 'the'\n",
      "    prev_tag:  'DT'  â† Already decided!\n",
      "    next_word: '<END>' (word known, tag unknown)\n",
      "\n",
      "  ğŸ¯ PREDICTION: 'candle' â†’ NN\n",
      "     Tags so far: [('Light', 'NNP'), ('the', 'DT'), ('candle', 'NN')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Light', 'NNP'), ('the', 'DT'), ('candle', 'NN')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's visualize exactly what features the tagger extracts for each word\n",
    "# This simulates the actual feature extraction process\n",
    "\n",
    "def show_tagger_features(sentence):\n",
    "    \"\"\"\n",
    "    Simulate the features that NLTK's averaged perceptron tagger extracts.\n",
    "    Based on the actual implementation in nltk/tag/perceptron.py\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(sentence)\n",
    "    \n",
    "    print(f\"Sentence: '{sentence}'\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nStep-by-step feature extraction (LEFT â†’ RIGHT):\\n\")\n",
    "    \n",
    "    # Simulate left-to-right tagging\n",
    "    predicted_tags = []\n",
    "    \n",
    "    for i, word in enumerate(tokens):\n",
    "        print(f\"{'â”€' * 80}\")\n",
    "        print(f\"STEP {i+1}: Tagging word '{word}' at position {i}\")\n",
    "        print(f\"{'â”€' * 80}\")\n",
    "        \n",
    "        # Features the tagger actually uses:\n",
    "        features = {}\n",
    "        \n",
    "        # 1. Word features\n",
    "        features['word'] = word\n",
    "        features['word.lower()'] = word.lower()\n",
    "        features['suffix(-3)'] = word[-3:] if len(word) >= 3 else word\n",
    "        features['suffix(-2)'] = word[-2:] if len(word) >= 2 else word\n",
    "        features['suffix(-1)'] = word[-1:] if len(word) >= 1 else word\n",
    "        features['prefix(1)'] = word[0] if len(word) >= 1 else ''\n",
    "        features['prefix(2)'] = word[:2] if len(word) >= 2 else word\n",
    "        features['prefix(3)'] = word[:3] if len(word) >= 3 else word\n",
    "        \n",
    "        # 2. Word shape features\n",
    "        features['is_capitalized'] = word[0].isupper() if word else False\n",
    "        features['is_all_caps'] = word.isupper()\n",
    "        features['is_all_lower'] = word.islower()\n",
    "        features['has_digit'] = any(c.isdigit() for c in word)\n",
    "        features['has_hyphen'] = '-' in word\n",
    "        \n",
    "        # 3. Position features\n",
    "        features['is_first_word'] = (i == 0)\n",
    "        features['is_last_word'] = (i == len(tokens) - 1)\n",
    "        \n",
    "        # 4. Context features (PREVIOUS words - already known!)\n",
    "        features['prev_word'] = tokens[i-1] if i > 0 else '<START>'\n",
    "        features['prev_word(-2)'] = tokens[i-2] if i > 1 else '<START>'\n",
    "        \n",
    "        # 5. PREVIOUS TAG features (already decided in earlier steps!)\n",
    "        features['prev_tag'] = predicted_tags[i-1] if i > 0 else '<START>'\n",
    "        features['prev_tag(-2)'] = predicted_tags[i-2] if i > 1 else '<START>'\n",
    "        \n",
    "        # 6. Next word (lookahead - words are known, but NOT their tags!)\n",
    "        features['next_word'] = tokens[i+1] if i < len(tokens)-1 else '<END>'\n",
    "        \n",
    "        # Print features\n",
    "        print(\"\\nğŸ“‹ FEATURES EXTRACTED:\")\n",
    "        print(\"\\n  Word-based features:\")\n",
    "        for k in ['word', 'word.lower()', 'suffix(-3)', 'prefix(3)']:\n",
    "            print(f\"    {k}: '{features[k]}'\")\n",
    "        \n",
    "        print(\"\\n  Shape features:\")\n",
    "        for k in ['is_capitalized', 'is_all_caps', 'is_first_word']:\n",
    "            print(f\"    {k}: {features[k]}\")\n",
    "        \n",
    "        print(\"\\n  Context features (ALREADY KNOWN):\")\n",
    "        print(f\"    prev_word: '{features['prev_word']}'\")\n",
    "        print(f\"    prev_tag:  '{features['prev_tag']}'  â† Already decided!\")\n",
    "        print(f\"    next_word: '{features['next_word']}' (word known, tag unknown)\")\n",
    "        \n",
    "        # Get actual prediction\n",
    "        actual_tags = pos_tag(tokens)\n",
    "        current_tag = actual_tags[i][1]\n",
    "        predicted_tags.append(current_tag)\n",
    "        \n",
    "        print(f\"\\n  ğŸ¯ PREDICTION: '{word}' â†’ {current_tag}\")\n",
    "        print(f\"     Tags so far: {list(zip(tokens[:i+1], predicted_tags))}\")\n",
    "    \n",
    "    return list(zip(tokens, predicted_tags))\n",
    "\n",
    "# Run the visualization\n",
    "show_tagger_features(\"Light the candle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c93e87fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How Previous Tags Cascade Through the Sentence\n",
      "======================================================================\n",
      "\n",
      "'The light is bright'\n",
      "--------------------------------------------------\n",
      "Step   Word       Prev Tag     â†’ Current Tag\n",
      "--------------------------------------------------\n",
      "1      The        <START>      â†’ DT\n",
      "2      light      DT           â†’ NN\n",
      "3      is         NN           â†’ VBZ\n",
      "4      bright     VBZ          â†’ JJ\n",
      "\n",
      "'I will light the candle'\n",
      "--------------------------------------------------\n",
      "Step   Word       Prev Tag     â†’ Current Tag\n",
      "--------------------------------------------------\n",
      "1      I          <START>      â†’ PRP\n",
      "2      will       PRP          â†’ MD\n",
      "3      light      MD           â†’ VB\n",
      "4      the        VB           â†’ DT\n",
      "5      candle     DT           â†’ NN\n",
      "\n",
      "======================================================================\n",
      "NOTICE: Each tag decision uses the PREVIOUS tag as a feature!\n",
      "The tagger never looks at FUTURE tags (they don't exist yet).\n"
     ]
    }
   ],
   "source": [
    "# Compare how PREVIOUS TAG influences decisions\n",
    "print(\"How Previous Tags Cascade Through the Sentence\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "examples = [\n",
    "    \"The light is bright\",      # DT â†’ NN â†’ VBZ â†’ JJ\n",
    "    \"I will light the candle\",  # PRP â†’ MD â†’ VB â†’ DT â†’ NN\n",
    "]\n",
    "\n",
    "for sent in examples:\n",
    "    tokens = word_tokenize(sent)\n",
    "    tagged = pos_tag(tokens)\n",
    "    \n",
    "    print(f\"\\n'{sent}'\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Step':<6} {'Word':<10} {'Prev Tag':<12} {'â†’ Current Tag'}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, (word, tag) in enumerate(tagged):\n",
    "        prev_tag = tagged[i-1][1] if i > 0 else '<START>'\n",
    "        print(f\"{i+1:<6} {word:<10} {prev_tag:<12} â†’ {tag}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"NOTICE: Each tag decision uses the PREVIOUS tag as a feature!\")\n",
    "print(\"The tagger never looks at FUTURE tags (they don't exist yet).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c5a4a",
   "metadata": {},
   "source": [
    "### Complete Feature List Used by NLTK's Averaged Perceptron Tagger\n",
    "\n",
    "The tagger extracts these features for each word at position `i`:\n",
    "\n",
    "| Category | Feature | Description | Example for \"light\" |\n",
    "|----------|---------|-------------|---------------------|\n",
    "| **Word** | `word` | The exact word | \"light\" |\n",
    "| | `word.lower()` | Lowercased | \"light\" |\n",
    "| | `suffix(-1,-2,-3)` | Last 1/2/3 chars | \"t\", \"ht\", \"ght\" |\n",
    "| | `prefix(1,2,3)` | First 1/2/3 chars | \"l\", \"li\", \"lig\" |\n",
    "| **Shape** | `is_upper` | Starts uppercase? | True (if \"Light\") |\n",
    "| | `is_title` | Title case? | True |\n",
    "| | `is_digit` | Contains digits? | False |\n",
    "| | `has_hyphen` | Contains hyphen? | False |\n",
    "| **Position** | `i == 0` | First word? | Depends |\n",
    "| | `i == len-1` | Last word? | Depends |\n",
    "| **Context** | `word[i-1]` | Previous word | \"The\" or \"will\" |\n",
    "| | `word[i-2]` | Word 2 back | varies |\n",
    "| | `word[i+1]` | Next word | \"the\" |\n",
    "| **Tags** | `tag[i-1]` | Previous tag | DT or MD |\n",
    "| | `tag[i-2]` | Tag 2 back | varies |\n",
    "| | `tag[i-1] + tag[i-2]` | Tag bigram | \"MD+PRP\" |\n",
    "\n",
    "### âš ï¸ Key Insight: NO FUTURE TAGS!\n",
    "\n",
    "Notice there's **no `tag[i+1]`** (next tag) feature because:\n",
    "- Tags are assigned **left-to-right**\n",
    "- Future tags **don't exist** when deciding current tag\n",
    "- Only previous tags (already decided) can be used\n",
    "\n",
    "This is why **early mistakes cascade**â€”a wrong tag at position 0 affects all subsequent predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb2b0fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Cascading Demo\n",
      "======================================================================\n",
      "\n",
      "When the first word is mistagged, it can affect the entire sentence.\n",
      "\n",
      "Common Tag Transition Patterns (from training data):\n",
      "--------------------------------------------------\n",
      "If prev_tag is...    Next tag likely...\n",
      "--------------------------------------------------\n",
      "<START>              ['DT', 'PRP', 'NNP', 'RB', 'VB']\n",
      "DT                   ['NN', 'JJ', 'NNP', 'RB']\n",
      "MD                   ['VB', 'RB']\n",
      "PRP                  ['VBP', 'VBD', 'MD', 'VBZ']\n",
      "NNP                  ['NNP', 'VBZ', 'VBD', ',']\n",
      "JJ                   ['NN', 'NNS', 'JJ', 'CC']\n",
      "VB                   ['DT', 'PRP', 'RB', 'TO']\n",
      "NN                   ['VBZ', 'VBD', 'IN', 'CC', '.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Now see how 'Light the candle' gets mistagged:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Step 1: Tag 'Light'\n",
      "   - Position: 0 (first word)\n",
      "   - prev_tag: <START>\n",
      "   - Features: capitalized=True, word='Light'\n",
      "   - Problem: Capitalization + sentence-start â†’ model guesses NNP\n",
      "   - Result: 'Light' â†’ NNP âŒ (should be VB)\n",
      "\n",
      "Step 2: Tag 'the'\n",
      "   - prev_tag: NNP (wrong, but tagger doesn't know!)\n",
      "   - After NNP, model expects: more nouns, verbs, punctuation\n",
      "   - Result: 'the' â†’ DT âœ“ (still correct, \"the\" is unambiguous)\n",
      "\n",
      "Step 3: Tag 'candle'\n",
      "   - prev_tag: DT\n",
      "   - After DT, model expects: noun or adjective\n",
      "   - Result: 'candle' â†’ NN âœ“\n",
      "\n",
      "Sentence tagged as: NNP DT NN (instead of VB DT NN)\n",
      "The error at position 0 cascaded but luckily didn't break everything!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate error cascading: early mistakes affect later predictions\n",
    "print(\"Error Cascading Demo\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nWhen the first word is mistagged, it can affect the entire sentence.\\n\")\n",
    "\n",
    "# Simulate what happens with different \"fake\" previous tags\n",
    "def simulate_tag_influence():\n",
    "    \"\"\"\n",
    "    Show how previous tag patterns influence predictions.\n",
    "    Common tag transition patterns learned from training data:\n",
    "    \"\"\"\n",
    "    transitions = {\n",
    "        # Previous tag â†’ likely current tags (from training statistics)\n",
    "        '<START>': ['DT', 'PRP', 'NNP', 'RB', 'VB'],\n",
    "        'DT': ['NN', 'JJ', 'NNP', 'RB'],      # After \"the\" â†’ noun/adj likely\n",
    "        'MD': ['VB', 'RB'],                    # After \"will/can\" â†’ verb likely\n",
    "        'PRP': ['VBP', 'VBD', 'MD', 'VBZ'],   # After \"I/you\" â†’ verb likely\n",
    "        'NNP': ['NNP', 'VBZ', 'VBD', ','],    # After proper noun â†’ verb/more nouns\n",
    "        'JJ': ['NN', 'NNS', 'JJ', 'CC'],      # After adjective â†’ noun likely\n",
    "        'VB': ['DT', 'PRP', 'RB', 'TO'],      # After verb â†’ object/adverb\n",
    "        'NN': ['VBZ', 'VBD', 'IN', 'CC', '.'], # After noun â†’ verb/prep\n",
    "    }\n",
    "    \n",
    "    print(\"Common Tag Transition Patterns (from training data):\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'If prev_tag is...':<20} {'Next tag likely...'}\")\n",
    "    print(\"-\" * 50)\n",
    "    for prev, nexts in transitions.items():\n",
    "        print(f\"{prev:<20} {nexts}\")\n",
    "    \n",
    "    return transitions\n",
    "\n",
    "transitions = simulate_tag_influence()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nNow see how 'Light the candle' gets mistagged:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "Step 1: Tag 'Light'\n",
    "   - Position: 0 (first word)\n",
    "   - prev_tag: <START>\n",
    "   - Features: capitalized=True, word='Light'\n",
    "   - Problem: Capitalization + sentence-start â†’ model guesses NNP\n",
    "   - Result: 'Light' â†’ NNP âŒ (should be VB)\n",
    "\n",
    "Step 2: Tag 'the'\n",
    "   - prev_tag: NNP (wrong, but tagger doesn't know!)\n",
    "   - After NNP, model expects: more nouns, verbs, punctuation\n",
    "   - Result: 'the' â†’ DT âœ“ (still correct, \"the\" is unambiguous)\n",
    "\n",
    "Step 3: Tag 'candle'\n",
    "   - prev_tag: DT\n",
    "   - After DT, model expects: noun or adjective\n",
    "   - Result: 'candle' â†’ NN âœ“\n",
    "\n",
    "Sentence tagged as: NNP DT NN (instead of VB DT NN)\n",
    "The error at position 0 cascaded but luckily didn't break everything!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f929e2b8",
   "metadata": {},
   "source": [
    "### Alternative Approaches: How Other Taggers Solve This\n",
    "\n",
    "| Approach | How it works | Pros | Cons |\n",
    "|----------|--------------|------|------|\n",
    "| **Greedy Lâ†’R** (NLTK default) | Tag one word at a time, use previous tags | Fast, simple | Errors cascade |\n",
    "| **Viterbi/HMM** | Find globally optimal tag sequence | Better accuracy | Slower, limited features |\n",
    "| **Bidirectional LSTM** | Neural network sees full sentence | State-of-the-art | Requires GPU, large model |\n",
    "| **Transformer (BERT)** | Attention over entire sentence | Best accuracy | Slow, resource-heavy |\n",
    "\n",
    "NLTK's perceptron tagger uses the **greedy approach** for speed, accepting some accuracy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904e5f2a",
   "metadata": {},
   "source": [
    "## 7.6 Extracting Words by POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63b3c9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The beautiful princess quickly ran through the dark forest.\n",
      "She was searching for her magical golden crown.\n",
      "\n",
      "Nouns: ['princess', 'forest', 'crown']\n",
      "Verbs: ['ran', 'was', 'searching']\n",
      "Adjectives: ['beautiful', 'dark', 'magical', 'golden']\n",
      "Adverbs: ['quickly']\n"
     ]
    }
   ],
   "source": [
    "def extract_by_pos(text, target_tags):\n",
    "    \"\"\"Extract words with specific POS tags\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "    return [word for word, tag in tagged if tag in target_tags]\n",
    "\n",
    "text = \"\"\"The beautiful princess quickly ran through the dark forest.\n",
    "She was searching for her magical golden crown.\"\"\"\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "\n",
    "# Extract different parts of speech\n",
    "nouns = extract_by_pos(text, ['NN', 'NNS', 'NNP', 'NNPS'])\n",
    "verbs = extract_by_pos(text, ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'])\n",
    "adjectives = extract_by_pos(text, ['JJ', 'JJR', 'JJS'])\n",
    "adverbs = extract_by_pos(text, ['RB', 'RBR', 'RBS'])\n",
    "\n",
    "print(f\"\\nNouns: {nouns}\")\n",
    "print(f\"Verbs: {verbs}\")\n",
    "print(f\"Adjectives: {adjectives}\")\n",
    "print(f\"Adverbs: {adverbs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b54b7883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tag Distribution\n",
      "==============================\n",
      "NN       7 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "JJ       3 â–ˆâ–ˆâ–ˆ\n",
      "VBG      2 â–ˆâ–ˆ\n",
      "NNS      2 â–ˆâ–ˆ\n",
      "VBP      2 â–ˆâ–ˆ\n",
      "CC       2 â–ˆâ–ˆ\n",
      ".        2 â–ˆâ–ˆ\n",
      "VBZ      1 â–ˆ\n",
      "WRB      1 â–ˆ\n",
      "RB       1 â–ˆ\n"
     ]
    }
   ],
   "source": [
    "# POS distribution\n",
    "from collections import Counter\n",
    "\n",
    "def pos_distribution(text):\n",
    "    \"\"\"Get distribution of POS tags\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "    return Counter(tag for word, tag in tagged)\n",
    "\n",
    "text = \"\"\"Machine learning is transforming how computers understand and process \n",
    "human language. Natural language processing applications are becoming \n",
    "increasingly sophisticated and accurate.\"\"\"\n",
    "\n",
    "dist = pos_distribution(text)\n",
    "\n",
    "print(\"POS Tag Distribution\")\n",
    "print(\"=\" * 30)\n",
    "for tag, count in dist.most_common():\n",
    "    print(f\"{tag:<6} {count:>3} {'â–ˆ' * count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6038703",
   "metadata": {},
   "source": [
    "## 7.7 Custom POS Taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bb5df11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sentences: 3698\n",
      "Test sentences: 925\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Get tagged sentences from Brown corpus\n",
    "brown_tagged = brown.tagged_sents(categories='news')\n",
    "\n",
    "# Split into train/test\n",
    "train_size = int(len(brown_tagged) * 0.8)\n",
    "train_sents = brown_tagged[:train_size]\n",
    "test_sents = brown_tagged[train_size:]\n",
    "\n",
    "print(f\"Training sentences: {len(train_sents)}\")\n",
    "print(f\"Test sentences: {len(test_sents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da5d43d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Tagger accuracy: 12.10%\n"
     ]
    }
   ],
   "source": [
    "# Default Tagger (assigns same tag to everything)\n",
    "default_tagger = DefaultTagger('NN')\n",
    "print(f\"Default Tagger accuracy: {default_tagger.accuracy(test_sents):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd48e4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Tagger accuracy: 82.67%\n"
     ]
    }
   ],
   "source": [
    "# Unigram Tagger (learns most common tag for each word)\n",
    "unigram_tagger = UnigramTagger(train_sents, backoff=default_tagger)\n",
    "print(f\"Unigram Tagger accuracy: {unigram_tagger.accuracy(test_sents):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ace359d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Tagger accuracy: 83.61%\n"
     ]
    }
   ],
   "source": [
    "# Bigram Tagger (considers previous word)\n",
    "bigram_tagger = BigramTagger(train_sents, backoff=unigram_tagger)\n",
    "print(f\"Bigram Tagger accuracy: {bigram_tagger.accuracy(test_sents):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a60900df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Tagger accuracy: 83.44%\n"
     ]
    }
   ],
   "source": [
    "# Trigram Tagger (considers two previous words)\n",
    "trigram_tagger = TrigramTagger(train_sents, backoff=bigram_tagger)\n",
    "print(f\"Trigram Tagger accuracy: {trigram_tagger.accuracy(test_sents):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc09506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tagger Comparison\n",
      "===================================\n",
      "Default    12.10%\n",
      "Unigram    82.67%\n",
      "Bigram     83.61%\n",
      "Trigram    83.44%\n"
     ]
    }
   ],
   "source": [
    "# Compare all taggers\n",
    "print(\"\\nTagger Comparison\")\n",
    "print(\"=\" * 35)\n",
    "taggers = [\n",
    "    (\"Default\", default_tagger),\n",
    "    (\"Unigram\", unigram_tagger),\n",
    "    (\"Bigram\", bigram_tagger),\n",
    "    (\"Trigram\", trigram_tagger),\n",
    "]\n",
    "\n",
    "for name, tagger in taggers:\n",
    "    acc = tagger.accuracy(test_sents)\n",
    "    print(f\"{name:<10} {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e50d2",
   "metadata": {},
   "source": [
    "## 7.8 Practical Application: Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8119087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The ambitious young scientist quickly discovered a remarkable \n",
      "breakthrough in artificial intelligence. She carefully analyzed the complex \n",
      "data and brilliantly solved the challenging problem.\n",
      "\n",
      "Text Analysis\n",
      "==================================================\n",
      "\n",
      "Nouns (6):\n",
      "  ['scientist', 'breakthrough', 'intelligence', 'data', 'challenging', 'problem']\n",
      "\n",
      "Verbs (3):\n",
      "  ['discovered', 'analyzed', 'solved']\n",
      "\n",
      "Adjectives (5):\n",
      "  ['ambitious', 'young', 'remarkable', 'artificial', 'complex']\n",
      "\n",
      "Adverbs (3):\n",
      "  ['quickly', 'carefully', 'brilliantly']\n",
      "\n",
      "Pronouns (1):\n",
      "  ['She']\n"
     ]
    }
   ],
   "source": [
    "def analyze_text(text):\n",
    "    \"\"\"Comprehensive text analysis using POS tagging\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "    \n",
    "    # Count by category\n",
    "    categories = {\n",
    "        'Nouns': ['NN', 'NNS', 'NNP', 'NNPS'],\n",
    "        'Verbs': ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'],\n",
    "        'Adjectives': ['JJ', 'JJR', 'JJS'],\n",
    "        'Adverbs': ['RB', 'RBR', 'RBS'],\n",
    "        'Pronouns': ['PRP', 'PRP$', 'WP', 'WP$'],\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for category, tags in categories.items():\n",
    "        words = [w for w, t in tagged if t in tags]\n",
    "        results[category] = {\n",
    "            'count': len(words),\n",
    "            'words': words\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "text = \"\"\"The ambitious young scientist quickly discovered a remarkable \n",
    "breakthrough in artificial intelligence. She carefully analyzed the complex \n",
    "data and brilliantly solved the challenging problem.\"\"\"\n",
    "\n",
    "print(f\"Text: {text}\\n\")\n",
    "\n",
    "analysis = analyze_text(text)\n",
    "\n",
    "print(\"Text Analysis\")\n",
    "print(\"=\" * 50)\n",
    "for category, data in analysis.items():\n",
    "    print(f\"\\n{category} ({data['count']}):\")\n",
    "    print(f\"  {data['words']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac7898e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `pos_tag(tokens)` | Tag a list of tokens |\n",
    "| `pos_tag(tokens, tagset='universal')` | Use universal tagset |\n",
    "| `pos_tag_sents(list_of_sents)` | Batch tag multiple sentences |\n",
    "| `nltk.help.upenn_tagset('TAG')` | Get tag description |\n",
    "\n",
    "### Common Tags\n",
    "- **Nouns**: NN, NNS, NNP, NNPS\n",
    "- **Verbs**: VB, VBD, VBG, VBN, VBP, VBZ\n",
    "- **Adjectives**: JJ, JJR, JJS\n",
    "- **Adverbs**: RB, RBR, RBS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
