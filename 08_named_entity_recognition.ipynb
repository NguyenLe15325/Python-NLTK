{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "357f8c73",
   "metadata": {},
   "source": [
    "# NLTK Complete Guide - Section 8: Named Entity Recognition (NER)\n",
    "\n",
    "This notebook covers:\n",
    "- What is NER?\n",
    "- NLTK's Named Entity Chunker\n",
    "- Entity Types\n",
    "- Extracting Entities\n",
    "- Practical Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "952fb10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('maxent_ne_chunker', quiet=True)\n",
    "nltk.download('words', quiet=True)\n",
    "\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdff076",
   "metadata": {},
   "source": [
    "## 8.1 What is Named Entity Recognition?\n",
    "\n",
    "**NER** identifies and classifies named entities in text:\n",
    "- **PERSON**: People's names\n",
    "- **ORGANIZATION**: Companies, institutions\n",
    "- **GPE**: Geo-Political Entities (countries, cities)\n",
    "- **LOCATION**: Mountains, rivers, regions\n",
    "- **DATE/TIME**: Temporal expressions\n",
    "- **MONEY**: Monetary values\n",
    "- **PERCENT**: Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cd69ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Apple Inc. was founded by Steve Jobs in California.\n",
      "\n",
      "Named Entities:\n",
      "(S\n",
      "  (PERSON Apple/NNP)\n",
      "  (ORGANIZATION Inc./NNP)\n",
      "  was/VBD\n",
      "  founded/VBN\n",
      "  by/IN\n",
      "  (PERSON Steve/NNP Jobs/NNP)\n",
      "  in/IN\n",
      "  (GPE California/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "text = \"Apple Inc. was founded by Steve Jobs in California.\"\n",
    "\n",
    "# NER Pipeline: Tokenize → POS Tag → NE Chunk\n",
    "tokens = word_tokenize(text)\n",
    "tagged = pos_tag(tokens)\n",
    "entities = ne_chunk(tagged)\n",
    "\n",
    "print(f\"Text: {text}\\n\")\n",
    "print(\"Named Entities:\")\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbc39b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Apple/NNP)\n",
      "  (ORGANIZATION Inc./NNP)\n",
      "  was/VBD\n",
      "  founded/VBN\n",
      "  by/IN\n",
      "  (PERSON Steve/NNP Jobs/NNP)\n",
      "  in/IN\n",
      "  (GPE California/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# Visualize the tree (if IPython display is available)\n",
    "# entities.draw()  # Uncomment to see tree visualization\n",
    "\n",
    "# Print tree structure\n",
    "entities.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24e9eba",
   "metadata": {},
   "source": [
    "## 8.2 Extracting Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56ffda54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    \"\"\"Extract named entities from text\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "    tree = ne_chunk(tagged)\n",
    "    \n",
    "    entities = []\n",
    "    for subtree in tree:\n",
    "        if isinstance(subtree, Tree):\n",
    "            entity_type = subtree.label()\n",
    "            entity_text = ' '.join(word for word, tag in subtree.leaves())\n",
    "            entities.append((entity_text, entity_type))\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0f4fb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "Barack Obama was the 44th President of the United States.\n",
      "He was born in Hawaii and studied at Harvard University.\n",
      "Microsoft and Google are major tech companies in America.\n",
      "\n",
      "Extracted Entities:\n",
      "----------------------------------------\n",
      "PERSON          Barack\n",
      "PERSON          Obama\n",
      "GPE             United States\n",
      "GPE             Hawaii\n",
      "ORGANIZATION    Harvard University\n",
      "PERSON          Microsoft\n",
      "GPE             Google\n",
      "GPE             America\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Barack Obama was the 44th President of the United States.\n",
    "He was born in Hawaii and studied at Harvard University.\n",
    "Microsoft and Google are major tech companies in America.\"\"\"\n",
    "\n",
    "print(f\"Text:\\n{text}\\n\")\n",
    "\n",
    "entities = extract_entities(text)\n",
    "\n",
    "print(\"Extracted Entities:\")\n",
    "print(\"-\" * 40)\n",
    "for entity, entity_type in entities:\n",
    "    print(f\"{entity_type:<15} {entity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce54e7",
   "metadata": {},
   "source": [
    "## 8.3 Entity Types in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41c2f172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Named Entity Types\n",
      "============================================================\n",
      "PERSON          People, including fictional characters\n",
      "ORGANIZATION    Companies, agencies, institutions\n",
      "GPE             Countries, cities, states (Geo-Political Entities)\n",
      "LOCATION        Non-GPE locations (mountains, rivers)\n",
      "FACILITY        Buildings, airports, highways\n",
      "GSP             Geo-Socio-Political groups\n"
     ]
    }
   ],
   "source": [
    "entity_types = {\n",
    "    'PERSON': 'People, including fictional characters',\n",
    "    'ORGANIZATION': 'Companies, agencies, institutions',\n",
    "    'GPE': 'Countries, cities, states (Geo-Political Entities)',\n",
    "    'LOCATION': 'Non-GPE locations (mountains, rivers)',\n",
    "    'FACILITY': 'Buildings, airports, highways',\n",
    "    'GSP': 'Geo-Socio-Political groups',\n",
    "}\n",
    "\n",
    "print(\"NLTK Named Entity Types\")\n",
    "print(\"=\" * 60)\n",
    "for entity_type, description in entity_types.items():\n",
    "    print(f\"{entity_type:<15} {description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b55ceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Type Examples\n",
      "============================================================\n",
      "\n",
      "Text: Elon Musk founded SpaceX.\n",
      "Expected: PERSON\n",
      "Found: [('Elon', 'PERSON'), ('Musk', 'PERSON'), ('SpaceX', 'ORGANIZATION')]\n",
      "\n",
      "Text: NASA launched a new satellite.\n",
      "Expected: ORGANIZATION\n",
      "Found: [('NASA', 'ORGANIZATION')]\n",
      "\n",
      "Text: Tokyo is the capital of Japan.\n",
      "Expected: GPE\n",
      "Found: [('Tokyo', 'GPE'), ('Japan', 'GPE')]\n",
      "\n",
      "Text: Mount Everest is the tallest mountain.\n",
      "Expected: LOCATION\n",
      "Found: [('Mount', 'PERSON'), ('Everest', 'ORGANIZATION')]\n"
     ]
    }
   ],
   "source": [
    "# Examples of each entity type\n",
    "examples = [\n",
    "    (\"PERSON\", \"Elon Musk founded SpaceX.\"),\n",
    "    (\"ORGANIZATION\", \"NASA launched a new satellite.\"),\n",
    "    (\"GPE\", \"Tokyo is the capital of Japan.\"),\n",
    "    (\"LOCATION\", \"Mount Everest is the tallest mountain.\"),\n",
    "]\n",
    "\n",
    "print(\"Entity Type Examples\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for expected_type, text in examples:\n",
    "    entities = extract_entities(text)\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Expected: {expected_type}\")\n",
    "    print(f\"Found: {entities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f9183c",
   "metadata": {},
   "source": [
    "## 8.4 Binary NER (Named Entity or Not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "edc3944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With entity types (binary=False):\n",
      "(S\n",
      "  (PERSON Steve/NNP)\n",
      "  (PERSON Jobs/NNP)\n",
      "  founded/VBD\n",
      "  Apple/NNP\n",
      "  in/IN\n",
      "  (GPE California/NNP)\n",
      "  ./.)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Binary mode (binary=True):\n",
      "(S\n",
      "  (NE Steve/NNP Jobs/NNP)\n",
      "  founded/VBD\n",
      "  Apple/NNP\n",
      "  in/IN\n",
      "  (NE California/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "text = \"Steve Jobs founded Apple in California.\"\n",
    "tokens = word_tokenize(text)\n",
    "tagged = pos_tag(tokens)\n",
    "\n",
    "# With entity types (default)\n",
    "entities_typed = ne_chunk(tagged, binary=False)\n",
    "print(\"With entity types (binary=False):\")\n",
    "entities_typed.pprint()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "# Binary (just NE or not)\n",
    "entities_binary = ne_chunk(tagged, binary=True)\n",
    "print(\"Binary mode (binary=True):\")\n",
    "entities_binary.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b83079",
   "metadata": {},
   "source": [
    "## 8.5 How NER Works Under the Hood\n",
    "\n",
    "### The NER Pipeline\n",
    "\n",
    "NLTK's NER is a **multi-stage pipeline**:\n",
    "\n",
    "```\n",
    "Raw Text\n",
    "    ↓ word_tokenize()\n",
    "Tokens: [\"Apple\", \"Inc.\", \"was\", \"founded\", \"by\", \"Steve\", \"Jobs\"]\n",
    "    ↓ pos_tag()\n",
    "POS Tagged: [(\"Apple\", \"NNP\"), (\"Inc.\", \"NNP\"), (\"was\", \"VBD\"), ...]\n",
    "    ↓ ne_chunk()\n",
    "Entity Tree: (ORGANIZATION Apple Inc.) (PERSON Steve Jobs)\n",
    "```\n",
    "\n",
    "### What Features Does NER Look At?\n",
    "\n",
    "NLTK's `maxent_ne_chunker` (Maximum Entropy NE Chunker) uses these features:\n",
    "\n",
    "| Feature | Example | Why It Helps |\n",
    "|---------|---------|--------------|\n",
    "| **POS Tag** | `NNP` (proper noun) | Entities are usually proper nouns |\n",
    "| **Word Shape** | `Xxxxx` (capitalized) | Names start with capitals |\n",
    "| **Previous POS** | What came before | \"President Obama\" vs \"obama\" |\n",
    "| **Previous Word** | Context words | \"Mr.\", \"Dr.\", \"Inc.\" are clues |\n",
    "| **Suffix/Prefix** | `-tion`, `Un-` | Some endings suggest entity types |\n",
    "| **Word Itself** | Gazetteer lookup | Known names like \"Microsoft\" |\n",
    "\n",
    "### Yes, NER is Context-Dependent!\n",
    "\n",
    "Unlike simple dictionary lookup, NER considers **surrounding context**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42d37c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONTEXT MATTERS: Same Word, Different Entity Decisions\n",
      "======================================================================\n",
      "\n",
      "How context changes entity recognition:\n",
      "\n",
      "Text: Apple announced new products today.\n",
      "  Expected: ORGANIZATION expected\n",
      "  Found: [('Apple', 'PERSON')]\n",
      "\n",
      "Text: I ate an apple for breakfast.\n",
      "  Expected: No entity expected\n",
      "  Found: No entities\n",
      "\n",
      "Text: George Washington was the first president.\n",
      "  Expected: PERSON expected\n",
      "  Found: [('George', 'PERSON'), ('Washington', 'GPE')]\n",
      "\n",
      "Text: I visited Washington last summer.\n",
      "  Expected: GPE expected\n",
      "  Found: [('Washington', 'GPE')]\n",
      "\n",
      "Text: Michael Jordan played basketball.\n",
      "  Expected: PERSON expected\n",
      "  Found: [('Michael', 'PERSON'), ('Jordan', 'PERSON')]\n",
      "\n",
      "Text: Jordan is located in the Middle East.\n",
      "  Expected: GPE expected\n",
      "  Found: [('Jordan', 'GPE'), ('Middle East', 'GPE')]\n",
      "\n",
      "Text: Bill works at Microsoft.\n",
      "  Expected: PERSON expected\n",
      "  Found: [('Bill', 'PERSON'), ('Microsoft', 'ORGANIZATION')]\n",
      "\n",
      "Text: The bill was passed by Congress.\n",
      "  Expected: No entity expected\n",
      "  Found: [('Congress', 'ORGANIZATION')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Demonstration: Context affects NER decisions\n",
    "print(\"=\" * 70)\n",
    "print(\"CONTEXT MATTERS: Same Word, Different Entity Decisions\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "context_examples = [\n",
    "    # \"Apple\" as company vs fruit\n",
    "    (\"Apple announced new products today.\", \"ORGANIZATION expected\"),\n",
    "    (\"I ate an apple for breakfast.\", \"No entity expected\"),\n",
    "    \n",
    "    # \"Washington\" as person vs place\n",
    "    (\"George Washington was the first president.\", \"PERSON expected\"),\n",
    "    (\"I visited Washington last summer.\", \"GPE expected\"),\n",
    "    \n",
    "    # \"Jordan\" as person vs country  \n",
    "    (\"Michael Jordan played basketball.\", \"PERSON expected\"),\n",
    "    (\"Jordan is located in the Middle East.\", \"GPE expected\"),\n",
    "    \n",
    "    # Capitalization matters\n",
    "    (\"Bill works at Microsoft.\", \"PERSON expected\"),\n",
    "    (\"The bill was passed by Congress.\", \"No entity expected\"),\n",
    "]\n",
    "\n",
    "print(\"\\nHow context changes entity recognition:\\n\")\n",
    "\n",
    "for text, expected in context_examples:\n",
    "    entities = extract_entities(text)\n",
    "    entity_str = entities if entities else \"No entities\"\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"  Expected: {expected}\")\n",
    "    print(f\"  Found: {entity_str}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb73eaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INSIDE ne_chunk: What the Model Sees\n",
      "======================================================================\n",
      "\n",
      "Text: Apple released the iPhone.\n",
      "POS Tags the NER model receives:\n",
      "  Apple           POS=NNP   Shape=Xxxxx\n",
      "  released        POS=VBD   Shape=xxxxxxxx\n",
      "  the             POS=DT    Shape=xxx\n",
      "  iPhone          POS=NN    Shape=xXxxxx\n",
      "  .               POS=.     Shape=.\n",
      "Result: [('Apple', 'PERSON'), ('iPhone', 'ORGANIZATION')]\n",
      "\n",
      "Text: Steve Jobs founded Apple.\n",
      "POS Tags the NER model receives:\n",
      "  Steve           POS=NNP   Shape=Xxxxx\n",
      "  Jobs            POS=NNP   Shape=Xxxx\n",
      "  founded         POS=VBD   Shape=xxxxxxx\n",
      "  Apple           POS=NNP   Shape=Xxxxx\n",
      "  .               POS=.     Shape=.\n",
      "Result: [('Steve', 'PERSON'), ('Jobs', 'PERSON'), ('Apple', 'PERSON')]\n",
      "\n",
      "Text: I live in New York City.\n",
      "POS Tags the NER model receives:\n",
      "  I               POS=PRP   Shape=X\n",
      "  live            POS=VBP   Shape=xxxx\n",
      "  in              POS=IN    Shape=xx\n",
      "  New             POS=NNP   Shape=Xxx\n",
      "  York            POS=NNP   Shape=Xxxx\n",
      "  City            POS=NNP   Shape=Xxxx\n",
      "  .               POS=.     Shape=.\n",
      "Result: [('New York City', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "# What features does the NER model actually use?\n",
    "# Let's examine the input to ne_chunk\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"INSIDE ne_chunk: What the Model Sees\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_sentences = [\n",
    "    \"Apple released the iPhone.\",\n",
    "    \"Steve Jobs founded Apple.\",\n",
    "    \"I live in New York City.\",\n",
    "]\n",
    "\n",
    "for text in test_sentences:\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "    \n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(\"POS Tags the NER model receives:\")\n",
    "    for word, tag in tagged:\n",
    "        # Show what features are available\n",
    "        shape = ''.join('X' if c.isupper() else 'x' if c.islower() else c for c in word)\n",
    "        print(f\"  {word:<15} POS={tag:<5} Shape={shape}\")\n",
    "    \n",
    "    entities = ne_chunk(tagged)\n",
    "    print(f\"Result: {extract_entities(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf1eb7",
   "metadata": {},
   "source": [
    "### The Algorithm: IOB Tagging + Maximum Entropy\n",
    "\n",
    "NER uses **IOB tagging** (Inside-Outside-Beginning):\n",
    "\n",
    "```\n",
    "Token       POS    IOB Tag      Meaning\n",
    "-------     ---    -------      -------\n",
    "Steve       NNP    B-PERSON     Beginning of PERSON entity\n",
    "Jobs        NNP    I-PERSON     Inside PERSON entity\n",
    "founded     VBD    O            Outside (not an entity)\n",
    "Apple       NNP    B-ORG        Beginning of ORG entity\n",
    "Inc         NNP    I-ORG        Inside ORG entity\n",
    ".           .      O            Outside\n",
    "```\n",
    "\n",
    "**Maximum Entropy Classifier** decides each token's IOB tag by:\n",
    "1. Extracting features (POS, word shape, context)\n",
    "2. Computing probability of each IOB tag\n",
    "3. Picking the highest probability tag\n",
    "\n",
    "This is **actual machine learning** (unlike N-gram POS taggers which just memorize)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f705005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "IOB TAGGING: How NER Labels Each Token\n",
      "======================================================================\n",
      "\n",
      "Text: Barack Obama visited Microsoft headquarters in Seattle.\n",
      "Token           POS    IOB Tag      Explanation\n",
      "------------------------------------------------------------\n",
      "Barack          NNP    B-PERSON     Beginning of PERSON\n",
      "Obama           NNP    B-PERSON     Beginning of PERSON\n",
      "visited         VBD    O            Outside (not entity)\n",
      "Microsoft       NNP    B-ORGANIZATION Beginning of ORGANIZATION\n",
      "headquarters    NNS    O            Outside (not entity)\n",
      "in              IN     O            Outside (not entity)\n",
      "Seattle         NNP    B-GPE        Beginning of GPE\n",
      ".               .      O            Outside (not entity)\n",
      "\n",
      "Text: Dr. John Smith works at Stanford University.\n",
      "Token           POS    IOB Tag      Explanation\n",
      "------------------------------------------------------------\n",
      "Dr.             NNP    O            Outside (not entity)\n",
      "John            NNP    B-PERSON     Beginning of PERSON\n",
      "Smith           NNP    I-PERSON     Inside PERSON\n",
      "works           VBZ    O            Outside (not entity)\n",
      "at              IN     O            Outside (not entity)\n",
      "Stanford        NNP    B-ORGANIZATION Beginning of ORGANIZATION\n",
      "University      NNP    I-ORGANIZATION Inside ORGANIZATION\n",
      ".               .      O            Outside (not entity)\n"
     ]
    }
   ],
   "source": [
    "# Simulate IOB tagging to understand the concept\n",
    "print(\"=\" * 70)\n",
    "print(\"IOB TAGGING: How NER Labels Each Token\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def show_iob_concept(text):\n",
    "    \"\"\"Demonstrate IOB tagging concept\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "    tree = ne_chunk(tagged)\n",
    "    \n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"{'Token':<15} {'POS':<6} {'IOB Tag':<12} {'Explanation'}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Walk through tree to show IOB concept\n",
    "    for item in tree:\n",
    "        if isinstance(item, Tree):\n",
    "            # This is an entity\n",
    "            entity_type = item.label()\n",
    "            words = item.leaves()\n",
    "            for i, (word, pos) in enumerate(words):\n",
    "                if i == 0:\n",
    "                    iob = f\"B-{entity_type}\"\n",
    "                    expl = f\"Beginning of {entity_type}\"\n",
    "                else:\n",
    "                    iob = f\"I-{entity_type}\"\n",
    "                    expl = f\"Inside {entity_type}\"\n",
    "                print(f\"{word:<15} {pos:<6} {iob:<12} {expl}\")\n",
    "        else:\n",
    "            # Not an entity\n",
    "            word, pos = item\n",
    "            print(f\"{word:<15} {pos:<6} {'O':<12} Outside (not entity)\")\n",
    "\n",
    "show_iob_concept(\"Barack Obama visited Microsoft headquarters in Seattle.\")\n",
    "show_iob_concept(\"Dr. John Smith works at Stanford University.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2763e3e1",
   "metadata": {},
   "source": [
    "### Why NER Sometimes Fails\n",
    "\n",
    "Common failure modes:\n",
    "\n",
    "| Problem | Example | Why It Fails |\n",
    "|---------|---------|--------------|\n",
    "| **Lowercase names** | \"obama spoke today\" | Relies on capitalization |\n",
    "| **Unknown entities** | \"Zorbflex Inc.\" | Not in training data |\n",
    "| **Ambiguous context** | \"Apple is great\" | Could be company or fruit |\n",
    "| **Multi-word entities** | \"New York Stock Exchange\" | May split incorrectly |\n",
    "| **Domain-specific** | \"BRCA1 gene\" | Medical/scientific terms |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec1aa331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "NER LIMITATIONS: When It Goes Wrong\n",
      "======================================================================\n",
      "\n",
      "Text                                               Found                          Note\n",
      "----------------------------------------------------------------------------------------------------\n",
      "obama visited china                                None                           Lowercase names → missed\n",
      "Obama visited China                                [('Obama', 'PERSON'), ('China', 'GPE')] Capitalized → found\n",
      "Zorbflex Corporation announced earnings            [('Zorbflex', 'PERSON'), ('Corporation', 'ORGANIZATION')] Unknown company name\n",
      "Microsoft Corporation announced earnings           [('Microsoft', 'PERSON'), ('Corporation', 'ORGANIZATION')] Known company name\n",
      "Apple is delicious                                 [('Apple', 'GPE')]             Ambiguous: fruit or company?\n",
      "Apple announced iPhone                             [('Apple', 'PERSON'), ('iPhone', 'ORGANIZATION')] Clear context: company\n",
      "The New York Stock Exchange opened today           [('New York', 'GPE')]          Long entity name\n",
      "United Nations Security Council met                [('United', 'GPE'), ('Nations', 'ORGANIZATION'), ('Security Council', 'ORGANIZATION')] Another long entity\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate NER failures and limitations\n",
    "print(\"=\" * 70)\n",
    "print(\"NER LIMITATIONS: When It Goes Wrong\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "failure_cases = [\n",
    "    # Lowercase problem\n",
    "    (\"obama visited china\", \"Lowercase names → missed\"),\n",
    "    (\"Obama visited China\", \"Capitalized → found\"),\n",
    "    \n",
    "    # Unknown entities\n",
    "    (\"Zorbflex Corporation announced earnings\", \"Unknown company name\"),\n",
    "    (\"Microsoft Corporation announced earnings\", \"Known company name\"),\n",
    "    \n",
    "    # Ambiguous without context\n",
    "    (\"Apple is delicious\", \"Ambiguous: fruit or company?\"),\n",
    "    (\"Apple announced iPhone\", \"Clear context: company\"),\n",
    "    \n",
    "    # Complex multi-word entities\n",
    "    (\"The New York Stock Exchange opened today\", \"Long entity name\"),\n",
    "    (\"United Nations Security Council met\", \"Another long entity\"),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Text':<50} {'Found':<30} {'Note'}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for text, note in failure_cases:\n",
    "    entities = extract_entities(text)\n",
    "    entity_str = str(entities) if entities else \"None\"\n",
    "    print(f\"{text:<50} {entity_str:<30} {note}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35874e8",
   "metadata": {},
   "source": [
    "## 8.6 Custom Training NER\n",
    "\n",
    "### Can You Train Your Own NER Model?\n",
    "\n",
    "**Short answer:** Yes, but NLTK's built-in NER trainer is limited.\n",
    "\n",
    "**Options for custom NER:**\n",
    "\n",
    "| Approach | Difficulty | Best For |\n",
    "|----------|------------|----------|\n",
    "| **Rule-based (gazetteers)** | Easy | Known entity lists |\n",
    "| **NLTK ClassifierBasedTagger** | Medium | Educational purposes |\n",
    "| **spaCy custom NER** | Medium | Production use |\n",
    "| **Transformers (BERT, etc.)** | Hard | State-of-the-art accuracy |\n",
    "\n",
    "### Option 1: Rule-Based NER with Gazetteers\n",
    "\n",
    "A **gazetteer** is simply a list of known entities. This is the easiest approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7859825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GAZETTEER-BASED NER: Custom Entity Lists\n",
      "======================================================================\n",
      "\n",
      "Text: I'm learning Python and Django for web development.\n",
      "Entities: [('Python', 'PROGRAMMING_LANG'), ('Django', 'FRAMEWORK')]\n",
      "\n",
      "Text: Microsoft uses TypeScript for VS Code.\n",
      "Entities: [('Microsoft', 'COMPANY'), ('TypeScript', 'PROGRAMMING_LANG')]\n",
      "\n",
      "Text: Tesla uses PyTorch for their AI systems.\n",
      "Entities: [('Tesla', 'COMPANY'), ('PyTorch', 'FRAMEWORK')]\n",
      "\n",
      "Text: Goldman Sachs runs Java applications on Oracle databases.\n",
      "Entities: [('Goldman Sachs', 'COMPANY'), ('Java', 'PROGRAMMING_LANG'), ('Oracle', 'DATABASE')]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Rule-based NER using gazetteers (lists of known entities)\n",
    "\n",
    "class GazetteerNER:\n",
    "    \"\"\"Simple rule-based NER using entity lists\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Define gazetteers (entity lists)\n",
    "        self.gazetteers = {\n",
    "            'COMPANY': {'Apple', 'Microsoft', 'Google', 'Amazon', 'Meta', \n",
    "                       'Tesla', 'SpaceX', 'Netflix', 'Uber', 'Airbnb'},\n",
    "            'PROGRAMMING_LANG': {'Python', 'Java', 'JavaScript', 'C++', \n",
    "                                'Rust', 'Go', 'TypeScript', 'Ruby'},\n",
    "            'FRAMEWORK': {'Django', 'Flask', 'React', 'Angular', 'Vue',\n",
    "                         'TensorFlow', 'PyTorch', 'Spring', 'Rails'},\n",
    "            'DATABASE': {'MySQL', 'PostgreSQL', 'MongoDB', 'Redis', \n",
    "                        'Cassandra', 'SQLite', 'Oracle'},\n",
    "        }\n",
    "        \n",
    "        # Also include multi-word entities\n",
    "        self.multi_word = {\n",
    "            'COMPANY': {'Goldman Sachs', 'JP Morgan', 'General Motors'},\n",
    "            'FRAMEWORK': {'Spring Boot', 'Ruby on Rails', 'ASP.NET'},\n",
    "        }\n",
    "    \n",
    "    def extract(self, text):\n",
    "        \"\"\"Extract entities using gazetteer lookup\"\"\"\n",
    "        entities = []\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Check multi-word entities first\n",
    "        for entity_type, entity_set in self.multi_word.items():\n",
    "            for entity in entity_set:\n",
    "                if entity.lower() in text.lower():\n",
    "                    entities.append((entity, entity_type))\n",
    "        \n",
    "        # Check single-word entities\n",
    "        for token in tokens:\n",
    "            for entity_type, entity_set in self.gazetteers.items():\n",
    "                if token in entity_set:\n",
    "                    entities.append((token, entity_type))\n",
    "        \n",
    "        return entities\n",
    "\n",
    "# Demo\n",
    "gaz_ner = GazetteerNER()\n",
    "\n",
    "tech_texts = [\n",
    "    \"I'm learning Python and Django for web development.\",\n",
    "    \"Microsoft uses TypeScript for VS Code.\",\n",
    "    \"Tesla uses PyTorch for their AI systems.\",\n",
    "    \"Goldman Sachs runs Java applications on Oracle databases.\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GAZETTEER-BASED NER: Custom Entity Lists\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for text in tech_texts:\n",
    "    entities = gaz_ner.extract(text)\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Entities: {entities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67141da1",
   "metadata": {},
   "source": [
    "### Option 2: Training NLTK's NE Chunker\n",
    "\n",
    "NLTK allows training a custom NER model using the **ClassifierBasedTagger**. \n",
    "The training data format uses IOB tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6246ff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "IOB TRAINING DATA FORMAT\n",
      "======================================================================\n",
      "\n",
      "How to annotate data for NER training:\n",
      "\n",
      "Sentence 1:\n",
      "Token           POS    IOB Tag     \n",
      "-----------------------------------\n",
      "Python          NNP    B-LANG      \n",
      "is              VBZ    O           \n",
      "developed       VBN    O           \n",
      "by              IN     O           \n",
      "Guido           NNP    B-PERSON    \n",
      "van             NNP    I-PERSON    \n",
      "Rossum          NNP    I-PERSON    \n",
      ".               .      O           \n",
      "\n",
      "Sentence 2:\n",
      "Token           POS    IOB Tag     \n",
      "-----------------------------------\n",
      "TensorFlow      NNP    B-FRAMEWORK \n",
      "was             VBD    O           \n",
      "created         VBN    O           \n",
      "by              IN     O           \n",
      "Google          NNP    B-ORG       \n",
      ".               .      O           \n",
      "\n",
      "Sentence 3:\n",
      "Token           POS    IOB Tag     \n",
      "-----------------------------------\n",
      "Django          NNP    B-FRAMEWORK \n",
      "and             CC     O           \n",
      "Flask           NNP    B-FRAMEWORK \n",
      "are             VBP    O           \n",
      "Python          NNP    B-LANG      \n",
      "frameworks      NNS    O           \n",
      ".               .      O           \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Training format for NLTK NER\n",
    "# Data format: list of sentences, each word has (token, POS, IOB_tag)\n",
    "\n",
    "# Example training data in IOB format\n",
    "training_data_iob = [\n",
    "    # Sentence 1\n",
    "    [\n",
    "        ('Python', 'NNP', 'B-LANG'),      # Beginning of LANG entity\n",
    "        ('is', 'VBZ', 'O'),                # Outside\n",
    "        ('developed', 'VBN', 'O'),\n",
    "        ('by', 'IN', 'O'),\n",
    "        ('Guido', 'NNP', 'B-PERSON'),     # Beginning of PERSON\n",
    "        ('van', 'NNP', 'I-PERSON'),       # Inside PERSON\n",
    "        ('Rossum', 'NNP', 'I-PERSON'),    # Inside PERSON\n",
    "        ('.', '.', 'O'),\n",
    "    ],\n",
    "    # Sentence 2\n",
    "    [\n",
    "        ('TensorFlow', 'NNP', 'B-FRAMEWORK'),\n",
    "        ('was', 'VBD', 'O'),\n",
    "        ('created', 'VBN', 'O'),\n",
    "        ('by', 'IN', 'O'),\n",
    "        ('Google', 'NNP', 'B-ORG'),\n",
    "        ('.', '.', 'O'),\n",
    "    ],\n",
    "    # Sentence 3\n",
    "    [\n",
    "        ('Django', 'NNP', 'B-FRAMEWORK'),\n",
    "        ('and', 'CC', 'O'),\n",
    "        ('Flask', 'NNP', 'B-FRAMEWORK'),\n",
    "        ('are', 'VBP', 'O'),\n",
    "        ('Python', 'NNP', 'B-LANG'),\n",
    "        ('frameworks', 'NNS', 'O'),\n",
    "        ('.', '.', 'O'),\n",
    "    ],\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"IOB TRAINING DATA FORMAT\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nHow to annotate data for NER training:\\n\")\n",
    "\n",
    "for i, sentence in enumerate(training_data_iob, 1):\n",
    "    print(f\"Sentence {i}:\")\n",
    "    print(f\"{'Token':<15} {'POS':<6} {'IOB Tag':<12}\")\n",
    "    print(\"-\" * 35)\n",
    "    for token, pos, iob in sentence:\n",
    "        print(f\"{token:<15} {pos:<6} {iob:<12}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6fe0d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "REGEX-BASED CHUNKER (Simple Custom NER)\n",
      "======================================================================\n",
      "\n",
      "Text: Steve Jobs founded Apple Inc in California\n",
      "POS Tags: [('Steve', 'NNP'), ('Jobs', 'NNP'), ('founded', 'VBD'), ('Apple', 'NNP'), ('Inc', 'NNP'), ('in', 'IN'), ('California', 'NNP')]\n",
      "\n",
      "Chunked result:\n",
      "(S\n",
      "  (TECH_COMPANY Steve/NNP Jobs/NNP)\n",
      "  founded/VBD\n",
      "  (TECH_COMPANY Apple/NNP Inc/NNP)\n",
      "  in/IN\n",
      "  (TECH_COMPANY California/NNP))\n",
      "\n",
      "⚠️ Note: This is pattern-based, not trained on data.\n"
     ]
    }
   ],
   "source": [
    "# Build a simple custom NER using NLTK's chunking framework\n",
    "from nltk.chunk import ChunkParserI\n",
    "from nltk import RegexpParser\n",
    "\n",
    "# Option 2a: Rule-based chunker using regex patterns\n",
    "# This is simpler than training but can be effective\n",
    "\n",
    "# Define grammar rules for chunking\n",
    "grammar = r\"\"\"\n",
    "    TECH_COMPANY: {<NNP>+<(Inc|Corp|LLC|Ltd)\\.?>?}  # Proper nouns optionally followed by Inc/Corp\n",
    "    PERSON: {<NNP><NNP>+}                            # Two or more proper nouns\n",
    "    LANGUAGE: {<NNP>}                                # Single proper noun (needs gazetteer)\n",
    "\"\"\"\n",
    "\n",
    "chunk_parser = RegexpParser(grammar)\n",
    "\n",
    "# Test it\n",
    "test_text = \"Steve Jobs founded Apple Inc in California\"\n",
    "tokens = word_tokenize(test_text)\n",
    "tagged = pos_tag(tokens)\n",
    "chunked = chunk_parser.parse(tagged)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"REGEX-BASED CHUNKER (Simple Custom NER)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nText: {test_text}\")\n",
    "print(f\"POS Tags: {tagged}\")\n",
    "print(f\"\\nChunked result:\")\n",
    "print(chunked)\n",
    "print(\"\\n⚠️ Note: This is pattern-based, not trained on data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93cc0eb",
   "metadata": {},
   "source": [
    "### Option 3: Combining NLTK with Gazetteers\n",
    "\n",
    "The most practical approach for custom domains: **combine NLTK's NER with your own entity lists**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8dfe2cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HYBRID NER: NLTK + Custom Gazetteers\n",
      "======================================================================\n",
      "\n",
      "Text: Elon Musk uses Python and TensorFlow at Tesla.\n",
      "Entities found:\n",
      "  • Elon (PERSON)\n",
      "  • Musk (ORGANIZATION)\n",
      "  • Python (PERSON)\n",
      "  • TensorFlow (ORGANIZATION)\n",
      "  • Tesla (ORGANIZATION)\n",
      "\n",
      "Text: Dr. Smith prescribed Aspirin for Hypertension.\n",
      "Entities found:\n",
      "  • Smith (PERSON)\n",
      "  • Aspirin (PERSON)\n",
      "  • Hypertension (DISEASE)\n",
      "\n",
      "Text: Google developed Go and TensorFlow in California.\n",
      "Entities found:\n",
      "  • Google (PERSON)\n",
      "  • TensorFlow (ORGANIZATION)\n",
      "  • California (GPE)\n",
      "\n",
      "Text: The Django framework uses PostgreSQL database.\n",
      "Entities found:\n",
      "  • Django (GPE)\n",
      "  • PostgreSQL (ORGANIZATION)\n"
     ]
    }
   ],
   "source": [
    "# Option 3: Hybrid NER - Combine NLTK's NER with custom gazetteers\n",
    "\n",
    "class HybridNER:\n",
    "    \"\"\"\n",
    "    Combines NLTK's built-in NER with custom gazetteers.\n",
    "    Best of both worlds!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Custom domain-specific gazetteers\n",
    "        self.custom_entities = {\n",
    "            # Tech domain\n",
    "            'PROGRAMMING_LANG': {'Python', 'Java', 'JavaScript', 'C++', 'Rust', 'Go'},\n",
    "            'FRAMEWORK': {'Django', 'Flask', 'React', 'TensorFlow', 'PyTorch', 'Spring'},\n",
    "            'DATABASE': {'MySQL', 'PostgreSQL', 'MongoDB', 'Redis', 'SQLite'},\n",
    "            # Medical domain (example)\n",
    "            'DRUG': {'Aspirin', 'Ibuprofen', 'Paracetamol', 'Amoxicillin'},\n",
    "            'DISEASE': {'Diabetes', 'Hypertension', 'Alzheimer', 'Parkinson'},\n",
    "        }\n",
    "    \n",
    "    def extract(self, text):\n",
    "        \"\"\"Extract entities using both NLTK and custom gazetteers\"\"\"\n",
    "        entities = []\n",
    "        \n",
    "        # 1. Use NLTK's built-in NER for standard entities\n",
    "        tokens = word_tokenize(text)\n",
    "        tagged = pos_tag(tokens)\n",
    "        tree = ne_chunk(tagged)\n",
    "        \n",
    "        for subtree in tree:\n",
    "            if isinstance(subtree, Tree):\n",
    "                entity_type = subtree.label()\n",
    "                entity_text = ' '.join(w for w, t in subtree.leaves())\n",
    "                entities.append((entity_text, entity_type))\n",
    "        \n",
    "        # 2. Add custom gazetteer matches\n",
    "        for token in tokens:\n",
    "            for entity_type, entity_set in self.custom_entities.items():\n",
    "                if token in entity_set:\n",
    "                    # Avoid duplicates\n",
    "                    if not any(token in e for e, t in entities):\n",
    "                        entities.append((token, entity_type))\n",
    "        \n",
    "        return entities\n",
    "\n",
    "# Demo\n",
    "hybrid_ner = HybridNER()\n",
    "\n",
    "test_texts = [\n",
    "    \"Elon Musk uses Python and TensorFlow at Tesla.\",\n",
    "    \"Dr. Smith prescribed Aspirin for Hypertension.\",\n",
    "    \"Google developed Go and TensorFlow in California.\",\n",
    "    \"The Django framework uses PostgreSQL database.\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"HYBRID NER: NLTK + Custom Gazetteers\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for text in test_texts:\n",
    "    entities = hybrid_ner.extract(text)\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Entities found:\")\n",
    "    for entity, etype in entities:\n",
    "        print(f\"  • {entity} ({etype})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b355c837",
   "metadata": {},
   "source": [
    "### Summary: NER Under the Hood\n",
    "\n",
    "| Aspect | How It Works |\n",
    "|--------|--------------|\n",
    "| **Algorithm** | Maximum Entropy classifier with IOB tagging |\n",
    "| **Context-Dependent?** | ✅ Yes - uses POS tags, word shape, surrounding words |\n",
    "| **Features Used** | POS tag, word shape, capitalization, previous/next words |\n",
    "| **Custom Training** | Possible but complex; easier to use gazetteers |\n",
    "\n",
    "**Best Practices for Custom NER:**\n",
    "1. **Simple domains**: Use gazetteer-based approach\n",
    "2. **Combined approach**: NLTK + your entity lists\n",
    "3. **Production quality**: Consider spaCy or Transformers\n",
    "\n",
    "**Remember:** NLTK's NER is **actual machine learning** (unlike N-gram POS taggers)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8cddd5",
   "metadata": {},
   "source": [
    "## 8.7 Extracting Entities by Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23eb6ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_by_type(text):\n",
    "    \"\"\"Extract entities grouped by type\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "    tree = ne_chunk(tagged)\n",
    "    \n",
    "    entities_by_type = {}\n",
    "    \n",
    "    for subtree in tree:\n",
    "        if isinstance(subtree, Tree):\n",
    "            entity_type = subtree.label()\n",
    "            entity_text = ' '.join(word for word, tag in subtree.leaves())\n",
    "            \n",
    "            if entity_type not in entities_by_type:\n",
    "                entities_by_type[entity_type] = []\n",
    "            entities_by_type[entity_type].append(entity_text)\n",
    "    \n",
    "    return entities_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42852643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "Bill Gates and Satya Nadella lead Microsoft in Redmond, Washington.\n",
      "Tim Cook is the CEO of Apple, headquartered in Cupertino, California.\n",
      "Google was founded by Larry Page and Sergey Brin at Stanford University.\n",
      "\n",
      "Entities by Type:\n",
      "==================================================\n",
      "\n",
      "PERSON:\n",
      "  • Bill\n",
      "  • Satya Nadella\n",
      "  • Microsoft\n",
      "  • Tim Cook\n",
      "  • Google\n",
      "  • Larry Page\n",
      "  • Sergey Brin\n",
      "\n",
      "ORGANIZATION:\n",
      "  • Gates\n",
      "  • CEO\n",
      "  • Stanford University\n",
      "\n",
      "GPE:\n",
      "  • Redmond\n",
      "  • Washington\n",
      "  • Apple\n",
      "  • Cupertino\n",
      "  • California\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Bill Gates and Satya Nadella lead Microsoft in Redmond, Washington.\n",
    "Tim Cook is the CEO of Apple, headquartered in Cupertino, California.\n",
    "Google was founded by Larry Page and Sergey Brin at Stanford University.\"\"\"\n",
    "\n",
    "print(f\"Text:\\n{text}\\n\")\n",
    "\n",
    "entities = extract_entities_by_type(text)\n",
    "\n",
    "print(\"Entities by Type:\")\n",
    "print(\"=\" * 50)\n",
    "for entity_type, entity_list in entities.items():\n",
    "    print(f\"\\n{entity_type}:\")\n",
    "    for entity in entity_list:\n",
    "        print(f\"  • {entity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8181b5",
   "metadata": {},
   "source": [
    "## 8.8 Entity Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e47acf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "Apple announced new products. Apple's CEO Tim Cook presented.\n",
      "Microsoft also had announcements. Google and Apple compete in many markets.\n",
      "Tim Cook mentioned Apple's commitment to privacy.\n",
      "\n",
      "Entity Counts:\n",
      "----------------------------------------\n",
      "Apple                (PERSON      ) 3x\n",
      "CEO Tim Cook         (ORGANIZATION) 1x\n",
      "Microsoft            (PERSON      ) 1x\n",
      "Google               (PERSON      ) 1x\n",
      "Tim Cook             (PERSON      ) 1x\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_entities(text):\n",
    "    \"\"\"Count entity occurrences\"\"\"\n",
    "    entities = extract_entities(text)\n",
    "    return Counter(entities)\n",
    "\n",
    "text = \"\"\"Apple announced new products. Apple's CEO Tim Cook presented.\n",
    "Microsoft also had announcements. Google and Apple compete in many markets.\n",
    "Tim Cook mentioned Apple's commitment to privacy.\"\"\"\n",
    "\n",
    "print(f\"Text:\\n{text}\\n\")\n",
    "\n",
    "entity_counts = count_entities(text)\n",
    "\n",
    "print(\"Entity Counts:\")\n",
    "print(\"-\" * 40)\n",
    "for (entity, etype), count in entity_counts.most_common():\n",
    "    print(f\"{entity:<20} ({etype:<12}) {count}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d574eb",
   "metadata": {},
   "source": [
    "## 8.9 Complete NER Pipeline Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76ecdb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERExtractor:\n",
    "    \"\"\"Named Entity Recognition utility class\"\"\"\n",
    "    \n",
    "    def __init__(self, binary=False):\n",
    "        self.binary = binary\n",
    "    \n",
    "    def process(self, text):\n",
    "        \"\"\"Process text and return NE tree\"\"\"\n",
    "        tokens = word_tokenize(text)\n",
    "        tagged = pos_tag(tokens)\n",
    "        return ne_chunk(tagged, binary=self.binary)\n",
    "    \n",
    "    def extract_all(self, text):\n",
    "        \"\"\"Extract all entities as list of tuples\"\"\"\n",
    "        tree = self.process(text)\n",
    "        entities = []\n",
    "        for subtree in tree:\n",
    "            if isinstance(subtree, Tree):\n",
    "                entity_type = subtree.label()\n",
    "                entity_text = ' '.join(w for w, t in subtree.leaves())\n",
    "                entities.append((entity_text, entity_type))\n",
    "        return entities\n",
    "    \n",
    "    def extract_by_type(self, text, target_type):\n",
    "        \"\"\"Extract entities of specific type\"\"\"\n",
    "        entities = self.extract_all(text)\n",
    "        return [e for e, t in entities if t == target_type]\n",
    "    \n",
    "    def get_people(self, text):\n",
    "        \"\"\"Extract person names\"\"\"\n",
    "        return self.extract_by_type(text, 'PERSON')\n",
    "    \n",
    "    def get_organizations(self, text):\n",
    "        \"\"\"Extract organization names\"\"\"\n",
    "        return self.extract_by_type(text, 'ORGANIZATION')\n",
    "    \n",
    "    def get_locations(self, text):\n",
    "        \"\"\"Extract locations (GPE + LOCATION)\"\"\"\n",
    "        gpe = self.extract_by_type(text, 'GPE')\n",
    "        loc = self.extract_by_type(text, 'LOCATION')\n",
    "        return gpe + loc\n",
    "    \n",
    "    def summary(self, text):\n",
    "        \"\"\"Get summary of all entities\"\"\"\n",
    "        return {\n",
    "            'people': self.get_people(text),\n",
    "            'organizations': self.get_organizations(text),\n",
    "            'locations': self.get_locations(text),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bd72bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "Elon Musk is the CEO of Tesla and SpaceX.\n",
      "Tesla is headquartered in Austin, Texas.\n",
      "SpaceX launches rockets from Cape Canaveral, Florida.\n",
      "Mark Zuckerberg runs Meta in Menlo Park, California.\n",
      "\n",
      "Entity Summary:\n",
      "==================================================\n",
      "\n",
      "PEOPLE:\n",
      "  • Elon\n",
      "  • Tesla\n",
      "  • Mark Zuckerberg\n",
      "\n",
      "ORGANIZATIONS:\n",
      "  • Musk\n",
      "  • CEO of Tesla\n",
      "  • SpaceX\n",
      "  • SpaceX\n",
      "  • Meta\n",
      "\n",
      "LOCATIONS:\n",
      "  • Austin\n",
      "  • Texas\n",
      "  • Cape\n",
      "  • Florida\n",
      "  • Menlo Park\n",
      "  • California\n"
     ]
    }
   ],
   "source": [
    "# Use the NER class\n",
    "ner = NERExtractor()\n",
    "\n",
    "text = \"\"\"Elon Musk is the CEO of Tesla and SpaceX.\n",
    "Tesla is headquartered in Austin, Texas.\n",
    "SpaceX launches rockets from Cape Canaveral, Florida.\n",
    "Mark Zuckerberg runs Meta in Menlo Park, California.\"\"\"\n",
    "\n",
    "print(f\"Text:\\n{text}\\n\")\n",
    "\n",
    "summary = ner.summary(text)\n",
    "\n",
    "print(\"Entity Summary:\")\n",
    "print(\"=\" * 50)\n",
    "for category, entities in summary.items():\n",
    "    print(f\"\\n{category.upper()}:\")\n",
    "    for entity in entities:\n",
    "        print(f\"  • {entity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5e0a93",
   "metadata": {},
   "source": [
    "## 8.10 Practical Application: News Article Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63c0c91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_article(text):\n",
    "    \"\"\"Analyze a news article for entities\"\"\"\n",
    "    ner = NERExtractor()\n",
    "    \n",
    "    # Get all entities\n",
    "    all_entities = ner.extract_all(text)\n",
    "    \n",
    "    # Count by type\n",
    "    type_counts = Counter(t for e, t in all_entities)\n",
    "    \n",
    "    # Most mentioned entities\n",
    "    entity_counts = Counter(e for e, t in all_entities)\n",
    "    \n",
    "    return {\n",
    "        'total_entities': len(all_entities),\n",
    "        'unique_entities': len(set(e for e, t in all_entities)),\n",
    "        'type_distribution': dict(type_counts),\n",
    "        'top_entities': entity_counts.most_common(5),\n",
    "        'summary': ner.summary(text)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02e5391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEWS ARTICLE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Technology giants Apple, Google, and Microsoft reported strong quarterly earnings.\n",
      "Apple CEO Tim Cook announced record iPhone sales in China and Europe.\n",
      "Google's Sundar Pichai highlighted growth in cloud computing services.\n",
      "Microsoft's Satya Nadella discussed the company's AI investments.\n",
      "Wall Street analysts predict continued growth for these Silicon Valley companies.\n",
      "Apple's headquarters in Cupertino and Google's campus in Mountain View remain innovation hubs.\n",
      "\n",
      "============================================================\n",
      "\n",
      "Total entities found: 18\n",
      "Unique entities: 14\n",
      "\n",
      "Entity Type Distribution:\n",
      "  GPE: 6\n",
      "  PERSON: 9\n",
      "  ORGANIZATION: 3\n",
      "\n",
      "Top Mentioned Entities:\n",
      "  Google: 3x\n",
      "  Apple: 2x\n",
      "  Microsoft: 2x\n",
      "  Technology: 1x\n",
      "  Apple CEO Tim Cook: 1x\n"
     ]
    }
   ],
   "source": [
    "article = \"\"\"Technology giants Apple, Google, and Microsoft reported strong quarterly earnings.\n",
    "Apple CEO Tim Cook announced record iPhone sales in China and Europe.\n",
    "Google's Sundar Pichai highlighted growth in cloud computing services.\n",
    "Microsoft's Satya Nadella discussed the company's AI investments.\n",
    "Wall Street analysts predict continued growth for these Silicon Valley companies.\n",
    "Apple's headquarters in Cupertino and Google's campus in Mountain View remain innovation hubs.\"\"\"\n",
    "\n",
    "print(\"NEWS ARTICLE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{article}\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "analysis = analyze_article(article)\n",
    "\n",
    "print(f\"\\nTotal entities found: {analysis['total_entities']}\")\n",
    "print(f\"Unique entities: {analysis['unique_entities']}\")\n",
    "\n",
    "print(f\"\\nEntity Type Distribution:\")\n",
    "for etype, count in analysis['type_distribution'].items():\n",
    "    print(f\"  {etype}: {count}\")\n",
    "\n",
    "print(f\"\\nTop Mentioned Entities:\")\n",
    "for entity, count in analysis['top_entities']:\n",
    "    print(f\"  {entity}: {count}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14c528a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `ne_chunk(tagged)` | Perform NER on POS-tagged tokens |\n",
    "| `ne_chunk(tagged, binary=True)` | Binary NER (entity or not) |\n",
    "| `tree.label()` | Get entity type |\n",
    "| `tree.leaves()` | Get words in entity |\n",
    "\n",
    "### NER Pipeline\n",
    "```python\n",
    "tokens = word_tokenize(text)     # 1. Tokenize\n",
    "tagged = pos_tag(tokens)         # 2. POS Tag\n",
    "entities = ne_chunk(tagged)      # 3. NE Chunk\n",
    "```\n",
    "\n",
    "### Entity Types\n",
    "- **PERSON**: People\n",
    "- **ORGANIZATION**: Companies, institutions\n",
    "- **GPE**: Countries, cities, states\n",
    "- **LOCATION**: Non-GPE locations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
