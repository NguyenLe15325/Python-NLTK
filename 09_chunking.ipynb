{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d023689e",
   "metadata": {},
   "source": [
    "# NLTK Complete Guide - Section 9: Chunking\n",
    "\n",
    "This notebook covers:\n",
    "- What is Chunking?\n",
    "- Noun Phrase Chunking\n",
    "- Chunk Grammar Rules\n",
    "- Chinking (Excluding Patterns)\n",
    "- Custom Chunkers\n",
    "- Practical Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f95901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.chunk import RegexpParser\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b7a4a",
   "metadata": {},
   "source": [
    "## 9.1 What is Chunking?\n",
    "\n",
    "**Chunking** (also called shallow parsing) groups words into meaningful phrases:\n",
    "\n",
    "- **Noun Phrases (NP)**: \"the big dog\", \"a beautiful sunset\"\n",
    "- **Verb Phrases (VP)**: \"is running\", \"has been working\"\n",
    "- **Prepositional Phrases (PP)**: \"in the house\", \"on the table\"\n",
    "\n",
    "Chunking uses POS tags to identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e22ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# POS tag the sentence\n",
    "tokens = word_tokenize(sentence)\n",
    "tagged = pos_tag(tokens)\n",
    "\n",
    "print(\"POS Tagged:\")\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple noun phrase grammar\n",
    "# NP: Determiner + Adjective(s) + Noun\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN.*>+}\"\n",
    "\n",
    "# Create a chunk parser\n",
    "chunk_parser = RegexpParser(grammar)\n",
    "\n",
    "# Parse the tagged sentence\n",
    "tree = chunk_parser.parse(tagged)\n",
    "\n",
    "print(\"Chunked:\")\n",
    "tree.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348b31c9",
   "metadata": {},
   "source": [
    "## 9.2 Chunk Grammar Syntax\n",
    "\n",
    "| Symbol | Meaning |\n",
    "|--------|----------|\n",
    "| `<TAG>` | Match a specific POS tag |\n",
    "| `<TAG1\\|TAG2>` | Match either tag |\n",
    "| `?` | Optional (0 or 1) |\n",
    "| `*` | Zero or more |\n",
    "| `+` | One or more |\n",
    "| `{pattern}` | Chunk pattern (include) |\n",
    "| `}pattern{` | Chink pattern (exclude) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf3ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different grammar patterns\n",
    "grammars = {\n",
    "    \"Simple NP\": \"NP: {<DT>?<NN>}\",\n",
    "    \"NP with adjectives\": \"NP: {<DT>?<JJ>*<NN>}\",\n",
    "    \"NP with multiple nouns\": \"NP: {<DT>?<JJ>*<NN.*>+}\",\n",
    "    \"Verb phrase\": \"VP: {<VB.*><RB>?}\",\n",
    "    \"Prepositional phrase\": \"PP: {<IN><DT>?<NN.*>}\",\n",
    "}\n",
    "\n",
    "sentence = \"The quick brown fox jumps quickly over the lazy dog.\"\n",
    "tagged = pos_tag(word_tokenize(sentence))\n",
    "\n",
    "print(f\"Sentence: {sentence}\")\n",
    "print(f\"Tagged: {tagged}\\n\")\n",
    "\n",
    "for name, grammar in grammars.items():\n",
    "    parser = RegexpParser(grammar)\n",
    "    tree = parser.parse(tagged)\n",
    "    \n",
    "    # Extract chunks\n",
    "    chunks = []\n",
    "    for subtree in tree:\n",
    "        if isinstance(subtree, Tree):\n",
    "            chunk_text = ' '.join(word for word, tag in subtree.leaves())\n",
    "            chunks.append(chunk_text)\n",
    "    \n",
    "    print(f\"{name}: {chunks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495582bd",
   "metadata": {},
   "source": [
    "## 9.3 Noun Phrase Chunking (NP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7310f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive NP grammar\n",
    "np_grammar = r\"\"\"\n",
    "    NP: {<DT|PRP\\$>?<JJ>*<NN.*>+}   # Determiner + adjectives + nouns\n",
    "        {<NNP>+}                      # Proper nouns\n",
    "        {<PRP>}                       # Pronouns\n",
    "\"\"\"\n",
    "\n",
    "np_parser = RegexpParser(np_grammar)\n",
    "\n",
    "sentences = [\n",
    "    \"The big brown dog chased the small cat.\",\n",
    "    \"My beautiful garden has colorful flowers.\",\n",
    "    \"John and Mary visited New York City.\",\n",
    "    \"She bought an expensive red sports car.\",\n",
    "]\n",
    "\n",
    "print(\"Noun Phrase Chunking\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sent in sentences:\n",
    "    tagged = pos_tag(word_tokenize(sent))\n",
    "    tree = np_parser.parse(tagged)\n",
    "    \n",
    "    nps = [' '.join(w for w, t in subtree.leaves()) \n",
    "           for subtree in tree if isinstance(subtree, Tree)]\n",
    "    \n",
    "    print(f\"\\nSentence: {sent}\")\n",
    "    print(f\"NPs: {nps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045ba0e0",
   "metadata": {},
   "source": [
    "## 9.4 Verb Phrase Chunking (VP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a45ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verb phrase grammar\n",
    "vp_grammar = r\"\"\"\n",
    "    VP: {<VB.*><RB.*>?<VB.*>*}  # Verb + optional adverb + more verbs\n",
    "        {<MD><VB>}              # Modal + base verb\n",
    "\"\"\"\n",
    "\n",
    "vp_parser = RegexpParser(vp_grammar)\n",
    "\n",
    "sentences = [\n",
    "    \"She is running quickly.\",\n",
    "    \"They have been working hard.\",\n",
    "    \"He can swim very fast.\",\n",
    "    \"The dog was barking loudly.\",\n",
    "]\n",
    "\n",
    "print(\"Verb Phrase Chunking\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sent in sentences:\n",
    "    tagged = pos_tag(word_tokenize(sent))\n",
    "    tree = vp_parser.parse(tagged)\n",
    "    \n",
    "    vps = [' '.join(w for w, t in subtree.leaves()) \n",
    "           for subtree in tree if isinstance(subtree, Tree)]\n",
    "    \n",
    "    print(f\"\\nSentence: {sent}\")\n",
    "    print(f\"VPs: {vps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f01fbdf",
   "metadata": {},
   "source": [
    "## 9.5 Chinking (Excluding Patterns)\n",
    "\n",
    "**Chinking** removes certain patterns from chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8623deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk everything, then exclude verbs and prepositions\n",
    "chink_grammar = r\"\"\"\n",
    "    NP: {<.*>+}         # Chunk everything\n",
    "        }<VB.*|IN>{     # Chink verbs and prepositions\n",
    "\"\"\"\n",
    "\n",
    "chink_parser = RegexpParser(chink_grammar)\n",
    "\n",
    "sentence = \"The dog ran through the park and jumped over the fence.\"\n",
    "tagged = pos_tag(word_tokenize(sentence))\n",
    "\n",
    "print(f\"Sentence: {sentence}\\n\")\n",
    "print(\"Tagged:\")\n",
    "print(tagged)\n",
    "\n",
    "tree = chink_parser.parse(tagged)\n",
    "print(\"\\nChunked (with chinking):\")\n",
    "tree.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with and without chinking\n",
    "sentence = \"The cat sat on the mat near the door.\"\n",
    "tagged = pos_tag(word_tokenize(sentence))\n",
    "\n",
    "# Without chinking - everything becomes one chunk\n",
    "no_chink = RegexpParser(\"NP: {<.*>+}\")\n",
    "tree1 = no_chink.parse(tagged)\n",
    "\n",
    "# With chinking - breaks at prepositions\n",
    "with_chink = RegexpParser(r\"NP: {<.*>+} }<IN>{\")\n",
    "tree2 = with_chink.parse(tagged)\n",
    "\n",
    "print(f\"Sentence: {sentence}\\n\")\n",
    "\n",
    "print(\"Without chinking:\")\n",
    "tree1.pprint()\n",
    "\n",
    "print(\"\\nWith chinking (exclude prepositions):\")\n",
    "tree2.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8883a0",
   "metadata": {},
   "source": [
    "## 9.6 Complex Multi-Level Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfdd020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-level chunking grammar\n",
    "complex_grammar = r\"\"\"\n",
    "    NP: {<DT|PRP\\$>?<JJ>*<NN.*>+}  # Noun phrases\n",
    "    VP: {<VB.*>+}                   # Verb phrases\n",
    "    PP: {<IN><NP>}                  # Prepositional phrases\n",
    "    CLAUSE: {<NP><VP><NP>?<PP>*}   # Simple clause\n",
    "\"\"\"\n",
    "\n",
    "complex_parser = RegexpParser(complex_grammar)\n",
    "\n",
    "sentence = \"The young student studies hard in the library.\"\n",
    "tagged = pos_tag(word_tokenize(sentence))\n",
    "\n",
    "print(f\"Sentence: {sentence}\\n\")\n",
    "print(\"Tagged:\")\n",
    "for word, tag in tagged:\n",
    "    print(f\"  {word}: {tag}\")\n",
    "\n",
    "tree = complex_parser.parse(tagged)\n",
    "print(\"\\nChunked tree:\")\n",
    "tree.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101eef7f",
   "metadata": {},
   "source": [
    "## 9.7 Extracting Chunks Programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b7d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunks(text, grammar):\n",
    "    \"\"\"Extract chunks from text using given grammar\"\"\"\n",
    "    parser = RegexpParser(grammar)\n",
    "    tagged = pos_tag(word_tokenize(text))\n",
    "    tree = parser.parse(tagged)\n",
    "    \n",
    "    chunks = {}\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() != 'S':  # Skip root\n",
    "            chunk_type = subtree.label()\n",
    "            chunk_text = ' '.join(word for word, tag in subtree.leaves())\n",
    "            \n",
    "            if chunk_type not in chunks:\n",
    "                chunks[chunk_type] = []\n",
    "            chunks[chunk_type].append(chunk_text)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4efd0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "    NP: {<DT|PRP\\$>?<JJ>*<NN.*>+}\n",
    "    VP: {<VB.*><RB>?}\n",
    "\"\"\"\n",
    "\n",
    "text = \"The clever student quickly solved the difficult math problem.\"\n",
    "\n",
    "print(f\"Text: {text}\\n\")\n",
    "\n",
    "chunks = extract_chunks(text, grammar)\n",
    "\n",
    "for chunk_type, chunk_list in chunks.items():\n",
    "    print(f\"{chunk_type}: {chunk_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47db8f",
   "metadata": {},
   "source": [
    "## 9.8 Practical: Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5fd4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_verb_object(sentence):\n",
    "    \"\"\"Simple SVO extraction using chunking\"\"\"\n",
    "    # Grammar for SVO patterns\n",
    "    grammar = r\"\"\"\n",
    "        NP: {<DT|PRP\\$>?<JJ>*<NN.*>+|<PRP>|<NNP>+}\n",
    "        VP: {<VB.*>}\n",
    "    \"\"\"\n",
    "    \n",
    "    parser = RegexpParser(grammar)\n",
    "    tagged = pos_tag(word_tokenize(sentence))\n",
    "    tree = parser.parse(tagged)\n",
    "    \n",
    "    chunks = []\n",
    "    for subtree in tree:\n",
    "        if isinstance(subtree, Tree):\n",
    "            chunk_type = subtree.label()\n",
    "            chunk_text = ' '.join(w for w, t in subtree.leaves())\n",
    "            chunks.append((chunk_type, chunk_text))\n",
    "    \n",
    "    # Simple heuristic: first NP = subject, VP = verb, second NP = object\n",
    "    nps = [text for ctype, text in chunks if ctype == 'NP']\n",
    "    vps = [text for ctype, text in chunks if ctype == 'VP']\n",
    "    \n",
    "    return {\n",
    "        'subject': nps[0] if len(nps) > 0 else None,\n",
    "        'verb': vps[0] if len(vps) > 0 else None,\n",
    "        'object': nps[1] if len(nps) > 1 else None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f02c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The cat chased the mouse.\",\n",
    "    \"John loves pizza.\",\n",
    "    \"The happy children played games.\",\n",
    "    \"Scientists discovered a new planet.\",\n",
    "    \"She wrote an interesting book.\",\n",
    "]\n",
    "\n",
    "print(\"Subject-Verb-Object Extraction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sent in sentences:\n",
    "    svo = extract_subject_verb_object(sent)\n",
    "    print(f\"\\n{sent}\")\n",
    "    print(f\"  Subject: {svo['subject']}\")\n",
    "    print(f\"  Verb:    {svo['verb']}\")\n",
    "    print(f\"  Object:  {svo['object']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e61556d",
   "metadata": {},
   "source": [
    "## 9.9 Chunk Parser Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b7e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkExtractor:\n",
    "    \"\"\"Reusable chunk extraction utility\"\"\"\n",
    "    \n",
    "    DEFAULT_GRAMMAR = r\"\"\"\n",
    "        NP: {<DT|PRP\\$>?<JJ>*<NN.*>+}\n",
    "        VP: {<VB.*>+<RB>?}\n",
    "        PP: {<IN><DT>?<JJ>*<NN.*>+}\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, grammar=None):\n",
    "        self.grammar = grammar or self.DEFAULT_GRAMMAR\n",
    "        self.parser = RegexpParser(self.grammar)\n",
    "    \n",
    "    def parse(self, text):\n",
    "        \"\"\"Parse text and return tree\"\"\"\n",
    "        tagged = pos_tag(word_tokenize(text))\n",
    "        return self.parser.parse(tagged)\n",
    "    \n",
    "    def extract_all(self, text):\n",
    "        \"\"\"Extract all chunks as dict\"\"\"\n",
    "        tree = self.parse(text)\n",
    "        chunks = {}\n",
    "        \n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() != 'S':\n",
    "                ctype = subtree.label()\n",
    "                ctext = ' '.join(w for w, t in subtree.leaves())\n",
    "                \n",
    "                if ctype not in chunks:\n",
    "                    chunks[ctype] = []\n",
    "                chunks[ctype].append(ctext)\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def get_noun_phrases(self, text):\n",
    "        \"\"\"Get noun phrases only\"\"\"\n",
    "        chunks = self.extract_all(text)\n",
    "        return chunks.get('NP', [])\n",
    "    \n",
    "    def get_verb_phrases(self, text):\n",
    "        \"\"\"Get verb phrases only\"\"\"\n",
    "        chunks = self.extract_all(text)\n",
    "        return chunks.get('VP', [])\n",
    "    \n",
    "    def get_prep_phrases(self, text):\n",
    "        \"\"\"Get prepositional phrases only\"\"\"\n",
    "        chunks = self.extract_all(text)\n",
    "        return chunks.get('PP', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5143a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the class\n",
    "chunker = ChunkExtractor()\n",
    "\n",
    "text = \"The young scientist conducted experiments in the modern laboratory.\"\n",
    "\n",
    "print(f\"Text: {text}\\n\")\n",
    "\n",
    "print(f\"Noun Phrases: {chunker.get_noun_phrases(text)}\")\n",
    "print(f\"Verb Phrases: {chunker.get_verb_phrases(text)}\")\n",
    "print(f\"Prep Phrases: {chunker.get_prep_phrases(text)}\")\n",
    "\n",
    "print(f\"\\nAll chunks:\")\n",
    "for ctype, chunks in chunker.extract_all(text).items():\n",
    "    print(f\"  {ctype}: {chunks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12abb838",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Syntax | Meaning |\n",
    "|--------|----------|\n",
    "| `{pattern}` | Chunk (include) |\n",
    "| `}pattern{` | Chink (exclude) |\n",
    "| `<TAG>` | Match tag |\n",
    "| `<TAG1\\|TAG2>` | Match either |\n",
    "| `?` | Optional |\n",
    "| `*` | Zero or more |\n",
    "| `+` | One or more |\n",
    "\n",
    "### Common Patterns\n",
    "```python\n",
    "# Noun phrase\n",
    "NP: {<DT>?<JJ>*<NN.*>+}\n",
    "\n",
    "# Verb phrase\n",
    "VP: {<VB.*>+}\n",
    "\n",
    "# Prepositional phrase\n",
    "PP: {<IN><NP>}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
