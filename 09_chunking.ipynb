{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d023689e",
   "metadata": {},
   "source": [
    "# NLTK Complete Guide - Section 9: Chunking\n",
    "\n",
    "This notebook covers:\n",
    "- What is Chunking?\n",
    "- Noun Phrase Chunking\n",
    "- Chunk Grammar Rules\n",
    "- Chinking (Excluding Patterns)\n",
    "- Custom Chunkers\n",
    "- Practical Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f95901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.chunk import RegexpParser\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b7a4a",
   "metadata": {},
   "source": [
    "## 9.1 What is Chunking?\n",
    "\n",
    "**Chunking** (also called **shallow parsing**) is an NLP technique that groups words into meaningful phrases based on their Part-of-Speech (POS) tags. Unlike full parsing which builds complete syntactic trees, chunking identifies flat, non-overlapping segments of text.\n",
    "\n",
    "### Why Use Chunking?\n",
    "\n",
    "1. **Information Extraction**: Identify key entities and relationships in text\n",
    "2. **Text Summarization**: Extract important noun phrases for summaries\n",
    "3. **Question Answering**: Find candidate answers by extracting relevant phrases\n",
    "4. **Named Entity Recognition**: Often used as a preprocessing step\n",
    "\n",
    "### Common Chunk Types\n",
    "\n",
    "| Chunk Type | Description | Examples |\n",
    "|------------|-------------|----------|\n",
    "| **NP** (Noun Phrase) | Groups around a noun | \"the big dog\", \"a beautiful sunset\" |\n",
    "| **VP** (Verb Phrase) | Groups around a verb | \"is running\", \"has been working\" |\n",
    "| **PP** (Prepositional Phrase) | Preposition + NP | \"in the house\", \"on the table\" |\n",
    "| **ADVP** (Adverb Phrase) | Groups around an adverb | \"very quickly\", \"extremely well\" |\n",
    "\n",
    "### How Chunking Works\n",
    "\n",
    "Chunking uses **regular expression patterns** over POS tags to identify phrase boundaries. The process is:\n",
    "\n",
    "1. **Tokenize** the text into words\n",
    "2. **POS tag** each token\n",
    "3. **Apply chunk grammar rules** to group tokens into phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60e22ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tagged:\n",
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# POS tag the sentence\n",
    "tokens = word_tokenize(sentence)\n",
    "tagged = pos_tag(tokens)\n",
    "\n",
    "print(\"POS Tagged:\")\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e41bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked:\n",
      "(S\n",
      "  (NP The/DT quick/JJ brown/NN fox/NN)\n",
      "  jumps/VBZ\n",
      "  over/IN\n",
      "  (NP the/DT lazy/JJ dog/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# Define a simple noun phrase grammar\n",
    "# NP: Determiner + Adjective(s) + Noun\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN.*>+}\"\n",
    "\n",
    "# Create a chunk parser\n",
    "chunk_parser = RegexpParser(grammar)\n",
    "\n",
    "# Parse the tagged sentence\n",
    "tree = chunk_parser.parse(tagged)\n",
    "\n",
    "print(\"Chunked:\")\n",
    "tree.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348b31c9",
   "metadata": {},
   "source": [
    "## 9.2 Chunk Grammar Syntax\n",
    "\n",
    "NLTK uses a special syntax for defining chunk patterns. The grammar is based on **regular expressions** that match sequences of POS tags.\n",
    "\n",
    "### Basic Syntax Elements\n",
    "\n",
    "| Symbol | Meaning | Example |\n",
    "|--------|---------|---------|\n",
    "| `<TAG>` | Match a specific POS tag | `<NN>` matches nouns |\n",
    "| `<TAG1\\|TAG2>` | Match either tag | `<NN\\|NNS>` matches singular or plural nouns |\n",
    "| `<TAG.*>` | Wildcard matching | `<NN.*>` matches NN, NNS, NNP, NNPS |\n",
    "| `?` | Optional (0 or 1) | `<DT>?` matches zero or one determiner |\n",
    "| `*` | Zero or more | `<JJ>*` matches any number of adjectives |\n",
    "| `+` | One or more | `<NN>+` matches one or more nouns |\n",
    "| `{pattern}` | **Chunk** - include this pattern | `{<DT><NN>}` groups DT+NN together |\n",
    "| `}pattern{` | **Chink** - exclude this pattern | `}<VB>{` removes verbs from chunks |\n",
    "\n",
    "### Understanding the Grammar Format\n",
    "\n",
    "```\n",
    "CHUNK_LABEL: {<pattern>}\n",
    "```\n",
    "\n",
    "- **CHUNK_LABEL**: The name for the chunk type (e.g., NP, VP, PP)\n",
    "- **{...}**: Curly braces indicate what to include in the chunk\n",
    "- **<...>**: Angle brackets contain POS tag patterns\n",
    "\n",
    "### Common POS Tags Reference\n",
    "\n",
    "| Tag | Description | Example |\n",
    "|-----|-------------|---------|\n",
    "| DT | Determiner | the, a, an |\n",
    "| JJ | Adjective | big, red, fast |\n",
    "| NN | Singular noun | dog, cat, house |\n",
    "| NNS | Plural noun | dogs, cats |\n",
    "| NNP | Proper noun | John, London |\n",
    "| VB | Base verb | run, eat |\n",
    "| VBD | Past tense verb | ran, ate |\n",
    "| VBG | Gerund/present participle | running, eating |\n",
    "| IN | Preposition | in, on, at |\n",
    "| RB | Adverb | quickly, very |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eacf3ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The quick brown fox jumps quickly over the lazy dog.\n",
      "Tagged: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'NNS'), ('quickly', 'RB'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n",
      "\n",
      "Simple NP: ['brown', 'fox', 'dog']\n",
      "NP with adjectives: ['The quick brown', 'fox', 'the lazy dog']\n",
      "NP with multiple nouns: ['The quick brown fox jumps', 'the lazy dog']\n",
      "Verb phrase: []\n",
      "Prepositional phrase: []\n"
     ]
    }
   ],
   "source": [
    "# Different grammar patterns\n",
    "grammars = {\n",
    "    \"Simple NP\": \"NP: {<DT>?<NN>}\",\n",
    "    \"NP with adjectives\": \"NP: {<DT>?<JJ>*<NN>}\",\n",
    "    \"NP with multiple nouns\": \"NP: {<DT>?<JJ>*<NN.*>+}\",\n",
    "    \"Verb phrase\": \"VP: {<VB.*><RB>?}\",\n",
    "    \"Prepositional phrase\": \"PP: {<IN><DT>?<NN.*>}\",\n",
    "}\n",
    "\n",
    "sentence = \"The quick brown fox jumps quickly over the lazy dog.\"\n",
    "tagged = pos_tag(word_tokenize(sentence))\n",
    "\n",
    "print(f\"Sentence: {sentence}\")\n",
    "print(f\"Tagged: {tagged}\\n\")\n",
    "\n",
    "for name, grammar in grammars.items():\n",
    "    parser = RegexpParser(grammar)\n",
    "    tree = parser.parse(tagged)\n",
    "    \n",
    "    # Extract chunks\n",
    "    chunks = []\n",
    "    for subtree in tree:\n",
    "        if isinstance(subtree, Tree):\n",
    "            chunk_text = ' '.join(word for word, tag in subtree.leaves())\n",
    "            chunks.append(chunk_text)\n",
    "    \n",
    "    print(f\"{name}: {chunks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495582bd",
   "metadata": {},
   "source": [
    "## 9.3 Noun Phrase Chunking (NP)\n",
    "\n",
    "**Noun Phrases (NPs)** are the most commonly chunked phrase type. They typically consist of:\n",
    "\n",
    "- **Head noun**: The main noun (required)\n",
    "- **Determiner**: Articles like \"the\", \"a\", possessives like \"my\" (optional)\n",
    "- **Modifiers**: Adjectives that describe the noun (optional)\n",
    "\n",
    "### Common NP Patterns\n",
    "\n",
    "| Pattern | Matches | Example |\n",
    "|---------|---------|---------|\n",
    "| `{<NN>}` | Single noun | \"dog\" |\n",
    "| `{<DT><NN>}` | Determiner + noun | \"the dog\" |\n",
    "| `{<DT>?<JJ>*<NN>}` | Optional det + adjectives + noun | \"the big brown dog\" |\n",
    "| `{<DT>?<JJ>*<NN.*>+}` | Handles noun variants | \"the quick brown fox\" |\n",
    "| `{<NNP>+}` | Proper noun sequences | \"New York City\" |\n",
    "| `{<PRP>}` | Pronouns | \"she\", \"they\" |\n",
    "\n",
    "### Multi-Rule Grammars\n",
    "\n",
    "You can define multiple patterns for the same chunk type. NLTK applies rules in order, so more specific patterns should come first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da7310f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun Phrase Chunking\n",
      "============================================================\n",
      "\n",
      "Sentence: The big brown dog chased the small cat.\n",
      "NPs: ['The big brown dog', 'the small cat']\n",
      "\n",
      "Sentence: My beautiful garden has colorful flowers.\n",
      "NPs: ['My beautiful garden', 'colorful flowers']\n",
      "\n",
      "Sentence: John and Mary visited New York City.\n",
      "NPs: ['John', 'Mary', 'New York City']\n",
      "\n",
      "Sentence: She bought an expensive red sports car.\n",
      "NPs: ['She', 'an expensive red sports car']\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive NP grammar\n",
    "np_grammar = r\"\"\"\n",
    "    NP: {<DT|PRP\\$>?<JJ>*<NN.*>+}   # Determiner + adjectives + nouns\n",
    "        {<NNP>+}                      # Proper nouns\n",
    "        {<PRP>}                       # Pronouns\n",
    "\"\"\"\n",
    "\n",
    "np_parser = RegexpParser(np_grammar)\n",
    "\n",
    "sentences = [\n",
    "    \"The big brown dog chased the small cat.\",\n",
    "    \"My beautiful garden has colorful flowers.\",\n",
    "    \"John and Mary visited New York City.\",\n",
    "    \"She bought an expensive red sports car.\",\n",
    "]\n",
    "\n",
    "print(\"Noun Phrase Chunking\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sent in sentences:\n",
    "    tagged = pos_tag(word_tokenize(sent))\n",
    "    tree = np_parser.parse(tagged)\n",
    "    \n",
    "    nps = [' '.join(w for w, t in subtree.leaves()) \n",
    "           for subtree in tree if isinstance(subtree, Tree)]\n",
    "    \n",
    "    print(f\"\\nSentence: {sent}\")\n",
    "    print(f\"NPs: {nps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045ba0e0",
   "metadata": {},
   "source": [
    "## 9.4 Verb Phrase Chunking (VP)\n",
    "\n",
    "**Verb Phrases (VPs)** capture the action part of a sentence. They can include:\n",
    "\n",
    "- **Main verb**: The action word (required)\n",
    "- **Auxiliary verbs**: \"is\", \"have\", \"will\" (optional)\n",
    "- **Adverbs**: Modifiers like \"quickly\", \"always\" (optional)\n",
    "- **Modal verbs**: \"can\", \"should\", \"must\" (optional)\n",
    "\n",
    "### Common VP Patterns\n",
    "\n",
    "| Pattern | Matches | Example |\n",
    "|---------|---------|---------|\n",
    "| `{<VB>}` | Base verb | \"run\" |\n",
    "| `{<VB.*>}` | Any verb form | \"runs\", \"running\", \"ran\" |\n",
    "| `{<VB.*><RB>?}` | Verb + optional adverb | \"runs quickly\" |\n",
    "| `{<MD><VB>}` | Modal + verb | \"can swim\" |\n",
    "| `{<VB.*>+}` | Verb sequences | \"has been running\" |\n",
    "\n",
    "### Verb POS Tags\n",
    "\n",
    "| Tag | Description | Example |\n",
    "|-----|-------------|---------|\n",
    "| VB | Base form | run, eat |\n",
    "| VBD | Past tense | ran, ate |\n",
    "| VBG | Gerund (-ing) | running, eating |\n",
    "| VBN | Past participle | run, eaten |\n",
    "| VBP | Present, non-3rd person | run, eat |\n",
    "| VBZ | Present, 3rd person | runs, eats |\n",
    "| MD | Modal | can, will, should |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a45ba92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verb Phrase Chunking\n",
      "============================================================\n",
      "\n",
      "Sentence: She is running quickly.\n",
      "VPs: ['is running']\n",
      "\n",
      "Sentence: They have been working hard.\n",
      "VPs: ['have been working']\n",
      "\n",
      "Sentence: He can swim very fast.\n",
      "VPs: ['swim very']\n",
      "\n",
      "Sentence: The dog was barking loudly.\n",
      "VPs: ['was barking']\n"
     ]
    }
   ],
   "source": [
    "# Verb phrase grammar\n",
    "vp_grammar = r\"\"\"\n",
    "    VP: {<VB.*><RB.*>?<VB.*>*}  # Verb + optional adverb + more verbs\n",
    "        {<MD><VB>}              # Modal + base verb\n",
    "\"\"\"\n",
    "\n",
    "vp_parser = RegexpParser(vp_grammar)\n",
    "\n",
    "sentences = [\n",
    "    \"She is running quickly.\",\n",
    "    \"They have been working hard.\",\n",
    "    \"He can swim very fast.\",\n",
    "    \"The dog was barking loudly.\",\n",
    "]\n",
    "\n",
    "print(\"Verb Phrase Chunking\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sent in sentences:\n",
    "    tagged = pos_tag(word_tokenize(sent))\n",
    "    tree = vp_parser.parse(tagged)\n",
    "    \n",
    "    vps = [' '.join(w for w, t in subtree.leaves()) \n",
    "           for subtree in tree if isinstance(subtree, Tree)]\n",
    "    \n",
    "    print(f\"\\nSentence: {sent}\")\n",
    "    print(f\"VPs: {vps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f01fbdf",
   "metadata": {},
   "source": [
    "## 9.5 Chinking (Excluding Patterns)\n",
    "\n",
    "**Chinking** is the opposite of chunking - it **removes** elements from existing chunks. This is useful when you want to:\n",
    "\n",
    "1. **Break apart large chunks** at certain boundaries\n",
    "2. **Exclude specific word types** from phrases\n",
    "3. **Create cleaner, more meaningful chunks**\n",
    "\n",
    "### Chinking Syntax\n",
    "\n",
    "```\n",
    "}pattern{    # Note: braces are REVERSED compared to chunking\n",
    "```\n",
    "\n",
    "The reversed braces `}...{` indicate \"exclude this pattern\" from the chunk.\n",
    "\n",
    "### How Chinking Works\n",
    "\n",
    "1. First, a chunk rule groups tokens together\n",
    "2. Then, a chink rule \"punches holes\" in the chunk\n",
    "3. The result is the original chunk split at the chinked elements\n",
    "\n",
    "### Chinking Strategy\n",
    "\n",
    "A common approach is to:\n",
    "1. **Chunk everything**: `{<.*>+}` - grab all tokens\n",
    "2. **Chink at boundaries**: `}<VB.*|IN>{` - split at verbs and prepositions\n",
    "\n",
    "This effectively creates noun phrases by excluding verbs and prepositions.\n",
    "\n",
    "### Important: Grammar Rules Must Be on Separate Lines\n",
    "\n",
    "When combining chunk and chink rules, each rule must be on its own line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8623deae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The dog ran through the park and jumped over the fence.\n",
      "\n",
      "Tagged:\n",
      "[('The', 'DT'), ('dog', 'NN'), ('ran', 'VBD'), ('through', 'IN'), ('the', 'DT'), ('park', 'NN'), ('and', 'CC'), ('jumped', 'VBD'), ('over', 'IN'), ('the', 'DT'), ('fence', 'NN'), ('.', '.')]\n",
      "\n",
      "Chunked (with chinking):\n",
      "(S\n",
      "  (NP The/DT dog/NN)\n",
      "  ran/VBD\n",
      "  through/IN\n",
      "  (NP the/DT park/NN and/CC)\n",
      "  jumped/VBD\n",
      "  over/IN\n",
      "  (NP the/DT fence/NN ./.))\n"
     ]
    }
   ],
   "source": [
    "# Chunk everything, then exclude verbs and prepositions\n",
    "chink_grammar = r\"\"\"\n",
    "    NP: {<.*>+}         # Chunk everything\n",
    "        }<VB.*|IN>{     # Chink verbs and prepositions\n",
    "\"\"\"\n",
    "\n",
    "chink_parser = RegexpParser(chink_grammar)\n",
    "\n",
    "sentence = \"The dog ran through the park and jumped over the fence.\"\n",
    "tagged = pos_tag(word_tokenize(sentence))\n",
    "\n",
    "print(f\"Sentence: {sentence}\\n\")\n",
    "print(\"Tagged:\")\n",
    "print(tagged)\n",
    "\n",
    "tree = chink_parser.parse(tagged)\n",
    "print(\"\\nChunked (with chinking):\")\n",
    "tree.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e48116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The cat sat on the mat near the door.\n",
      "\n",
      "Without chinking:\n",
      "(S\n",
      "  (NP\n",
      "    The/DT\n",
      "    cat/NN\n",
      "    sat/VBD\n",
      "    on/IN\n",
      "    the/DT\n",
      "    mat/NN\n",
      "    near/IN\n",
      "    the/DT\n",
      "    door/NN\n",
      "    ./.))\n",
      "\n",
      "With chinking (exclude prepositions):\n",
      "(S\n",
      "  (NP The/DT cat/NN sat/VBD)\n",
      "  on/IN\n",
      "  (NP the/DT mat/NN)\n",
      "  near/IN\n",
      "  (NP the/DT door/NN ./.))\n"
     ]
    }
   ],
   "source": [
    "# Compare with and without chinking\n",
    "sentence = \"The cat sat on the mat near the door.\"\n",
    "tagged = pos_tag(word_tokenize(sentence))\n",
    "\n",
    "# Without chinking - everything becomes one chunk\n",
    "no_chink = RegexpParser(\"NP: {<.*>+}\")\n",
    "tree1 = no_chink.parse(tagged)\n",
    "\n",
    "# With chinking - breaks at prepositions\n",
    "with_chink = RegexpParser(r\"\"\"\n",
    "    NP: {<.*>+}\n",
    "        }<IN>{\n",
    "\"\"\")\n",
    "tree2 = with_chink.parse(tagged)\n",
    "\n",
    "print(f\"Sentence: {sentence}\\n\")\n",
    "\n",
    "print(\"Without chinking:\")\n",
    "tree1.pprint()\n",
    "\n",
    "print(\"\\nWith chinking (exclude prepositions):\")\n",
    "tree2.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8883a0",
   "metadata": {},
   "source": [
    "## 9.6 Complex Multi-Level Grammar\n",
    "\n",
    "NLTK's `RegexpParser` supports **cascaded chunking**, where you can define multiple chunk types and even nest them. Rules are applied in order from top to bottom.\n",
    "\n",
    "### Cascaded Chunking Process\n",
    "\n",
    "1. **First pass**: Identify basic chunks (NP, VP)\n",
    "2. **Second pass**: Combine basic chunks into larger structures (PP, CLAUSE)\n",
    "3. **Result**: Hierarchical phrase structure\n",
    "\n",
    "### Building Complex Grammars\n",
    "\n",
    "When designing multi-level grammars:\n",
    "\n",
    "- **Order matters**: Define base chunks before compound chunks\n",
    "- **Reference other chunks**: Use chunk labels in later patterns (e.g., `<NP>` after NP is defined)\n",
    "- **Keep it simple**: Complex grammars can be hard to debug\n",
    "\n",
    "### Example Structure\n",
    "\n",
    "```\n",
    "NP: {<DT>?<JJ>*<NN.*>+}    # Level 1: Basic noun phrases\n",
    "VP: {<VB.*>+}               # Level 1: Basic verb phrases  \n",
    "PP: {<IN><NP>}              # Level 2: Preposition + NP\n",
    "CLAUSE: {<NP><VP><NP>?}     # Level 3: Subject + Verb + Object\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbfdd020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The young student studies hard in the library.\n",
      "\n",
      "Tagged:\n",
      "  The: DT\n",
      "  young: JJ\n",
      "  student: NN\n",
      "  studies: NNS\n",
      "  hard: VBP\n",
      "  in: IN\n",
      "  the: DT\n",
      "  library: NN\n",
      "  .: .\n",
      "\n",
      "Chunked tree:\n",
      "(S\n",
      "  (CLAUSE\n",
      "    (NP The/DT young/JJ student/NN studies/NNS)\n",
      "    (VP hard/VBP)\n",
      "    (PP in/IN (NP the/DT library/NN)))\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# Multi-level chunking grammar\n",
    "complex_grammar = r\"\"\"\n",
    "    NP: {<DT|PRP\\$>?<JJ>*<NN.*>+}  # Noun phrases\n",
    "    VP: {<VB.*>+}                   # Verb phrases\n",
    "    PP: {<IN><NP>}                  # Prepositional phrases\n",
    "    CLAUSE: {<NP><VP><NP>?<PP>*}   # Simple clause\n",
    "\"\"\"\n",
    "\n",
    "complex_parser = RegexpParser(complex_grammar)\n",
    "\n",
    "sentence = \"The young student studies hard in the library.\"\n",
    "tagged = pos_tag(word_tokenize(sentence))\n",
    "\n",
    "print(f\"Sentence: {sentence}\\n\")\n",
    "print(\"Tagged:\")\n",
    "for word, tag in tagged:\n",
    "    print(f\"  {word}: {tag}\")\n",
    "\n",
    "tree = complex_parser.parse(tagged)\n",
    "print(\"\\nChunked tree:\")\n",
    "tree.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101eef7f",
   "metadata": {},
   "source": [
    "## 9.7 Extracting Chunks Programmatically\n",
    "\n",
    "The chunker returns a **tree structure** where:\n",
    "- The root node is labeled 'S' (sentence)\n",
    "- Chunk nodes are labeled with their chunk type (NP, VP, etc.)\n",
    "- Leaf nodes contain the original (word, tag) tuples\n",
    "\n",
    "### Key Methods for Working with Chunk Trees\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `tree.subtrees()` | Iterate over all subtrees (including root) |\n",
    "| `tree.leaves()` | Get all (word, tag) pairs |\n",
    "| `subtree.label()` | Get the chunk label (NP, VP, S) |\n",
    "| `isinstance(node, Tree)` | Check if node is a chunk (vs. unchunked word) |\n",
    "\n",
    "### Extracting Chunks as Text\n",
    "\n",
    "To get the actual words in a chunk:\n",
    "```python\n",
    "chunk_text = ' '.join(word for word, tag in subtree.leaves())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b7d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunks(text, grammar):\n",
    "    \"\"\"Extract chunks from text using given grammar\"\"\"\n",
    "    parser = RegexpParser(grammar)\n",
    "    tagged = pos_tag(word_tokenize(text))\n",
    "    tree = parser.parse(tagged)\n",
    "    \n",
    "    chunks = {}\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() != 'S':  # Skip root\n",
    "            chunk_type = subtree.label()\n",
    "            chunk_text = ' '.join(word for word, tag in subtree.leaves())\n",
    "            \n",
    "            if chunk_type not in chunks:\n",
    "                chunks[chunk_type] = []\n",
    "            chunks[chunk_type].append(chunk_text)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4efd0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The clever student quickly solved the difficult math problem.\n",
      "\n",
      "NP: ['The clever student', 'the difficult math problem']\n",
      "VP: ['solved']\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "    NP: {<DT|PRP\\$>?<JJ>*<NN.*>+}\n",
    "    VP: {<VB.*><RB>?}\n",
    "\"\"\"\n",
    "\n",
    "text = \"The clever student quickly solved the difficult math problem.\"\n",
    "\n",
    "print(f\"Text: {text}\\n\")\n",
    "\n",
    "chunks = extract_chunks(text, grammar)\n",
    "\n",
    "for chunk_type, chunk_list in chunks.items():\n",
    "    print(f\"{chunk_type}: {chunk_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47db8f",
   "metadata": {},
   "source": [
    "## 9.8 Practical: Information Extraction\n",
    "\n",
    "One of the most useful applications of chunking is **information extraction** - automatically identifying structured information from unstructured text.\n",
    "\n",
    "### Subject-Verb-Object (SVO) Extraction\n",
    "\n",
    "In English, simple sentences follow the **SVO pattern**:\n",
    "- **Subject**: Who/what performs the action (usually first NP)\n",
    "- **Verb**: The action (VP)\n",
    "- **Object**: Who/what receives the action (usually second NP)\n",
    "\n",
    "Example: \"**The cat** (S) **chased** (V) **the mouse** (O).\"\n",
    "\n",
    "### Applications of SVO Extraction\n",
    "\n",
    "1. **Knowledge graph construction**: Build relationships between entities\n",
    "2. **Summarization**: Extract key facts from documents\n",
    "3. **Question answering**: Find answers to \"who did what\" questions\n",
    "4. **Sentiment analysis**: Identify what entity is associated with sentiment\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Simple chunking-based SVO extraction has limitations:\n",
    "- Doesn't handle passive voice well (\"The mouse was chased by the cat\")\n",
    "- Struggles with complex sentences (subordinate clauses, relative pronouns)\n",
    "- May miss indirect objects (\"She gave **him** the book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf5fd4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_verb_object(sentence):\n",
    "    \"\"\"Simple SVO extraction using chunking\"\"\"\n",
    "    # Grammar for SVO patterns\n",
    "    grammar = r\"\"\"\n",
    "        NP: {<DT|PRP\\$>?<JJ>*<NN.*>+|<PRP>|<NNP>+}\n",
    "        VP: {<VB.*>}\n",
    "    \"\"\"\n",
    "    \n",
    "    parser = RegexpParser(grammar)\n",
    "    tagged = pos_tag(word_tokenize(sentence))\n",
    "    tree = parser.parse(tagged)\n",
    "    \n",
    "    chunks = []\n",
    "    for subtree in tree:\n",
    "        if isinstance(subtree, Tree):\n",
    "            chunk_type = subtree.label()\n",
    "            chunk_text = ' '.join(w for w, t in subtree.leaves())\n",
    "            chunks.append((chunk_type, chunk_text))\n",
    "    \n",
    "    # Simple heuristic: first NP = subject, VP = verb, second NP = object\n",
    "    nps = [text for ctype, text in chunks if ctype == 'NP']\n",
    "    vps = [text for ctype, text in chunks if ctype == 'VP']\n",
    "    \n",
    "    return {\n",
    "        'subject': nps[0] if len(nps) > 0 else None,\n",
    "        'verb': vps[0] if len(vps) > 0 else None,\n",
    "        'object': nps[1] if len(nps) > 1 else None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42f02c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject-Verb-Object Extraction\n",
      "============================================================\n",
      "\n",
      "The cat chased the mouse.\n",
      "  Subject: The cat\n",
      "  Verb:    chased\n",
      "  Object:  the mouse\n",
      "\n",
      "John loves pizza.\n",
      "  Subject: John\n",
      "  Verb:    loves\n",
      "  Object:  pizza\n",
      "\n",
      "The happy children played games.\n",
      "  Subject: The happy children\n",
      "  Verb:    played\n",
      "  Object:  games\n",
      "\n",
      "Scientists discovered a new planet.\n",
      "  Subject: Scientists\n",
      "  Verb:    discovered\n",
      "  Object:  a new planet\n",
      "\n",
      "She wrote an interesting book.\n",
      "  Subject: She\n",
      "  Verb:    wrote\n",
      "  Object:  an interesting book\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"The cat chased the mouse.\",\n",
    "    \"John loves pizza.\",\n",
    "    \"The happy children played games.\",\n",
    "    \"Scientists discovered a new planet.\",\n",
    "    \"She wrote an interesting book.\",\n",
    "]\n",
    "\n",
    "print(\"Subject-Verb-Object Extraction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sent in sentences:\n",
    "    svo = extract_subject_verb_object(sent)\n",
    "    print(f\"\\n{sent}\")\n",
    "    print(f\"  Subject: {svo['subject']}\")\n",
    "    print(f\"  Verb:    {svo['verb']}\")\n",
    "    print(f\"  Object:  {svo['object']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e61556d",
   "metadata": {},
   "source": [
    "## 9.9 Chunk Parser Class\n",
    "\n",
    "Creating a **reusable class** for chunking provides several benefits:\n",
    "\n",
    "1. **Encapsulation**: Grammar and parsing logic in one place\n",
    "2. **Convenience methods**: Easy access to specific chunk types\n",
    "3. **Extensibility**: Easy to add new methods or grammars\n",
    "4. **Consistency**: Same parsing behavior across your application\n",
    "\n",
    "### Design Considerations\n",
    "\n",
    "When building a chunking utility:\n",
    "- Provide **sensible defaults** but allow customization\n",
    "- Include methods for **common use cases** (get NPs, get VPs)\n",
    "- Consider **caching** parsed results for performance\n",
    "- Handle **edge cases** (empty text, no matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4b7e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkExtractor:\n",
    "    \"\"\"Reusable chunk extraction utility\"\"\"\n",
    "    \n",
    "    DEFAULT_GRAMMAR = r\"\"\"\n",
    "        NP: {<DT|PRP\\$>?<JJ>*<NN.*>+}\n",
    "        VP: {<VB.*>+<RB>?}\n",
    "        PP: {<IN><DT>?<JJ>*<NN.*>+}\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, grammar=None):\n",
    "        self.grammar = grammar or self.DEFAULT_GRAMMAR\n",
    "        self.parser = RegexpParser(self.grammar)\n",
    "    \n",
    "    def parse(self, text):\n",
    "        \"\"\"Parse text and return tree\"\"\"\n",
    "        tagged = pos_tag(word_tokenize(text))\n",
    "        return self.parser.parse(tagged)\n",
    "    \n",
    "    def extract_all(self, text):\n",
    "        \"\"\"Extract all chunks as dict\"\"\"\n",
    "        tree = self.parse(text)\n",
    "        chunks = {}\n",
    "        \n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() != 'S':\n",
    "                ctype = subtree.label()\n",
    "                ctext = ' '.join(w for w, t in subtree.leaves())\n",
    "                \n",
    "                if ctype not in chunks:\n",
    "                    chunks[ctype] = []\n",
    "                chunks[ctype].append(ctext)\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def get_noun_phrases(self, text):\n",
    "        \"\"\"Get noun phrases only\"\"\"\n",
    "        chunks = self.extract_all(text)\n",
    "        return chunks.get('NP', [])\n",
    "    \n",
    "    def get_verb_phrases(self, text):\n",
    "        \"\"\"Get verb phrases only\"\"\"\n",
    "        chunks = self.extract_all(text)\n",
    "        return chunks.get('VP', [])\n",
    "    \n",
    "    def get_prep_phrases(self, text):\n",
    "        \"\"\"Get prepositional phrases only\"\"\"\n",
    "        chunks = self.extract_all(text)\n",
    "        return chunks.get('PP', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea5143a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The young scientist conducted experiments in the modern laboratory.\n",
      "\n",
      "Noun Phrases: ['The young scientist', 'experiments', 'the modern laboratory']\n",
      "Verb Phrases: ['conducted']\n",
      "Prep Phrases: []\n",
      "\n",
      "All chunks:\n",
      "  NP: ['The young scientist', 'experiments', 'the modern laboratory']\n",
      "  VP: ['conducted']\n"
     ]
    }
   ],
   "source": [
    "# Use the class\n",
    "chunker = ChunkExtractor()\n",
    "\n",
    "text = \"The young scientist conducted experiments in the modern laboratory.\"\n",
    "\n",
    "print(f\"Text: {text}\\n\")\n",
    "\n",
    "print(f\"Noun Phrases: {chunker.get_noun_phrases(text)}\")\n",
    "print(f\"Verb Phrases: {chunker.get_verb_phrases(text)}\")\n",
    "print(f\"Prep Phrases: {chunker.get_prep_phrases(text)}\")\n",
    "\n",
    "print(f\"\\nAll chunks:\")\n",
    "for ctype, chunks in chunker.extract_all(text).items():\n",
    "    print(f\"  {ctype}: {chunks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12abb838",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Chunk Grammar Quick Reference\n",
    "\n",
    "| Syntax | Meaning | Example |\n",
    "|--------|---------|---------|\n",
    "| `{pattern}` | Chunk (include) | `{<DT><NN>}` |\n",
    "| `}pattern{` | Chink (exclude) | `}<IN>{` |\n",
    "| `<TAG>` | Match exact tag | `<NN>` |\n",
    "| `<TAG.*>` | Match tag prefix | `<NN.*>` matches NN, NNS, NNP |\n",
    "| `<TAG1\\|TAG2>` | Match either tag | `<NN\\|NNS>` |\n",
    "| `?` | Optional (0 or 1) | `<DT>?` |\n",
    "| `*` | Zero or more | `<JJ>*` |\n",
    "| `+` | One or more | `<NN>+` |\n",
    "\n",
    "### Common Chunk Patterns\n",
    "\n",
    "```python\n",
    "# Noun phrase - most common pattern\n",
    "NP: {<DT|PRP\\$>?<JJ>*<NN.*>+}\n",
    "\n",
    "# Verb phrase - captures verb sequences\n",
    "VP: {<VB.*>+}\n",
    "\n",
    "# Prepositional phrase - preposition followed by NP\n",
    "PP: {<IN><DT>?<JJ>*<NN.*>+}\n",
    "\n",
    "# Chunk everything, then exclude verbs/prepositions\n",
    "NP: {<.*>+}\n",
    "    }<VB.*|IN>{\n",
    "```\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Chunking is shallow parsing** - identifies phrases without full syntactic analysis\n",
    "2. **POS tags are essential** - chunking operates on tagged text\n",
    "3. **Grammar rules use regex-like syntax** - `?`, `*`, `+` work as expected\n",
    "4. **Chinking removes elements** - use reversed braces `}pattern{`\n",
    "5. **Rules must be on separate lines** - when combining chunk and chink rules\n",
    "6. **Order matters** - define base chunks before compound chunks\n",
    "\n",
    "### When to Use Chunking\n",
    "\n",
    "✅ **Good for:**\n",
    "- Information extraction\n",
    "- Named entity recognition preprocessing\n",
    "- Simple phrase identification\n",
    "- Text summarization\n",
    "- Building search indexes\n",
    "\n",
    "❌ **Not ideal for:**\n",
    "- Complex grammatical analysis\n",
    "- Handling long-distance dependencies\n",
    "- Parsing nested structures\n",
    "- Languages with free word order\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Section 10**: N-grams and Language Models\n",
    "- **Section 13**: Sentiment Analysis (uses chunking for feature extraction)\n",
    "- **Section 14**: Text Classification (chunking as preprocessing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
