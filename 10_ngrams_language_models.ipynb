{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbabdd27",
   "metadata": {},
   "source": [
    "# NLTK Complete Guide - Section 10: N-Grams & Language Models\n",
    "\n",
    "This notebook covers:\n",
    "- What are N-Grams?\n",
    "- Generating N-Grams\n",
    "- N-Gram Frequency Analysis\n",
    "- Collocations\n",
    "- Simple Language Models\n",
    "- Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e02d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('gutenberg', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "from nltk import ngrams, bigrams, trigrams\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures, TrigramAssocMeasures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85450599",
   "metadata": {},
   "source": [
    "## 10.1 What are N-Grams?\n",
    "\n",
    "**N-grams** are contiguous sequences of n items from text:\n",
    "\n",
    "| Type | N | Example (\"I love NLP\") |\n",
    "|------|---|------------------------|\n",
    "| Unigram | 1 | [\"I\", \"love\", \"NLP\"] |\n",
    "| Bigram | 2 | [(\"I\", \"love\"), (\"love\", \"NLP\")] |\n",
    "| Trigram | 3 | [(\"I\", \"love\", \"NLP\")] |\n",
    "| 4-gram | 4 | Not enough words! |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I love natural language processing\"\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Tokens: {tokens}\\n\")\n",
    "\n",
    "# Generate n-grams\n",
    "unigrams = list(ngrams(tokens, 1))\n",
    "bi_grams = list(ngrams(tokens, 2))\n",
    "tri_grams = list(ngrams(tokens, 3))\n",
    "four_grams = list(ngrams(tokens, 4))\n",
    "\n",
    "print(f\"Unigrams (1): {unigrams}\")\n",
    "print(f\"Bigrams (2):  {bi_grams}\")\n",
    "print(f\"Trigrams (3): {tri_grams}\")\n",
    "print(f\"4-grams (4):  {four_grams}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c2c8a4",
   "metadata": {},
   "source": [
    "## 10.2 NLTK Convenience Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "tokens = word_tokenize(text.lower())\n",
    "\n",
    "print(f\"Text: {text}\\n\")\n",
    "\n",
    "# Using convenience functions\n",
    "print(\"Bigrams (using bigrams()):\")\n",
    "for bg in bigrams(tokens):\n",
    "    print(f\"  {bg}\")\n",
    "\n",
    "print(\"\\nTrigrams (using trigrams()):\")\n",
    "for tg in trigrams(tokens):\n",
    "    print(f\"  {tg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09fcc3",
   "metadata": {},
   "source": [
    "## 10.3 N-Gram with Padding\n",
    "\n",
    "Add start/end markers for better language modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4256aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline, pad_both_ends\n",
    "\n",
    "text = \"I love NLP\"\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Tokens: {tokens}\\n\")\n",
    "\n",
    "# Without padding\n",
    "print(\"Bigrams without padding:\")\n",
    "print(list(bigrams(tokens)))\n",
    "\n",
    "# With padding\n",
    "print(\"\\nBigrams with padding:\")\n",
    "padded = list(pad_both_ends(tokens, n=2))\n",
    "print(f\"Padded tokens: {padded}\")\n",
    "print(f\"Padded bigrams: {list(bigrams(padded))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a18db3",
   "metadata": {},
   "source": [
    "## 10.4 N-Gram Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8234671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample text\n",
    "text = gutenberg.raw('austen-emma.txt')[:10000]  # First 10K chars\n",
    "tokens = word_tokenize(text.lower())\n",
    "\n",
    "# Filter to alphabetic tokens only\n",
    "tokens = [t for t in tokens if t.isalpha()]\n",
    "\n",
    "print(f\"Total tokens: {len(tokens)}\")\n",
    "print(f\"Sample: {tokens[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab0187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram frequencies\n",
    "bi_grams = list(bigrams(tokens))\n",
    "bigram_freq = Counter(bi_grams)\n",
    "\n",
    "print(\"Top 15 Most Common Bigrams:\")\n",
    "print(\"-\" * 40)\n",
    "for bg, count in bigram_freq.most_common(15):\n",
    "    print(f\"{bg[0]:<10} {bg[1]:<10} {count:>5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3570e8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigram frequencies\n",
    "tri_grams = list(trigrams(tokens))\n",
    "trigram_freq = Counter(tri_grams)\n",
    "\n",
    "print(\"Top 15 Most Common Trigrams:\")\n",
    "print(\"-\" * 50)\n",
    "for tg, count in trigram_freq.most_common(15):\n",
    "    print(f\"{tg[0]:<10} {tg[1]:<10} {tg[2]:<10} {count:>5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a6229",
   "metadata": {},
   "source": [
    "## 10.5 Collocations\n",
    "\n",
    "**Collocations** are words that appear together more often than by chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27700f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load more text\n",
    "text = gutenberg.raw('austen-emma.txt')\n",
    "tokens = word_tokenize(text.lower())\n",
    "tokens = [t for t in tokens if t.isalpha() and len(t) > 2]\n",
    "\n",
    "print(f\"Total tokens: {len(tokens):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d275f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find bigram collocations\n",
    "bigram_finder = BigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "# Filter low-frequency bigrams\n",
    "bigram_finder.apply_freq_filter(5)\n",
    "\n",
    "# Get top collocations using PMI (Pointwise Mutual Information)\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "\n",
    "print(\"Top 15 Bigram Collocations (PMI):\")\n",
    "print(\"-\" * 40)\n",
    "for colloc in bigram_finder.nbest(bigram_measures.pmi, 15):\n",
    "    print(f\"  {colloc[0]} {colloc[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different scoring methods\n",
    "print(\"Top 10 by Likelihood Ratio:\")\n",
    "for colloc in bigram_finder.nbest(bigram_measures.likelihood_ratio, 10):\n",
    "    print(f\"  {colloc[0]} {colloc[1]}\")\n",
    "\n",
    "print(\"\\nTop 10 by Chi-Square:\")\n",
    "for colloc in bigram_finder.nbest(bigram_measures.chi_sq, 10):\n",
    "    print(f\"  {colloc[0]} {colloc[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3b973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigram collocations\n",
    "trigram_finder = TrigramCollocationFinder.from_words(tokens)\n",
    "trigram_finder.apply_freq_filter(3)\n",
    "\n",
    "trigram_measures = TrigramAssocMeasures()\n",
    "\n",
    "print(\"Top 15 Trigram Collocations:\")\n",
    "print(\"-\" * 50)\n",
    "for colloc in trigram_finder.nbest(trigram_measures.pmi, 15):\n",
    "    print(f\"  {' '.join(colloc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7791db8",
   "metadata": {},
   "source": [
    "## 10.6 Simple Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b1ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBigramModel:\n",
    "    \"\"\"Simple bigram language model\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.bigram_counts = defaultdict(Counter)\n",
    "        self.unigram_counts = Counter()\n",
    "    \n",
    "    def train(self, tokens):\n",
    "        \"\"\"Train on a list of tokens\"\"\"\n",
    "        # Count unigrams\n",
    "        self.unigram_counts = Counter(tokens)\n",
    "        \n",
    "        # Count bigrams (word1 -> word2)\n",
    "        for w1, w2 in bigrams(tokens):\n",
    "            self.bigram_counts[w1][w2] += 1\n",
    "    \n",
    "    def probability(self, word, context):\n",
    "        \"\"\"P(word | context)\"\"\"\n",
    "        if context not in self.bigram_counts:\n",
    "            return 0\n",
    "        \n",
    "        total = sum(self.bigram_counts[context].values())\n",
    "        return self.bigram_counts[context][word] / total\n",
    "    \n",
    "    def next_word_probs(self, context):\n",
    "        \"\"\"Get probabilities for all possible next words\"\"\"\n",
    "        if context not in self.bigram_counts:\n",
    "            return {}\n",
    "        \n",
    "        total = sum(self.bigram_counts[context].values())\n",
    "        return {word: count/total \n",
    "                for word, count in self.bigram_counts[context].items()}\n",
    "    \n",
    "    def generate(self, start_word, length=10):\n",
    "        \"\"\"Generate text starting from a word\"\"\"\n",
    "        words = [start_word]\n",
    "        current = start_word\n",
    "        \n",
    "        for _ in range(length - 1):\n",
    "            if current not in self.bigram_counts:\n",
    "                break\n",
    "            \n",
    "            # Get next word probabilities\n",
    "            probs = self.next_word_probs(current)\n",
    "            if not probs:\n",
    "                break\n",
    "            \n",
    "            # Choose next word weighted by probability\n",
    "            next_words = list(probs.keys())\n",
    "            weights = list(probs.values())\n",
    "            current = random.choices(next_words, weights=weights)[0]\n",
    "            words.append(current)\n",
    "        \n",
    "        return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a49aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "text = gutenberg.raw('austen-emma.txt')\n",
    "tokens = word_tokenize(text.lower())\n",
    "tokens = [t for t in tokens if t.isalpha()]\n",
    "\n",
    "model = SimpleBigramModel()\n",
    "model.train(tokens)\n",
    "\n",
    "print(f\"Vocabulary size: {len(model.unigram_counts):,}\")\n",
    "print(f\"Unique bigram contexts: {len(model.bigram_counts):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check probabilities\n",
    "context = \"mr\"\n",
    "print(f\"Words that follow '{context}':\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "probs = model.next_word_probs(context)\n",
    "sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for word, prob in sorted_probs[:10]:\n",
    "    print(f\"  {word:<15} {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text\n",
    "print(\"Generated text samples:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_words = [\"the\", \"she\", \"he\", \"it\", \"mr\"]\n",
    "\n",
    "for start in start_words:\n",
    "    generated = model.generate(start, length=12)\n",
    "    print(f\"\\n'{start}' â†’ {generated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91695e57",
   "metadata": {},
   "source": [
    "## 10.7 NLTK's Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b03f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "# Prepare training data\n",
    "text = gutenberg.raw('austen-emma.txt')[:50000]\n",
    "sentences = sent_tokenize(text)\n",
    "tokenized_sents = [word_tokenize(s.lower()) for s in sentences]\n",
    "tokenized_sents = [[t for t in s if t.isalpha()] for s in tokenized_sents]\n",
    "\n",
    "# Remove empty sentences\n",
    "tokenized_sents = [s for s in tokenized_sents if len(s) > 0]\n",
    "\n",
    "print(f\"Number of sentences: {len(tokenized_sents)}\")\n",
    "print(f\"Sample: {tokenized_sents[0][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a9d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data with padding\n",
    "n = 3  # trigram model\n",
    "train_data, vocab = padded_everygram_pipeline(n, tokenized_sents)\n",
    "\n",
    "# Train MLE (Maximum Likelihood Estimation) model\n",
    "lm = MLE(n)\n",
    "lm.fit(train_data, vocab)\n",
    "\n",
    "print(f\"Vocabulary size: {len(lm.vocab):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa7a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score some words given context\n",
    "print(\"P(word | context)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "contexts = [\n",
    "    ([\"she\", \"was\"], \"very\"),\n",
    "    ([\"she\", \"was\"], \"not\"),\n",
    "    ([\"mr\"], \"knightley\"),\n",
    "    ([\"mr\"], \"woodhouse\"),\n",
    "]\n",
    "\n",
    "for context, word in contexts:\n",
    "    prob = lm.score(word, context)\n",
    "    print(f\"P({word} | {' '.join(context)}) = {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ea3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text using NLTK's model\n",
    "print(\"Generated text (NLTK MLE model):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i in range(5):\n",
    "    generated = lm.generate(15, random_seed=i)\n",
    "    print(f\"{i+1}. {' '.join(generated)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cd230c",
   "metadata": {},
   "source": [
    "## 10.8 Practical: N-Gram Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef415ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ngrams(text, n=2, top_k=10, remove_stopwords=True):\n",
    "    \"\"\"Comprehensive n-gram analysis\"\"\"\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [t for t in tokens if t.isalpha()]\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [t for t in tokens if t not in stop_words]\n",
    "    \n",
    "    # Generate n-grams\n",
    "    grams = list(ngrams(tokens, n))\n",
    "    freq = Counter(grams)\n",
    "    \n",
    "    return {\n",
    "        'total_ngrams': len(grams),\n",
    "        'unique_ngrams': len(freq),\n",
    "        'top_ngrams': freq.most_common(top_k),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd1a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a text\n",
    "text = \"\"\"Machine learning is a subset of artificial intelligence.\n",
    "Machine learning enables computers to learn from data.\n",
    "Deep learning is a subset of machine learning.\n",
    "Natural language processing uses machine learning.\n",
    "Machine learning models can process natural language.\"\"\"\n",
    "\n",
    "print(f\"Text:\\n{text}\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for n in [1, 2, 3]:\n",
    "    result = analyze_ngrams(text, n=n, remove_stopwords=True)\n",
    "    \n",
    "    print(f\"\\n{n}-grams Analysis:\")\n",
    "    print(f\"  Total: {result['total_ngrams']}\")\n",
    "    print(f\"  Unique: {result['unique_ngrams']}\")\n",
    "    print(f\"  Top {n}-grams:\")\n",
    "    for gram, count in result['top_ngrams']:\n",
    "        print(f\"    {' '.join(gram)}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8fa37a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Function | Description |\n",
    "|----------|-------------|\n",
    "| `ngrams(tokens, n)` | Generate n-grams |\n",
    "| `bigrams(tokens)` | Generate bigrams |\n",
    "| `trigrams(tokens)` | Generate trigrams |\n",
    "| `BigramCollocationFinder` | Find significant bigrams |\n",
    "| `TrigramCollocationFinder` | Find significant trigrams |\n",
    "\n",
    "### Collocation Measures\n",
    "- **PMI**: Pointwise Mutual Information\n",
    "- **Chi-Square**: Statistical significance\n",
    "- **Likelihood Ratio**: How likely is this collocation\n",
    "\n",
    "### Use Cases\n",
    "- Text generation\n",
    "- Autocomplete / suggestion\n",
    "- Keyphrase extraction\n",
    "- Language detection\n",
    "- Spell checking"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
