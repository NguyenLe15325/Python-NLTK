{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09866fb",
   "metadata": {},
   "source": [
    "# NLTK Complete Guide - Section 14: Text Classification\n",
    "\n",
    "This notebook covers:\n",
    "- Feature Extraction\n",
    "- Naive Bayes Classifier\n",
    "- Training and Evaluation\n",
    "- Document Classification\n",
    "- Practical Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56617685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('movie_reviews', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('names', quiet=True)\n",
    "\n",
    "from nltk.corpus import movie_reviews, names, stopwords\n",
    "from nltk.classify import NaiveBayesClassifier, accuracy\n",
    "from nltk.classify.util import apply_features\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11bad5e",
   "metadata": {},
   "source": [
    "## 14.1 Introduction to Text Classification\n",
    "\n",
    "**Text Classification** assigns categories to documents:\n",
    "- Spam detection\n",
    "- Sentiment analysis\n",
    "- Topic categorization\n",
    "- Language detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e34787",
   "metadata": {},
   "source": [
    "## 14.2 Simple Example: Gender Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(name):\n",
    "    \"\"\"Extract features from a name\"\"\"\n",
    "    return {\n",
    "        'last_letter': name[-1].lower(),\n",
    "        'last_two': name[-2:].lower(),\n",
    "        'first_letter': name[0].lower(),\n",
    "        'length': len(name),\n",
    "    }\n",
    "\n",
    "# Test the feature extractor\n",
    "print(\"Feature extraction examples:\")\n",
    "print(f\"  John: {gender_features('John')}\")\n",
    "print(f\"  Mary: {gender_features('Mary')}\")\n",
    "print(f\"  Alexandra: {gender_features('Alexandra')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d013ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "male_names = [(name, 'male') for name in names.words('male.txt')]\n",
    "female_names = [(name, 'female') for name in names.words('female.txt')]\n",
    "all_names = male_names + female_names\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(all_names)\n",
    "\n",
    "print(f\"Total names: {len(all_names)}\")\n",
    "print(f\"Male: {len(male_names)}, Female: {len(female_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31523eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature sets\n",
    "featuresets = [(gender_features(name), gender) for (name, gender) in all_names]\n",
    "\n",
    "# Split into train/test\n",
    "train_size = int(len(featuresets) * 0.8)\n",
    "train_set = featuresets[:train_size]\n",
    "test_set = featuresets[train_size:]\n",
    "\n",
    "print(f\"Training set: {len(train_set)}\")\n",
    "print(f\"Test set: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f929d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Naive Bayes classifier\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Evaluate\n",
    "acc = accuracy(classifier, test_set)\n",
    "print(f\"Accuracy: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b7b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most informative features\n",
    "print(\"\\nMost Informative Features:\")\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with new names\n",
    "test_names = ['Michael', 'Jessica', 'Alex', 'Taylor', 'Jordan', 'Emily', 'James']\n",
    "\n",
    "print(\"\\nPredictions:\")\n",
    "print(\"-\" * 30)\n",
    "for name in test_names:\n",
    "    features = gender_features(name)\n",
    "    prediction = classifier.classify(features)\n",
    "    prob = classifier.prob_classify(features)\n",
    "    confidence = prob.prob(prediction)\n",
    "    print(f\"{name:<12} â†’ {prediction:<8} ({confidence:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043ee022",
   "metadata": {},
   "source": [
    "## 14.3 Document Classification: Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57844a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movie reviews\n",
    "documents = [\n",
    "    (list(movie_reviews.words(fileid)), category)\n",
    "    for category in movie_reviews.categories()\n",
    "    for fileid in movie_reviews.fileids(category)\n",
    "]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(documents)\n",
    "\n",
    "print(f\"Total documents: {len(documents)}\")\n",
    "print(f\"Categories: {movie_reviews.categories()}\")\n",
    "print(f\"\\nSample document (first 20 words): {documents[0][0][:20]}\")\n",
    "print(f\"Label: {documents[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most common words for features\n",
    "all_words = [w.lower() for w in movie_reviews.words() if w.isalpha()]\n",
    "word_freq = Counter(all_words)\n",
    "common_words = [w for w, f in word_freq.most_common(2000)]\n",
    "\n",
    "print(f\"Vocabulary size: {len(word_freq)}\")\n",
    "print(f\"Using top 2000 words as features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfedc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document, word_features):\n",
    "    \"\"\"Extract features from document\"\"\"\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[f'contains({word})'] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "# Example\n",
    "sample_features = document_features(documents[0][0], common_words[:10])\n",
    "print(\"Sample features (first 10 words):\")\n",
    "for feat, value in sample_features.items():\n",
    "    print(f\"  {feat}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d42e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature sets (using apply_features for memory efficiency)\n",
    "featuresets = [\n",
    "    (document_features(doc, common_words), category)\n",
    "    for (doc, category) in documents\n",
    "]\n",
    "\n",
    "# Split data\n",
    "train_set = featuresets[:1600]\n",
    "test_set = featuresets[1600:]\n",
    "\n",
    "print(f\"Training: {len(train_set)}, Testing: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "print(\"Training classifier...\")\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Evaluate\n",
    "acc = accuracy(classifier, test_set)\n",
    "print(f\"\\nAccuracy: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d3ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most informative features\n",
    "print(\"\\nMost Informative Features for Sentiment:\")\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced1ff41",
   "metadata": {},
   "source": [
    "## 14.4 Improved Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09120e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def improved_features(document, word_features):\n",
    "    \"\"\"Extract improved features\"\"\"\n",
    "    document_words = set(w.lower() for w in document if w.isalpha())\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Word presence (excluding stopwords)\n",
    "    for word in word_features:\n",
    "        if word not in stop_words:\n",
    "            features[f'contains({word})'] = (word in document_words)\n",
    "    \n",
    "    # Additional features\n",
    "    features['doc_length'] = len(document) > 500\n",
    "    features['has_exclamation'] = '!' in ' '.join(document)\n",
    "    features['has_question'] = '?' in ' '.join(document)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter word features (remove stopwords)\n",
    "filtered_words = [w for w in common_words if w not in stop_words][:1500]\n",
    "\n",
    "print(f\"Filtered features: {len(filtered_words)}\")\n",
    "\n",
    "# Create new feature sets\n",
    "featuresets_improved = [\n",
    "    (improved_features(doc, filtered_words), category)\n",
    "    for (doc, category) in documents\n",
    "]\n",
    "\n",
    "train_improved = featuresets_improved[:1600]\n",
    "test_improved = featuresets_improved[1600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad289fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train improved classifier\n",
    "print(\"Training improved classifier...\")\n",
    "classifier_improved = NaiveBayesClassifier.train(train_improved)\n",
    "\n",
    "acc_improved = accuracy(classifier_improved, test_improved)\n",
    "print(f\"\\nImproved Accuracy: {acc_improved:.2%}\")\n",
    "print(f\"Original Accuracy: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4166ef39",
   "metadata": {},
   "source": [
    "## 14.5 Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a3243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(featuresets, num_folds=5):\n",
    "    \"\"\"Perform k-fold cross validation\"\"\"\n",
    "    fold_size = len(featuresets) // num_folds\n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(num_folds):\n",
    "        # Split data\n",
    "        test_start = i * fold_size\n",
    "        test_end = test_start + fold_size\n",
    "        \n",
    "        test_fold = featuresets[test_start:test_end]\n",
    "        train_fold = featuresets[:test_start] + featuresets[test_end:]\n",
    "        \n",
    "        # Train and evaluate\n",
    "        classifier = NaiveBayesClassifier.train(train_fold)\n",
    "        acc = accuracy(classifier, test_fold)\n",
    "        accuracies.append(acc)\n",
    "        print(f\"Fold {i+1}: {acc:.2%}\")\n",
    "    \n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    return avg_accuracy, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"5-Fold Cross Validation:\")\n",
    "print(\"-\" * 30)\n",
    "avg_acc, fold_accs = cross_validate(featuresets_improved, num_folds=5)\n",
    "print(f\"\\nAverage Accuracy: {avg_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff9c3c1",
   "metadata": {},
   "source": [
    "## 14.6 Confusion Matrix and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725fb5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(classifier, test_set):\n",
    "    \"\"\"Calculate precision, recall, F1 for each class\"\"\"\n",
    "    # Get predictions\n",
    "    predictions = [classifier.classify(features) for features, label in test_set]\n",
    "    actual = [label for features, label in test_set]\n",
    "    \n",
    "    # Build confusion matrix\n",
    "    labels = list(set(actual))\n",
    "    confusion = {}\n",
    "    for true_label in labels:\n",
    "        confusion[true_label] = {}\n",
    "        for pred_label in labels:\n",
    "            confusion[true_label][pred_label] = 0\n",
    "    \n",
    "    for true, pred in zip(actual, predictions):\n",
    "        confusion[true][pred] += 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {}\n",
    "    for label in labels:\n",
    "        tp = confusion[label][label]\n",
    "        fp = sum(confusion[other][label] for other in labels if other != label)\n",
    "        fn = sum(confusion[label][other] for other in labels if other != label)\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        metrics[label] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        }\n",
    "    \n",
    "    return confusion, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a9209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion, metrics = evaluate_classifier(classifier_improved, test_improved)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"{'':>12} {'Predicted':<20}\")\n",
    "print(f\"{'Actual':<12} {'neg':<10} {'pos':<10}\")\n",
    "print(\"-\" * 40)\n",
    "for true_label in ['neg', 'pos']:\n",
    "    print(f\"{true_label:<12}\", end='')\n",
    "    for pred_label in ['neg', 'pos']:\n",
    "        print(f\"{confusion[true_label][pred_label]:<10}\", end='')\n",
    "    print()\n",
    "\n",
    "print(\"\\nMetrics by Class:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"{'Class':<10} {'Precision':<12} {'Recall':<12} {'F1':<10}\")\n",
    "print(\"-\" * 40)\n",
    "for label, m in metrics.items():\n",
    "    print(f\"{label:<10} {m['precision']:<12.2%} {m['recall']:<12.2%} {m['f1']:<10.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb8929",
   "metadata": {},
   "source": [
    "## 14.7 Complete Classifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier:\n",
    "    \"\"\"Complete text classification pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, num_features=1500):\n",
    "        self.num_features = num_features\n",
    "        self.word_features = None\n",
    "        self.classifier = None\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    def extract_features(self, document):\n",
    "        \"\"\"Extract features from a document\"\"\"\n",
    "        if isinstance(document, str):\n",
    "            document = word_tokenize(document.lower())\n",
    "        \n",
    "        doc_words = set(w.lower() for w in document if w.isalpha())\n",
    "        \n",
    "        features = {}\n",
    "        for word in self.word_features:\n",
    "            features[f'contains({word})'] = (word in doc_words)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def train(self, documents, labels):\n",
    "        \"\"\"Train the classifier\"\"\"\n",
    "        # Build vocabulary\n",
    "        all_words = []\n",
    "        for doc in documents:\n",
    "            if isinstance(doc, str):\n",
    "                doc = word_tokenize(doc.lower())\n",
    "            all_words.extend([w.lower() for w in doc if w.isalpha() and w.lower() not in self.stop_words])\n",
    "        \n",
    "        word_freq = Counter(all_words)\n",
    "        self.word_features = [w for w, f in word_freq.most_common(self.num_features)]\n",
    "        \n",
    "        # Create feature sets\n",
    "        featuresets = [\n",
    "            (self.extract_features(doc), label)\n",
    "            for doc, label in zip(documents, labels)\n",
    "        ]\n",
    "        \n",
    "        # Train\n",
    "        self.classifier = NaiveBayesClassifier.train(featuresets)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, document):\n",
    "        \"\"\"Predict class for a document\"\"\"\n",
    "        features = self.extract_features(document)\n",
    "        return self.classifier.classify(features)\n",
    "    \n",
    "    def predict_proba(self, document):\n",
    "        \"\"\"Get probability distribution\"\"\"\n",
    "        features = self.extract_features(document)\n",
    "        prob_dist = self.classifier.prob_classify(features)\n",
    "        return {label: prob_dist.prob(label) for label in prob_dist.samples()}\n",
    "    \n",
    "    def evaluate(self, documents, labels):\n",
    "        \"\"\"Evaluate accuracy on test data\"\"\"\n",
    "        featuresets = [\n",
    "            (self.extract_features(doc), label)\n",
    "            for doc, label in zip(documents, labels)\n",
    "        ]\n",
    "        return accuracy(self.classifier, featuresets)\n",
    "    \n",
    "    def show_features(self, n=10):\n",
    "        \"\"\"Show most informative features\"\"\"\n",
    "        self.classifier.show_most_informative_features(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0cfe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the class\n",
    "# Prepare data\n",
    "docs = [list(movie_reviews.words(fid)) for fid in movie_reviews.fileids()]\n",
    "labels = [movie_reviews.categories(fid)[0] for fid in movie_reviews.fileids()]\n",
    "\n",
    "# Shuffle\n",
    "combined = list(zip(docs, labels))\n",
    "random.shuffle(combined)\n",
    "docs, labels = zip(*combined)\n",
    "\n",
    "# Split\n",
    "train_docs, test_docs = docs[:1600], docs[1600:]\n",
    "train_labels, test_labels = labels[:1600], labels[1600:]\n",
    "\n",
    "# Train\n",
    "clf = TextClassifier(num_features=1500)\n",
    "clf.train(train_docs, train_labels)\n",
    "\n",
    "# Evaluate\n",
    "acc = clf.evaluate(test_docs, test_labels)\n",
    "print(f\"Accuracy: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with new text\n",
    "test_reviews = [\n",
    "    \"This movie was absolutely fantastic! Great acting and storyline.\",\n",
    "    \"Terrible film. Waste of time and money. Very disappointing.\",\n",
    "    \"It was okay. Not great, not terrible. Average movie.\",\n",
    "]\n",
    "\n",
    "print(\"Predictions on new reviews:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for review in test_reviews:\n",
    "    prediction = clf.predict(review)\n",
    "    probs = clf.predict_proba(review)\n",
    "    \n",
    "    print(f\"\\nReview: {review[:50]}...\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print(f\"Confidence: pos={probs['pos']:.1%}, neg={probs['neg']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25bd013",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Step | Code |\n",
    "|------|------|\n",
    "| Create features | `features = {...}` dictionary |\n",
    "| Create featuresets | `[(features, label), ...]` |\n",
    "| Train classifier | `NaiveBayesClassifier.train(train_set)` |\n",
    "| Classify | `classifier.classify(features)` |\n",
    "| Get probabilities | `classifier.prob_classify(features)` |\n",
    "| Evaluate | `accuracy(classifier, test_set)` |\n",
    "| Show features | `classifier.show_most_informative_features(n)` |\n",
    "\n",
    "### Classification Pipeline\n",
    "1. **Collect** labeled data\n",
    "2. **Extract** features from text\n",
    "3. **Split** into train/test sets\n",
    "4. **Train** classifier\n",
    "5. **Evaluate** performance\n",
    "6. **Tune** features and parameters"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
