{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09866fb",
   "metadata": {},
   "source": [
    "# NLTK Complete Guide - Section 14: Text Classification\n",
    "\n",
    "## What is Text Classification?\n",
    "\n",
    "**Text Classification** (also called Text Categorization) is the task of automatically assigning predefined categories or labels to text documents. It's one of the most fundamental and widely-used NLP tasks.\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "| Application | Description | Example |\n",
    "|-------------|-------------|---------|\n",
    "| **Spam Detection** | Classify emails as spam or not spam | Gmail's spam filter |\n",
    "| **Sentiment Analysis** | Determine if text is positive/negative | Product review ratings |\n",
    "| **Topic Classification** | Assign topics to articles | News categorization |\n",
    "| **Language Detection** | Identify the language of text | Google Translate detection |\n",
    "| **Intent Recognition** | Understand user intent in chatbots | Customer service bots |\n",
    "| **Content Moderation** | Detect inappropriate content | Social media filtering |\n",
    "\n",
    "### The Classification Pipeline\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Raw Text  â”‚ â†’  â”‚   Feature    â”‚ â†’  â”‚   Machine   â”‚ â†’  â”‚ Predicted  â”‚\n",
    "â”‚  Documents  â”‚    â”‚  Extraction  â”‚    â”‚  Learning   â”‚    â”‚   Label    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### What This Notebook Covers\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "| **Feature Extraction** | Converting text to numerical features |\n",
    "| **Naive Bayes Classifier** | A probabilistic classification algorithm |\n",
    "| **Training & Evaluation** | How to train and measure performance |\n",
    "| **Cross-Validation** | Robust evaluation technique |\n",
    "| **Practical Examples** | Gender classification, movie review sentiment |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56617685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('movie_reviews', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('names', quiet=True)\n",
    "\n",
    "from nltk.corpus import movie_reviews, names, stopwords\n",
    "from nltk.classify import NaiveBayesClassifier, accuracy\n",
    "from nltk.classify.util import apply_features\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867e15f",
   "metadata": {},
   "source": [
    "### Understanding the Imports\n",
    "\n",
    "| Import | Purpose |\n",
    "|--------|---------|\n",
    "| `movie_reviews` | Corpus of 2000 movie reviews labeled positive/negative |\n",
    "| `names` | Corpus of male and female first names |\n",
    "| `stopwords` | Common words to filter out (the, is, at, etc.) |\n",
    "| `NaiveBayesClassifier` | The classifier algorithm we'll use |\n",
    "| `accuracy` | Function to calculate classification accuracy |\n",
    "| `apply_features` | Memory-efficient feature extraction |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11bad5e",
   "metadata": {},
   "source": [
    "## 14.1 Introduction to Text Classification\n",
    "\n",
    "### The Core Concept\n",
    "\n",
    "Text classification works by:\n",
    "1. **Converting text to features** (numbers that represent the text)\n",
    "2. **Learning patterns** from labeled examples\n",
    "3. **Predicting labels** for new, unseen text\n",
    "\n",
    "### Types of Classification\n",
    "\n",
    "| Type | Classes | Example |\n",
    "|------|---------|---------|\n",
    "| **Binary** | 2 classes | Spam vs Not Spam |\n",
    "| **Multi-class** | 3+ classes (one per doc) | News topics (sports, politics, tech) |\n",
    "| **Multi-label** | Multiple labels per doc | Movie genres (action AND comedy) |\n",
    "\n",
    "### Naive Bayes Classifier\n",
    "\n",
    "We'll use **Naive Bayes**, a probabilistic classifier based on Bayes' theorem:\n",
    "\n",
    "$$P(class|features) = \\frac{P(features|class) \\cdot P(class)}{P(features)}$$\n",
    "\n",
    "**Why \"Naive\"?** It assumes all features are independent of each other (which is rarely true in practice, but the algorithm still works remarkably well!)\n",
    "\n",
    "### Why Naive Bayes for Text?\n",
    "\n",
    "âœ… **Fast to train** - Linear time complexity  \n",
    "âœ… **Works well with high-dimensional data** - Text has many features  \n",
    "âœ… **Requires little training data** - Good for small datasets  \n",
    "âœ… **Handles irrelevant features** - Robust to noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e34787",
   "metadata": {},
   "source": [
    "## 14.2 Simple Example: Gender Classification from Names\n",
    "\n",
    "Let's start with a simple example: predicting gender from first names. This is a great introduction because:\n",
    "- The data is simple (just names)\n",
    "- The features are intuitive (letters in the name)\n",
    "- The results are interpretable\n",
    "\n",
    "### The Key Concept: Feature Extraction\n",
    "\n",
    "**Features** are the measurable properties we extract from data. For names, we might use:\n",
    "- Last letter (names ending in 'a' are often female)\n",
    "- First letter\n",
    "- Length of name\n",
    "- Last two letters\n",
    "\n",
    "The classifier will learn which features are most predictive of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05de4cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE EXTRACTION EXAMPLES\n",
      "=======================================================\n",
      "\n",
      "Extracting features from different names:\n",
      "\n",
      "  John         â†’ {'last_letter': 'n', 'last_two': 'hn', 'first_letter': 'j', 'length': 4}\n",
      "  Mary         â†’ {'last_letter': 'y', 'last_two': 'ry', 'first_letter': 'm', 'length': 4}\n",
      "  Alexandra    â†’ {'last_letter': 'a', 'last_two': 'ra', 'first_letter': 'a', 'length': 9}\n",
      "  Michael      â†’ {'last_letter': 'l', 'last_two': 'el', 'first_letter': 'm', 'length': 7}\n",
      "  Sarah        â†’ {'last_letter': 'h', 'last_two': 'ah', 'first_letter': 's', 'length': 5}\n",
      "\n",
      "ğŸ’¡ Notice: Female names often end in vowels (a, y, h)\n",
      "   Male names often end in consonants (n, l, d)\n"
     ]
    }
   ],
   "source": [
    "def gender_features(name):\n",
    "    \"\"\"\n",
    "    Extract features from a name for gender classification.\n",
    "    \n",
    "    Features are stored in a dictionary where:\n",
    "    - Keys are feature names (strings)\n",
    "    - Values are the feature values (can be any type)\n",
    "    \n",
    "    The classifier will learn which features correlate with which gender.\n",
    "    \n",
    "    Args:\n",
    "        name: A person's first name (string)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of features\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'last_letter': name[-1].lower(),      # Most predictive feature!\n",
    "        'last_two': name[-2:].lower(),        # \"ia\", \"na\" â†’ often female\n",
    "        'first_letter': name[0].lower(),      # Less predictive\n",
    "        'length': len(name),                   # Names length varies by gender\n",
    "    }\n",
    "\n",
    "# Test the feature extractor with example names\n",
    "print(\"FEATURE EXTRACTION EXAMPLES\")\n",
    "print(\"=\" * 55)\n",
    "print(\"\\nExtracting features from different names:\\n\")\n",
    "\n",
    "test_names = ['John', 'Mary', 'Alexandra', 'Michael', 'Sarah']\n",
    "for name in test_names:\n",
    "    features = gender_features(name)\n",
    "    print(f\"  {name:<12} â†’ {features}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Notice: Female names often end in vowels (a, y, h)\")\n",
    "print(\"   Male names often end in consonants (n, l, d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d013ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA PREPARED\n",
      "=============================================\n",
      "\n",
      "ğŸ“Š Dataset Statistics:\n",
      "   Total names:  7,944\n",
      "   Male names:   2,943\n",
      "   Female names: 5,001\n",
      "\n",
      "ğŸ“ Sample data (first 5 after shuffling):\n",
      "   Raye            â†’ female\n",
      "   Marita          â†’ female\n",
      "   Fey             â†’ female\n",
      "   Vittoria        â†’ female\n",
      "   Dannie          â†’ female\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Prepare the labeled training data\n",
    "# Each item is a tuple: (name, gender_label)\n",
    "\n",
    "male_names = [(name, 'male') for name in names.words('male.txt')]\n",
    "female_names = [(name, 'female') for name in names.words('female.txt')]\n",
    "\n",
    "# Combine all names\n",
    "all_names = male_names + female_names\n",
    "\n",
    "# IMPORTANT: Shuffle the data to avoid ordering bias\n",
    "# (All male names first, then all female would bias training)\n",
    "random.seed(42)  # For reproducibility\n",
    "random.shuffle(all_names)\n",
    "\n",
    "print(\"TRAINING DATA PREPARED\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"\\nğŸ“Š Dataset Statistics:\")\n",
    "print(f\"   Total names:  {len(all_names):,}\")\n",
    "print(f\"   Male names:   {len(male_names):,}\")\n",
    "print(f\"   Female names: {len(female_names):,}\")\n",
    "\n",
    "print(f\"\\nğŸ“ Sample data (first 5 after shuffling):\")\n",
    "for name, gender in all_names[:5]:\n",
    "    print(f\"   {name:<15} â†’ {gender}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31523eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN/TEST SPLIT\n",
      "=============================================\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚  Training set:   6355 examples (80%)     â”‚\n",
      "â”‚  Test set:       1589 examples (20%)     â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Why split the data?\n",
      "â€¢ Training set: Classifier learns patterns from this\n",
      "â€¢ Test set: Measures how well it generalizes to NEW data\n",
      "\n",
      "âš ï¸ NEVER test on training data - it leads to over-optimistic results!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Create feature sets and split into train/test\n",
    "# Feature set = (features_dict, label) for each example\n",
    "\n",
    "featuresets = [(gender_features(name), gender) for (name, gender) in all_names]\n",
    "\n",
    "# Split into training (80%) and test (20%) sets\n",
    "# Training set: Used to train the classifier\n",
    "# Test set: Used to evaluate performance on unseen data\n",
    "train_size = int(len(featuresets) * 0.8)\n",
    "train_set = featuresets[:train_size]\n",
    "test_set = featuresets[train_size:]\n",
    "\n",
    "print(\"TRAIN/TEST SPLIT\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Training set:  {len(train_set):>5} examples (80%)     â”‚\n",
    "â”‚  Test set:      {len(test_set):>5} examples (20%)     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Why split the data?\n",
    "â€¢ Training set: Classifier learns patterns from this\n",
    "â€¢ Test set: Measures how well it generalizes to NEW data\n",
    "\n",
    "âš ï¸ NEVER test on training data - it leads to over-optimistic results!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f929d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING CLASSIFIER...\n",
      "=============================================\n",
      "âœ… Training complete!\n",
      "\n",
      "EVALUATION RESULTS\n",
      "=============================================\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚           ACCURACY: 78.4%               â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "This means the classifier correctly predicts gender\n",
      "for 78.4% of names it has never seen before!\n",
      "\n",
      "For reference:\n",
      "â€¢ 50% = Random guessing (coin flip)\n",
      "â€¢ 70-80% = Good for this task\n",
      "â€¢ 100% = Perfect (impossible for this task)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Train the Naive Bayes classifier\n",
    "# This is where the magic happens - the algorithm learns from the training data\n",
    "\n",
    "print(\"TRAINING CLASSIFIER...\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print(\"âœ… Training complete!\\n\")\n",
    "\n",
    "# STEP 4: Evaluate on test set\n",
    "# accuracy() returns the proportion of correct predictions\n",
    "acc = accuracy(classifier, test_set)\n",
    "\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           ACCURACY: {acc:.1%}               â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "This means the classifier correctly predicts gender\n",
    "for {acc*100:.1f}% of names it has never seen before!\n",
    "\n",
    "For reference:\n",
    "â€¢ 50% = Random guessing (coin flip)\n",
    "â€¢ 70-80% = Good for this task\n",
    "â€¢ 100% = Perfect (impossible for this task)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "341b7b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST INFORMATIVE FEATURES\n",
      "============================================================\n",
      "\n",
      "This shows which features are most useful for distinguishing\n",
      "male vs female names. The ratio indicates how much more likely\n",
      "a feature value is for one gender vs the other.\n",
      "\n",
      "Example: \"last_letter = 'a'\" with ratio 35.3:1 means names\n",
      "ending in 'a' are 35.3x more likely to be female than male.\n",
      "\n",
      "------------------------------------------------------------\n",
      "Most Informative Features\n",
      "                last_two = 'la'           female : male   =     64.0 : 1.0\n",
      "                last_two = 'ra'           female : male   =     50.4 : 1.0\n",
      "             last_letter = 'a'            female : male   =     41.3 : 1.0\n",
      "                last_two = 'us'             male : female =     38.5 : 1.0\n",
      "             last_letter = 'k'              male : female =     37.2 : 1.0\n",
      "                last_two = 'ia'           female : male   =     35.6 : 1.0\n",
      "                last_two = 'ta'           female : male   =     27.8 : 1.0\n",
      "                last_two = 'rd'             male : female =     21.7 : 1.0\n",
      "                last_two = 'ld'             male : female =     21.1 : 1.0\n",
      "                last_two = 'do'             male : female =     20.6 : 1.0\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ’¡ The last letter is clearly the most informative feature!\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Inspect most informative features\n",
    "# This tells us WHAT the classifier learned\n",
    "\n",
    "print(\"MOST INFORMATIVE FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "This shows which features are most useful for distinguishing\n",
    "male vs female names. The ratio indicates how much more likely\n",
    "a feature value is for one gender vs the other.\n",
    "\n",
    "Example: \"last_letter = 'a'\" with ratio 35.3:1 means names\n",
    "ending in 'a' are 35.3x more likely to be female than male.\n",
    "\"\"\")\n",
    "print(\"-\" * 60)\n",
    "classifier.show_most_informative_features(10)\n",
    "print(\"-\" * 60)\n",
    "print(\"\\nğŸ’¡ The last letter is clearly the most informative feature!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6278c470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTIONS ON NEW NAMES\n",
      "=======================================================\n",
      "Name         Prediction   Confidence   Notes\n",
      "-------------------------------------------------------\n",
      "Michael      male            55.0%     âš ï¸ Uncertain\n",
      "Jessica      female         100.0%     \n",
      "Alex         male            81.9%     (Gender-neutral)\n",
      "Taylor       male            96.1%     (Gender-neutral)\n",
      "Jordan       male            77.7%     (Gender-neutral)\n",
      "Emily        female          61.4%     âš ï¸ Uncertain\n",
      "James        male            90.8%     \n",
      "Pat          male            92.0%     (Gender-neutral)\n",
      "\n",
      "ğŸ’¡ Note: Some names (Alex, Taylor, Jordan) are gender-neutral,\n",
      "   so low confidence is expected and appropriate!\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Make predictions on new names\n",
    "# Let's test with names not in the training data\n",
    "\n",
    "test_names = ['Michael', 'Jessica', 'Alex', 'Taylor', 'Jordan', 'Emily', 'James', 'Pat']\n",
    "\n",
    "print(\"PREDICTIONS ON NEW NAMES\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Name':<12} {'Prediction':<12} {'Confidence':<12} {'Notes'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for name in test_names:\n",
    "    # Extract features\n",
    "    features = gender_features(name)\n",
    "    \n",
    "    # Get prediction\n",
    "    prediction = classifier.classify(features)\n",
    "    \n",
    "    # Get probability distribution\n",
    "    prob = classifier.prob_classify(features)\n",
    "    confidence = prob.prob(prediction)\n",
    "    \n",
    "    # Add notes for ambiguous names\n",
    "    notes = \"\"\n",
    "    if confidence < 0.7:\n",
    "        notes = \"âš ï¸ Uncertain\"\n",
    "    elif name in ['Alex', 'Taylor', 'Jordan', 'Pat']:\n",
    "        notes = \"(Gender-neutral)\"\n",
    "    \n",
    "    print(f\"{name:<12} {prediction:<12} {confidence:>8.1%}     {notes}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Note: Some names (Alex, Taylor, Jordan) are gender-neutral,\")\n",
    "print(\"   so low confidence is expected and appropriate!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043ee022",
   "metadata": {},
   "source": [
    "## 14.3 Document Classification: Movie Reviews\n",
    "\n",
    "Now let's tackle a more realistic task: **sentiment classification of movie reviews**.\n",
    "\n",
    "### The Dataset: NLTK Movie Reviews Corpus\n",
    "\n",
    "- **2000 movie reviews** from IMDb\n",
    "- **Labeled**: 1000 positive, 1000 negative\n",
    "- **Average length**: ~700 words per review\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "Unlike names (short, simple), movie reviews are:\n",
    "- **Long** (hundreds of words)\n",
    "- **Complex** (varied vocabulary)\n",
    "- **High-dimensional** (many possible features)\n",
    "\n",
    "### Feature Engineering for Documents\n",
    "\n",
    "For documents, we use **bag-of-words** features:\n",
    "- Each word is a potential feature\n",
    "- Feature value = whether word is present in document\n",
    "- Ignore word order (hence \"bag\")\n",
    "\n",
    "```\n",
    "\"I love this movie\" â†’ {contains(love): True, contains(hate): False, ...}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57844a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOVIE REVIEWS DATASET\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Dataset Statistics:\n",
      "   Total documents:  2000\n",
      "   Categories:       ['neg', 'pos']\n",
      "\n",
      "   Positive reviews: 1000\n",
      "   Negative reviews: 1000\n",
      "\n",
      "ğŸ“ Sample Review (neg):\n",
      "   First 15 words: ['mr', '.', 'bean', ',', 'a', 'bumbling', 'security', 'guard', 'from', 'england', 'is', 'sent', 'to', 'la', 'to']\n",
      "   Total words: 642\n",
      "\n",
      "   Raw text preview: 'mr . bean , a bumbling security guard from england is sent to la to help with the grandiose homecoming of a masterpiece american painting . the first two words...'\n"
     ]
    }
   ],
   "source": [
    "# Load and explore the movie reviews corpus\n",
    "# Each document is a list of words paired with its category\n",
    "\n",
    "documents = [\n",
    "    (list(movie_reviews.words(fileid)), category)\n",
    "    for category in movie_reviews.categories()\n",
    "    for fileid in movie_reviews.fileids(category)\n",
    "]\n",
    "\n",
    "# Shuffle to mix positive and negative reviews\n",
    "random.seed(42)\n",
    "random.shuffle(documents)\n",
    "\n",
    "print(\"MOVIE REVIEWS DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "ğŸ“Š Dataset Statistics:\n",
    "   Total documents:  {len(documents)}\n",
    "   Categories:       {movie_reviews.categories()}\n",
    "   \n",
    "   Positive reviews: {len([d for d, c in documents if c == 'pos'])}\n",
    "   Negative reviews: {len([d for d, c in documents if c == 'neg'])}\n",
    "\"\"\")\n",
    "\n",
    "# Show a sample\n",
    "sample_doc, sample_label = documents[0]\n",
    "print(f\"ğŸ“ Sample Review ({sample_label}):\")\n",
    "print(f\"   First 15 words: {sample_doc[:15]}\")\n",
    "print(f\"   Total words: {len(sample_doc)}\")\n",
    "\n",
    "# Show what reviews look like\n",
    "print(f\"\\n   Raw text preview: '{' '.join(sample_doc[:30])}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32cc816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABULARY SELECTION\n",
      "==================================================\n",
      "\n",
      "ğŸ“š Corpus Statistics:\n",
      "   Total word occurrences: 1,329,753\n",
      "   Unique words:           38,889\n",
      "\n",
      "ğŸ¯ Feature Selection:\n",
      "   Using top 2000 words as features\n",
      "\n",
      "ğŸ“Š Most Common Words:\n",
      "   [('the', 76529), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), ('is', 25195), ('in', 21822), ('s', 18513), ('it', 16107), ('that', 15924)]\n",
      "\n",
      "ğŸ’¡ Why limit features?\n",
      "   â€¢ Too many features â†’ overfitting\n",
      "   â€¢ Rare words don't help generalization\n",
      "   â€¢ Faster training and prediction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BUILD THE VOCABULARY (Feature Selection)\n",
    "# We can't use ALL words as features - too many (overfitting, slow, memory)\n",
    "# Instead, we select the most common words as our feature vocabulary\n",
    "\n",
    "# Get all words from the corpus\n",
    "all_words = [w.lower() for w in movie_reviews.words() if w.isalpha()]\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "# Use the 2000 most common words as features\n",
    "# Why 2000? Balance between coverage and efficiency\n",
    "common_words = [w for w, f in word_freq.most_common(2000)]\n",
    "\n",
    "print(\"VOCABULARY SELECTION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\"\"\n",
    "ğŸ“š Corpus Statistics:\n",
    "   Total word occurrences: {len(all_words):,}\n",
    "   Unique words:           {len(word_freq):,}\n",
    "   \n",
    "ğŸ¯ Feature Selection:\n",
    "   Using top 2000 words as features\n",
    "   \n",
    "ğŸ“Š Most Common Words:\n",
    "   {word_freq.most_common(10)}\n",
    "   \n",
    "ğŸ’¡ Why limit features?\n",
    "   â€¢ Too many features â†’ overfitting\n",
    "   â€¢ Rare words don't help generalization\n",
    "   â€¢ Faster training and prediction\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acfedc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCUMENT FEATURE EXTRACTION\n",
      "=======================================================\n",
      "\n",
      "Converting a document to a feature dictionary:\n",
      "\n",
      "Sample features (first 10 vocabulary words):\n",
      "   âœ“ contains(the): True\n",
      "   âœ“ contains(a): True\n",
      "   âœ“ contains(and): True\n",
      "   âœ“ contains(of): True\n",
      "   âœ“ contains(to): True\n",
      "   âœ“ contains(is): True\n",
      "   âœ“ contains(in): True\n",
      "   âœ“ contains(s): True\n",
      "   âœ“ contains(it): True\n",
      "   âœ“ contains(that): True\n",
      "\n",
      "ğŸ’¡ Key Points:\n",
      "   â€¢ Binary features: word present (True) or not (False)\n",
      "   â€¢ Same features for ALL documents (consistent representation)\n",
      "   â€¢ Order doesn't matter (bag-of-words assumption)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def document_features(document, word_features):\n",
    "    \"\"\"\n",
    "    Extract bag-of-words features from a document.\n",
    "    \n",
    "    For each word in our vocabulary, create a binary feature\n",
    "    indicating whether that word appears in the document.\n",
    "    \n",
    "    Args:\n",
    "        document: List of words in the document\n",
    "        word_features: List of words to use as features\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of features: {contains(word): True/False}\n",
    "    \"\"\"\n",
    "    # Convert document to set for O(1) lookup\n",
    "    document_words = set(document)\n",
    "    \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        # Feature name is descriptive: \"contains(love)\"\n",
    "        features[f'contains({word})'] = (word in document_words)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Demonstrate feature extraction\n",
    "print(\"DOCUMENT FEATURE EXTRACTION\")\n",
    "print(\"=\" * 55)\n",
    "print(\"\\nConverting a document to a feature dictionary:\")\n",
    "\n",
    "sample_features = document_features(documents[0][0], common_words[:10])\n",
    "print(\"\\nSample features (first 10 vocabulary words):\")\n",
    "for feat, value in sample_features.items():\n",
    "    marker = \"âœ“\" if value else \"âœ—\"\n",
    "    print(f\"   {marker} {feat}: {value}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "ğŸ’¡ Key Points:\n",
    "   â€¢ Binary features: word present (True) or not (False)\n",
    "   â€¢ Same features for ALL documents (consistent representation)\n",
    "   â€¢ Order doesn't matter (bag-of-words assumption)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d42e64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating feature sets for all 2000 documents...\n",
      "âœ… Feature extraction complete!\n",
      "\n",
      "TRAIN/TEST SPLIT\n",
      "=============================================\n",
      "   Training set: 1600 documents\n",
      "   Test set:     400 documents\n",
      "\n",
      "   Each document â†’ 2000 binary features\n",
      "   Total feature values: 3,200,000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create feature sets for all documents\n",
    "# This may take a moment due to the size of the data\n",
    "\n",
    "print(\"Creating feature sets for all 2000 documents...\")\n",
    "\n",
    "featuresets = [\n",
    "    (document_features(doc, common_words), category)\n",
    "    for (doc, category) in documents\n",
    "]\n",
    "\n",
    "print(\"âœ… Feature extraction complete!\")\n",
    "\n",
    "# Split into training and test sets (80/20 split)\n",
    "train_set = featuresets[:1600]  # 1600 for training\n",
    "test_set = featuresets[1600:]    # 400 for testing\n",
    "\n",
    "print(f\"\"\"\n",
    "TRAIN/TEST SPLIT\n",
    "{'=' * 45}\n",
    "   Training set: {len(train_set)} documents\n",
    "   Test set:     {len(test_set)} documents\n",
    "   \n",
    "   Each document â†’ {len(common_words)} binary features\n",
    "   Total feature values: {len(train_set) * len(common_words):,}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fc0cffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SENTIMENT CLASSIFIER\n",
      "=============================================\n",
      "Training Naive Bayes on 1600 movie reviews...\n",
      "(This may take a few seconds)\n",
      "\n",
      "âœ… Training complete!\n",
      "\n",
      "EVALUATION RESULTS\n",
      "=============================================\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚         ACCURACY: 81.5%                  â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Interpreting the result:\n",
      "â€¢ 81.5% of reviews correctly classified\n",
      "â€¢ Baseline (random): 50%\n",
      "â€¢ Our improvement: 31.5 percentage points\n",
      "\n",
      "This is a solid result for bag-of-words features!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier\n",
    "print(\"TRAINING SENTIMENT CLASSIFIER\")\n",
    "print(\"=\" * 45)\n",
    "print(\"Training Naive Bayes on 1600 movie reviews...\")\n",
    "print(\"(This may take a few seconds)\\n\")\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print(\"âœ… Training complete!\")\n",
    "\n",
    "# Evaluate on test set\n",
    "acc = accuracy(classifier, test_set)\n",
    "\n",
    "print(f\"\"\"\n",
    "EVALUATION RESULTS\n",
    "{'=' * 45}\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚         ACCURACY: {acc:.1%}                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Interpreting the result:\n",
    "â€¢ {acc*100:.1f}% of reviews correctly classified\n",
    "â€¢ Baseline (random): 50%\n",
    "â€¢ Our improvement: {(acc-0.5)*100:.1f} percentage points\n",
    "\n",
    "This is a solid result for bag-of-words features!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e7d3ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST INFORMATIVE FEATURES FOR SENTIMENT\n",
      "============================================================\n",
      "\n",
      "These are the words that best distinguish positive from negative reviews.\n",
      "The ratio shows how much more likely a word is in one class vs the other.\n",
      "\n",
      "------------------------------------------------------------\n",
      "Most Informative Features\n",
      "   contains(wonderfully) = True              pos : neg    =     10.3 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =      9.6 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =      8.5 : 1.0\n",
      "         contains(damon) = True              pos : neg    =      7.0 : 1.0\n",
      "         contains(mulan) = True              pos : neg    =      6.4 : 1.0\n",
      "         contains(awful) = True              neg : pos    =      5.8 : 1.0\n",
      "         contains(flynt) = True              pos : neg    =      5.7 : 1.0\n",
      "          contains(lame) = True              neg : pos    =      5.6 : 1.0\n",
      "    contains(ridiculous) = True              neg : pos    =      5.6 : 1.0\n",
      "        contains(poorly) = True              neg : pos    =      5.1 : 1.0\n",
      "         contains(worst) = True              neg : pos    =      5.1 : 1.0\n",
      "       contains(unfunny) = True              neg : pos    =      5.0 : 1.0\n",
      "         contains(waste) = True              neg : pos    =      4.9 : 1.0\n",
      "        contains(stupid) = True              neg : pos    =      4.8 : 1.0\n",
      "        contains(wasted) = True              neg : pos    =      4.5 : 1.0\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ’¡ Observations:\n",
      "   â€¢ \"outstanding\", \"wonderfully\" â†’ Strong positive indicators\n",
      "   â€¢ \"worst\", \"waste\", \"poorly\" â†’ Strong negative indicators\n",
      "   â€¢ The classifier learned meaningful sentiment words!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze what the classifier learned\n",
    "print(\"MOST INFORMATIVE FEATURES FOR SENTIMENT\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "These are the words that best distinguish positive from negative reviews.\n",
    "The ratio shows how much more likely a word is in one class vs the other.\n",
    "\"\"\")\n",
    "print(\"-\" * 60)\n",
    "classifier.show_most_informative_features(15)\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "ğŸ’¡ Observations:\n",
    "   â€¢ \"outstanding\", \"wonderfully\" â†’ Strong positive indicators\n",
    "   â€¢ \"worst\", \"waste\", \"poorly\" â†’ Strong negative indicators\n",
    "   â€¢ The classifier learned meaningful sentiment words!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced1ff41",
   "metadata": {},
   "source": [
    "## 14.4 Improved Feature Extraction\n",
    "\n",
    "Our basic bag-of-words approach can be improved! Common enhancements:\n",
    "\n",
    "### Feature Engineering Techniques\n",
    "\n",
    "| Technique | Description | Benefit |\n",
    "|-----------|-------------|---------|\n",
    "| **Remove stopwords** | Filter out common words (the, is, a) | Reduce noise |\n",
    "| **Add metadata features** | Document length, punctuation counts | Capture style |\n",
    "| **Bigrams** | Word pairs (\"not good\") | Capture negation |\n",
    "| **TF-IDF weighting** | Weight rare words higher | Better discrimination |\n",
    "\n",
    "### Stopwords\n",
    "\n",
    "**Stopwords** are common words that usually don't carry sentiment meaning:\n",
    "- Articles: \"the\", \"a\", \"an\"\n",
    "- Prepositions: \"in\", \"on\", \"at\"\n",
    "- Pronouns: \"it\", \"they\", \"we\"\n",
    "\n",
    "Removing them:\n",
    "- Reduces feature space\n",
    "- Focuses on content words\n",
    "- Often improves accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09120e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stopwords: 198\n",
      "Examples: ['because', 'y', 'hers', 'his', 'mightn', 'aren', 'their', 'in', 'o', 's']\n",
      "\n",
      "âœ… Improved feature extractor defined!\n",
      "\n",
      "Improvements:\n",
      "â€¢ Stopwords excluded from vocabulary\n",
      "â€¢ Added metadata: length, punctuation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(f\"Number of stopwords: {len(stop_words)}\")\n",
    "print(f\"Examples: {list(stop_words)[:10]}\")\n",
    "\n",
    "def improved_features(document, word_features):\n",
    "    \"\"\"\n",
    "    Extract improved features with stopword filtering and metadata.\n",
    "    \n",
    "    Improvements over basic bag-of-words:\n",
    "    1. Exclude stopwords from word features\n",
    "    2. Add document-level metadata features\n",
    "    \n",
    "    Args:\n",
    "        document: List of words\n",
    "        word_features: Vocabulary list\n",
    "    \n",
    "    Returns:\n",
    "        Feature dictionary\n",
    "    \"\"\"\n",
    "    # Normalize words (lowercase, alphabetic only)\n",
    "    document_words = set(w.lower() for w in document if w.isalpha())\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Word presence features (excluding stopwords)\n",
    "    for word in word_features:\n",
    "        if word not in stop_words:\n",
    "            features[f'contains({word})'] = (word in document_words)\n",
    "    \n",
    "    # METADATA FEATURES - capture document characteristics\n",
    "    features['doc_length_long'] = len(document) > 500  # Long review?\n",
    "    features['has_exclamation'] = '!' in ' '.join(document)  # Excitement?\n",
    "    features['has_question'] = '?' in ' '.join(document)  # Questioning?\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"\\nâœ… Improved feature extractor defined!\")\n",
    "print(\"\"\"\n",
    "Improvements:\n",
    "â€¢ Stopwords excluded from vocabulary\n",
    "â€¢ Added metadata: length, punctuation\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b293f946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED VOCABULARY\n",
      "==================================================\n",
      "Original vocabulary: 2000 words\n",
      "After removing stopwords: 1500 words\n",
      "Reduction: 500 words removed\n",
      "\n",
      "Creating improved feature sets...\n",
      "âœ… Improved feature sets ready!\n"
     ]
    }
   ],
   "source": [
    "# Create filtered vocabulary (no stopwords)\n",
    "filtered_words = [w for w in common_words if w not in stop_words][:1500]\n",
    "\n",
    "print(\"IMPROVED VOCABULARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Original vocabulary: {len(common_words)} words\")\n",
    "print(f\"After removing stopwords: {len(filtered_words)} words\")\n",
    "print(f\"Reduction: {len(common_words) - len(filtered_words)} words removed\")\n",
    "\n",
    "# Create new feature sets with improved features\n",
    "print(\"\\nCreating improved feature sets...\")\n",
    "featuresets_improved = [\n",
    "    (improved_features(doc, filtered_words), category)\n",
    "    for (doc, category) in documents\n",
    "]\n",
    "\n",
    "train_improved = featuresets_improved[:1600]\n",
    "test_improved = featuresets_improved[1600:]\n",
    "\n",
    "print(\"âœ… Improved feature sets ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fad289fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING IMPROVED CLASSIFIER\n",
      "==================================================\n",
      "\n",
      "COMPARISON: Original vs Improved\n",
      "==================================================\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚  Original Accuracy:  81.5%                     â”‚\n",
      "â”‚  Improved Accuracy:  79.8%                     â”‚\n",
      "â”‚  Change:             -1.7 percentage points     â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "ğŸ’¡ Feature engineering can significantly impact performance!\n",
      "   Even simple improvements like removing stopwords help.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train improved classifier\n",
    "print(\"TRAINING IMPROVED CLASSIFIER\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "classifier_improved = NaiveBayesClassifier.train(train_improved)\n",
    "acc_improved = accuracy(classifier_improved, test_improved)\n",
    "\n",
    "print(f\"\"\"\n",
    "COMPARISON: Original vs Improved\n",
    "{'=' * 50}\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Original Accuracy:  {acc:.1%}                     â”‚\n",
    "â”‚  Improved Accuracy:  {acc_improved:.1%}                     â”‚\n",
    "â”‚  Change:             {(acc_improved-acc)*100:+.1f} percentage points     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "ğŸ’¡ Feature engineering can significantly impact performance!\n",
    "   Even simple improvements like removing stopwords help.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4166ef39",
   "metadata": {},
   "source": [
    "## 14.5 Cross-Validation\n",
    "\n",
    "### The Problem with Simple Train/Test Split\n",
    "\n",
    "A single 80/20 split has issues:\n",
    "- Results depend on which examples end up in test set\n",
    "- High variance in accuracy estimates\n",
    "- Might get \"lucky\" or \"unlucky\" split\n",
    "\n",
    "### K-Fold Cross-Validation\n",
    "\n",
    "**Cross-validation** provides more reliable estimates by:\n",
    "1. Splitting data into K equal \"folds\"\n",
    "2. Using each fold once as test set, rest as training\n",
    "3. Averaging results across all K experiments\n",
    "\n",
    "```\n",
    "Fold 1: [TEST] [Train] [Train] [Train] [Train]\n",
    "Fold 2: [Train] [TEST] [Train] [Train] [Train]\n",
    "Fold 3: [Train] [Train] [TEST] [Train] [Train]\n",
    "Fold 4: [Train] [Train] [Train] [TEST] [Train]\n",
    "Fold 5: [Train] [Train] [Train] [Train] [TEST]\n",
    "```\n",
    "\n",
    "### Benefits\n",
    "\n",
    "âœ… Uses all data for both training and testing  \n",
    "âœ… More stable accuracy estimates  \n",
    "âœ… Better estimate of real-world performance  \n",
    "âœ… Standard practice in machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "160a3243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(featuresets, num_folds=5):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross validation.\n",
    "    \n",
    "    Process:\n",
    "    1. Split data into num_folds equal parts\n",
    "    2. For each fold:\n",
    "       - Use that fold as test set\n",
    "       - Use remaining folds as training set\n",
    "       - Train classifier and measure accuracy\n",
    "    3. Return average accuracy across all folds\n",
    "    \n",
    "    Args:\n",
    "        featuresets: List of (features, label) tuples\n",
    "        num_folds: Number of folds (default 5)\n",
    "    \n",
    "    Returns:\n",
    "        Average accuracy and list of fold accuracies\n",
    "    \"\"\"\n",
    "    fold_size = len(featuresets) // num_folds\n",
    "    accuracies = []\n",
    "    \n",
    "    print(f\"Performing {num_folds}-fold cross-validation...\")\n",
    "    print(f\"Each fold: {fold_size} examples\\n\")\n",
    "    \n",
    "    for i in range(num_folds):\n",
    "        # Define test fold boundaries\n",
    "        test_start = i * fold_size\n",
    "        test_end = test_start + fold_size\n",
    "        \n",
    "        # Split data\n",
    "        test_fold = featuresets[test_start:test_end]\n",
    "        train_fold = featuresets[:test_start] + featuresets[test_end:]\n",
    "        \n",
    "        # Train and evaluate\n",
    "        classifier = NaiveBayesClassifier.train(train_fold)\n",
    "        acc = accuracy(classifier, test_fold)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        print(f\"Fold {i+1}: {acc:.2%} (trained on {len(train_fold)}, tested on {len(test_fold)})\")\n",
    "    \n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    return avg_accuracy, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7a0a2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-FOLD CROSS-VALIDATION RESULTS\n",
      "=======================================================\n",
      "Performing 5-fold cross-validation...\n",
      "Each fold: 400 examples\n",
      "\n",
      "Fold 1: 78.00% (trained on 1600, tested on 400)\n",
      "Fold 2: 78.25% (trained on 1600, tested on 400)\n",
      "Fold 3: 80.50% (trained on 1600, tested on 400)\n",
      "Fold 4: 81.00% (trained on 1600, tested on 400)\n",
      "Fold 5: 79.75% (trained on 1600, tested on 400)\n",
      "\n",
      "=======================================================\n",
      "SUMMARY\n",
      "=======================================================\n",
      "   Individual fold accuracies: ['78.00%', '78.25%', '80.50%', '81.00%', '79.75%']\n",
      "\n",
      "   Average Accuracy: 79.50%\n",
      "   Std Deviation:    1.19%\n",
      "\n",
      "ğŸ’¡ Cross-validation gives us confidence that our 79.5% \n",
      "   accuracy is a reliable estimate, not just luck!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run cross-validation on improved features\n",
    "print(\"5-FOLD CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "avg_acc, fold_accs = cross_validate(featuresets_improved, num_folds=5)\n",
    "\n",
    "print(f\"\"\"\n",
    "{'=' * 55}\n",
    "SUMMARY\n",
    "{'=' * 55}\n",
    "   Individual fold accuracies: {[f'{a:.2%}' for a in fold_accs]}\n",
    "   \n",
    "   Average Accuracy: {avg_acc:.2%}\n",
    "   Std Deviation:    {(sum((a-avg_acc)**2 for a in fold_accs)/len(fold_accs))**0.5:.2%}\n",
    "   \n",
    "ğŸ’¡ Cross-validation gives us confidence that our {avg_acc:.1%} \n",
    "   accuracy is a reliable estimate, not just luck!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff9c3c1",
   "metadata": {},
   "source": [
    "## 14.6 Confusion Matrix and Evaluation Metrics\n",
    "\n",
    "### Beyond Accuracy\n",
    "\n",
    "Accuracy alone can be misleading. Consider:\n",
    "- 95% accuracy on spam detection sounds great...\n",
    "- But if 95% of emails are NOT spam, predicting \"not spam\" always gives 95% accuracy!\n",
    "\n",
    "### Confusion Matrix\n",
    "\n",
    "A **confusion matrix** shows the detailed breakdown of predictions:\n",
    "\n",
    "```\n",
    "                    Predicted\n",
    "                 Neg      Pos\n",
    "Actual  Neg   [  TN   |   FP  ]    TN = True Negative\n",
    "        Pos   [  FN   |   TP  ]    FP = False Positive\n",
    "                                   FN = False Negative\n",
    "                                   TP = True Positive\n",
    "```\n",
    "\n",
    "### Key Metrics\n",
    "\n",
    "| Metric | Formula | What it Measures |\n",
    "|--------|---------|------------------|\n",
    "| **Precision** | TP / (TP + FP) | Of predicted positives, how many are correct? |\n",
    "| **Recall** | TP / (TP + FN) | Of actual positives, how many did we find? |\n",
    "| **F1 Score** | 2 Ã— (P Ã— R) / (P + R) | Harmonic mean of precision and recall |\n",
    "\n",
    "### When to Use What?\n",
    "\n",
    "- **Spam filter**: High precision (don't mark good emails as spam!)\n",
    "- **Disease diagnosis**: High recall (don't miss sick patients!)\n",
    "- **Balanced tasks**: F1 score (balance both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "725fb5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evaluation function defined!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_classifier(classifier, test_set):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive evaluation metrics.\n",
    "    \n",
    "    Computes:\n",
    "    - Confusion matrix\n",
    "    - Precision, Recall, F1 for each class\n",
    "    \n",
    "    Args:\n",
    "        classifier: Trained classifier\n",
    "        test_set: List of (features, label) tuples\n",
    "    \n",
    "    Returns:\n",
    "        confusion: Confusion matrix as nested dict\n",
    "        metrics: Precision, recall, F1 for each class\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    predictions = [classifier.classify(features) for features, label in test_set]\n",
    "    actual = [label for features, label in test_set]\n",
    "    \n",
    "    # Build confusion matrix\n",
    "    labels = list(set(actual))\n",
    "    confusion = {true_label: {pred_label: 0 for pred_label in labels} \n",
    "                 for true_label in labels}\n",
    "    \n",
    "    for true, pred in zip(actual, predictions):\n",
    "        confusion[true][pred] += 1\n",
    "    \n",
    "    # Calculate metrics for each class\n",
    "    metrics = {}\n",
    "    for label in labels:\n",
    "        # True Positives: predicted label correctly\n",
    "        tp = confusion[label][label]\n",
    "        \n",
    "        # False Positives: predicted label but was wrong\n",
    "        fp = sum(confusion[other][label] for other in labels if other != label)\n",
    "        \n",
    "        # False Negatives: should have predicted label but didn't\n",
    "        fn = sum(confusion[label][other] for other in labels if other != label)\n",
    "        \n",
    "        # Calculate metrics (handle division by zero)\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        metrics[label] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'support': tp + fn  # Total actual examples of this class\n",
    "        }\n",
    "    \n",
    "    return confusion, metrics\n",
    "\n",
    "print(\"âœ… Evaluation function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89a9209c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETAILED EVALUATION RESULTS\n",
      "=======================================================\n",
      "\n",
      "CONFUSION MATRIX\n",
      "(Rows = Actual, Columns = Predicted)\n",
      "\n",
      "                Predicted                \n",
      "Actual          neg          pos         \n",
      "----------------------------------------\n",
      "neg            169         29          \n",
      "pos            52          150         \n",
      "\n",
      "\n",
      "INTERPRETING THE MATRIX:\n",
      "â€¢ Diagonal (negâ†’neg, posâ†’pos): Correct predictions âœ“\n",
      "â€¢ Off-diagonal: Errors âœ—\n",
      "  - negâ†’pos: Negative reviews predicted as positive (False Positive)\n",
      "  - posâ†’neg: Positive reviews predicted as negative (False Negative)\n",
      "\n",
      "\n",
      "PER-CLASS METRICS\n",
      "-------------------------------------------------------\n",
      "Class      Precision    Recall       F1         Support\n",
      "-------------------------------------------------------\n",
      "neg        76.47%       85.35%       80.67%     198\n",
      "pos        83.80%       74.26%       78.74%     202\n",
      "-------------------------------------------------------\n",
      "Macro Avg  80.13%       79.81%       79.70%    \n"
     ]
    }
   ],
   "source": [
    "# Evaluate classifier with detailed metrics\n",
    "confusion, metrics = evaluate_classifier(classifier_improved, test_improved)\n",
    "\n",
    "print(\"DETAILED EVALUATION RESULTS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "print(\"\"\"\n",
    "CONFUSION MATRIX\n",
    "(Rows = Actual, Columns = Predicted)\n",
    "\"\"\")\n",
    "print(f\"{'':>15} {'Predicted':<25}\")\n",
    "print(f\"{'Actual':<15} {'neg':<12} {'pos':<12}\")\n",
    "print(\"-\" * 40)\n",
    "for true_label in ['neg', 'pos']:\n",
    "    print(f\"{true_label:<15}\", end='')\n",
    "    for pred_label in ['neg', 'pos']:\n",
    "        count = confusion[true_label][pred_label]\n",
    "        print(f\"{count:<12}\", end='')\n",
    "    print()\n",
    "\n",
    "print(f\"\"\"\n",
    "\n",
    "INTERPRETING THE MATRIX:\n",
    "â€¢ Diagonal (negâ†’neg, posâ†’pos): Correct predictions âœ“\n",
    "â€¢ Off-diagonal: Errors âœ—\n",
    "  - negâ†’pos: Negative reviews predicted as positive (False Positive)\n",
    "  - posâ†’neg: Positive reviews predicted as negative (False Negative)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nPER-CLASS METRICS\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'Class':<10} {'Precision':<12} {'Recall':<12} {'F1':<10} {'Support'}\")\n",
    "print(\"-\" * 55)\n",
    "for label in ['neg', 'pos']:\n",
    "    m = metrics[label]\n",
    "    print(f\"{label:<10} {m['precision']:<12.2%} {m['recall']:<12.2%} {m['f1']:<10.2%} {m['support']}\")\n",
    "\n",
    "# Calculate macro averages\n",
    "macro_precision = sum(m['precision'] for m in metrics.values()) / len(metrics)\n",
    "macro_recall = sum(m['recall'] for m in metrics.values()) / len(metrics)\n",
    "macro_f1 = sum(m['f1'] for m in metrics.values()) / len(metrics)\n",
    "\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'Macro Avg':<10} {macro_precision:<12.2%} {macro_recall:<12.2%} {macro_f1:<10.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb8929",
   "metadata": {},
   "source": [
    "## 14.7 Complete Text Classifier Class\n",
    "\n",
    "Let's wrap everything we've learned into a reusable, production-ready class.\n",
    "\n",
    "### Design Goals\n",
    "\n",
    "1. **Easy to use** - Simple train/predict interface\n",
    "2. **Flexible** - Works with raw text or tokenized documents\n",
    "3. **Configurable** - Adjustable number of features\n",
    "4. **Informative** - Provides probability estimates and feature analysis\n",
    "\n",
    "### Class Structure\n",
    "\n",
    "```python\n",
    "TextClassifier\n",
    "â”œâ”€â”€ __init__(num_features)      # Initialize\n",
    "â”œâ”€â”€ train(documents, labels)    # Train the model\n",
    "â”œâ”€â”€ predict(document)           # Classify new text\n",
    "â”œâ”€â”€ predict_proba(document)     # Get probabilities\n",
    "â”œâ”€â”€ evaluate(documents, labels) # Test accuracy\n",
    "â””â”€â”€ show_features(n)            # Show top features\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73f6c4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TextClassifier class defined!\n"
     ]
    }
   ],
   "source": [
    "class TextClassifier:\n",
    "    \"\"\"\n",
    "    A complete, reusable text classification pipeline.\n",
    "    \n",
    "    This class encapsulates the entire text classification workflow:\n",
    "    1. Vocabulary building\n",
    "    2. Feature extraction\n",
    "    3. Model training\n",
    "    4. Prediction and evaluation\n",
    "    \n",
    "    Example:\n",
    "        clf = TextClassifier(num_features=1500)\n",
    "        clf.train(train_docs, train_labels)\n",
    "        prediction = clf.predict(\"This movie is great!\")\n",
    "        accuracy = clf.evaluate(test_docs, test_labels)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_features=1500):\n",
    "        \"\"\"\n",
    "        Initialize the classifier.\n",
    "        \n",
    "        Args:\n",
    "            num_features: Number of top words to use as features (default 1500)\n",
    "        \"\"\"\n",
    "        self.num_features = num_features\n",
    "        self.word_features = None  # Will be set during training\n",
    "        self.classifier = None     # Will be set during training\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        print(f\"TextClassifier initialized (max {num_features} features)\")\n",
    "    \n",
    "    def extract_features(self, document):\n",
    "        \"\"\"\n",
    "        Extract features from a single document.\n",
    "        \n",
    "        Handles both raw text (string) and tokenized documents (list).\n",
    "        \n",
    "        Args:\n",
    "            document: String or list of tokens\n",
    "        \n",
    "        Returns:\n",
    "            Feature dictionary\n",
    "        \"\"\"\n",
    "        # Handle raw text input\n",
    "        if isinstance(document, str):\n",
    "            document = word_tokenize(document.lower())\n",
    "        \n",
    "        # Create set of document words for fast lookup\n",
    "        doc_words = set(w.lower() for w in document if w.isalpha())\n",
    "        \n",
    "        # Build feature dictionary\n",
    "        features = {}\n",
    "        for word in self.word_features:\n",
    "            features[f'contains({word})'] = (word in doc_words)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def train(self, documents, labels):\n",
    "        \"\"\"\n",
    "        Train the classifier on labeled documents.\n",
    "        \n",
    "        Steps:\n",
    "        1. Build vocabulary from all documents\n",
    "        2. Extract features from each document\n",
    "        3. Train Naive Bayes classifier\n",
    "        \n",
    "        Args:\n",
    "            documents: List of documents (strings or token lists)\n",
    "            labels: List of labels (same length as documents)\n",
    "        \n",
    "        Returns:\n",
    "            self (for method chaining)\n",
    "        \"\"\"\n",
    "        print(f\"Training on {len(documents)} documents...\")\n",
    "        \n",
    "        # Step 1: Build vocabulary\n",
    "        all_words = []\n",
    "        for doc in documents:\n",
    "            if isinstance(doc, str):\n",
    "                doc = word_tokenize(doc.lower())\n",
    "            # Only keep alphabetic words, exclude stopwords\n",
    "            all_words.extend([w.lower() for w in doc \n",
    "                            if w.isalpha() and w.lower() not in self.stop_words])\n",
    "        \n",
    "        # Select top N words by frequency\n",
    "        word_freq = Counter(all_words)\n",
    "        self.word_features = [w for w, f in word_freq.most_common(self.num_features)]\n",
    "        print(f\"Vocabulary: {len(self.word_features)} words\")\n",
    "        \n",
    "        # Step 2: Create feature sets\n",
    "        featuresets = [\n",
    "            (self.extract_features(doc), label)\n",
    "            for doc, label in zip(documents, labels)\n",
    "        ]\n",
    "        \n",
    "        # Step 3: Train classifier\n",
    "        self.classifier = NaiveBayesClassifier.train(featuresets)\n",
    "        print(\"âœ… Training complete!\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, document):\n",
    "        \"\"\"\n",
    "        Predict the class for a document.\n",
    "        \n",
    "        Args:\n",
    "            document: Text to classify (string or token list)\n",
    "        \n",
    "        Returns:\n",
    "            Predicted class label\n",
    "        \"\"\"\n",
    "        features = self.extract_features(document)\n",
    "        return self.classifier.classify(features)\n",
    "    \n",
    "    def predict_proba(self, document):\n",
    "        \"\"\"\n",
    "        Get probability distribution over classes.\n",
    "        \n",
    "        Args:\n",
    "            document: Text to classify\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary {class: probability}\n",
    "        \"\"\"\n",
    "        features = self.extract_features(document)\n",
    "        prob_dist = self.classifier.prob_classify(features)\n",
    "        return {label: prob_dist.prob(label) for label in prob_dist.samples()}\n",
    "    \n",
    "    def evaluate(self, documents, labels):\n",
    "        \"\"\"\n",
    "        Evaluate accuracy on test data.\n",
    "        \n",
    "        Args:\n",
    "            documents: Test documents\n",
    "            labels: True labels\n",
    "        \n",
    "        Returns:\n",
    "            Accuracy score (0 to 1)\n",
    "        \"\"\"\n",
    "        featuresets = [\n",
    "            (self.extract_features(doc), label)\n",
    "            for doc, label in zip(documents, labels)\n",
    "        ]\n",
    "        return accuracy(self.classifier, featuresets)\n",
    "    \n",
    "    def show_features(self, n=10):\n",
    "        \"\"\"\n",
    "        Display the most informative features.\n",
    "        \n",
    "        Args:\n",
    "            n: Number of features to show\n",
    "        \"\"\"\n",
    "        print(f\"\\nTop {n} Most Informative Features:\")\n",
    "        print(\"-\" * 50)\n",
    "        self.classifier.show_most_informative_features(n)\n",
    "\n",
    "print(\"âœ… TextClassifier class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb0cfe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXTCLASSIFIER DEMONSTRATION\n",
      "=======================================================\n",
      "TextClassifier initialized (max 1500 features)\n",
      "Training on 1600 documents...\n",
      "Vocabulary: 1500 words\n",
      "âœ… Training complete!\n",
      "\n",
      "ğŸ“Š Test Accuracy: 79.75%\n",
      "\n",
      "Top 10 Most Informative Features:\n",
      "--------------------------------------------------\n",
      "Most Informative Features\n",
      "         contains(mulan) = True              pos : neg    =      7.0 : 1.0\n",
      "   contains(wonderfully) = True              pos : neg    =      6.6 : 1.0\n",
      "          contains(lame) = True              neg : pos    =      6.5 : 1.0\n",
      "    contains(ridiculous) = True              neg : pos    =      5.8 : 1.0\n",
      "         contains(awful) = True              neg : pos    =      5.6 : 1.0\n",
      "        contains(wasted) = True              neg : pos    =      5.3 : 1.0\n",
      "           contains(era) = True              pos : neg    =      5.1 : 1.0\n",
      "        contains(poorly) = True              neg : pos    =      4.8 : 1.0\n",
      "         contains(worst) = True              neg : pos    =      4.3 : 1.0\n",
      "         contains(bland) = True              neg : pos    =      4.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# DEMONSTRATION: Using the TextClassifier class\n",
    "\n",
    "# Prepare data\n",
    "docs = [list(movie_reviews.words(fid)) for fid in movie_reviews.fileids()]\n",
    "labels = [movie_reviews.categories(fid)[0] for fid in movie_reviews.fileids()]\n",
    "\n",
    "# Shuffle\n",
    "combined = list(zip(docs, labels))\n",
    "random.shuffle(combined)\n",
    "docs, labels = zip(*combined)\n",
    "\n",
    "# Split\n",
    "train_docs, test_docs = docs[:1600], docs[1600:]\n",
    "train_labels, test_labels = labels[:1600], labels[1600:]\n",
    "\n",
    "print(\"TEXTCLASSIFIER DEMONSTRATION\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Create and train classifier\n",
    "clf = TextClassifier(num_features=1500)\n",
    "clf.train(train_docs, train_labels)\n",
    "\n",
    "# Evaluate\n",
    "acc = clf.evaluate(test_docs, test_labels)\n",
    "print(f\"\\nğŸ“Š Test Accuracy: {acc:.2%}\")\n",
    "\n",
    "# Show what it learned\n",
    "clf.show_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4c8bb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PREDICTIONS ON NEW REVIEWS\n",
      "=================================================================\n",
      "\n",
      "ğŸ“ Review 1: \"This movie was absolutely fantastic! Great acting ...\"\n",
      "   ğŸ˜ Prediction: NEG\n",
      "   ğŸ“Š Confidence: pos=0.0%, neg=100.0%\n",
      "   ğŸ’¡ High confidence\n",
      "\n",
      "ğŸ“ Review 2: \"Terrible film. Complete waste of time and money. V...\"\n",
      "   ğŸ˜ Prediction: NEG\n",
      "   ğŸ“Š Confidence: pos=0.0%, neg=100.0%\n",
      "   ğŸ’¡ High confidence\n",
      "\n",
      "ğŸ“ Review 3: \"It was okay. Not great, not terrible. Just an aver...\"\n",
      "   ğŸ˜ Prediction: NEG\n",
      "   ğŸ“Š Confidence: pos=0.0%, neg=100.0%\n",
      "   ğŸ’¡ High confidence\n",
      "\n",
      "=================================================================\n",
      "âœ… The classifier successfully generalizes to new, unseen reviews!\n"
     ]
    }
   ],
   "source": [
    "# Test with completely new reviews (not from the corpus)\n",
    "test_reviews = [\n",
    "    \"This movie was absolutely fantastic! Great acting and storyline. A masterpiece!\",\n",
    "    \"Terrible film. Complete waste of time and money. Very disappointing experience.\",\n",
    "    \"It was okay. Not great, not terrible. Just an average movie overall.\",\n",
    "]\n",
    "\n",
    "print(\"\\nPREDICTIONS ON NEW REVIEWS\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "for i, review in enumerate(test_reviews, 1):\n",
    "    prediction = clf.predict(review)\n",
    "    probs = clf.predict_proba(review)\n",
    "    \n",
    "    # Determine confidence\n",
    "    confidence = max(probs.values())\n",
    "    emoji = \"ğŸ˜Š\" if prediction == 'pos' else \"ğŸ˜\"\n",
    "    \n",
    "    print(f\"\\nğŸ“ Review {i}: \\\"{review[:50]}...\\\"\")\n",
    "    print(f\"   {emoji} Prediction: {prediction.upper()}\")\n",
    "    print(f\"   ğŸ“Š Confidence: pos={probs['pos']:.1%}, neg={probs['neg']:.1%}\")\n",
    "    \n",
    "    # Interpretation\n",
    "    if confidence > 0.8:\n",
    "        certainty = \"High confidence\"\n",
    "    elif confidence > 0.6:\n",
    "        certainty = \"Moderate confidence\"\n",
    "    else:\n",
    "        certainty = \"Low confidence (ambiguous)\"\n",
    "    print(f\"   ğŸ’¡ {certainty}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"âœ… The classifier successfully generalizes to new, unseen reviews!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25bd013",
   "metadata": {},
   "source": [
    "## Summary & Quick Reference\n",
    "\n",
    "### Text Classification Pipeline\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  1. Collect  â”‚ â†’  â”‚  2. Extract  â”‚ â†’  â”‚  3. Train    â”‚ â†’  â”‚  4. Predict  â”‚\n",
    "â”‚  Labeled     â”‚    â”‚  Features    â”‚    â”‚  Classifier  â”‚    â”‚  New Data    â”‚\n",
    "â”‚  Data        â”‚    â”‚              â”‚    â”‚              â”‚    â”‚              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Key NLTK Functions\n",
    "\n",
    "| Function | Purpose | Example |\n",
    "|----------|---------|---------|\n",
    "| `NaiveBayesClassifier.train()` | Train classifier | `clf = NaiveBayesClassifier.train(train_set)` |\n",
    "| `classifier.classify()` | Predict single example | `label = clf.classify(features)` |\n",
    "| `classifier.prob_classify()` | Get probabilities | `probs = clf.prob_classify(features)` |\n",
    "| `accuracy()` | Evaluate performance | `acc = accuracy(clf, test_set)` |\n",
    "| `show_most_informative_features()` | Inspect learning | `clf.show_most_informative_features(10)` |\n",
    "\n",
    "### Feature Set Format\n",
    "\n",
    "```python\n",
    "featuresets = [\n",
    "    ({'feature1': value1, 'feature2': value2}, 'label1'),\n",
    "    ({'feature1': value3, 'feature2': value4}, 'label2'),\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "### Evaluation Metrics Cheat Sheet\n",
    "\n",
    "| Metric | Formula | Use When |\n",
    "|--------|---------|----------|\n",
    "| **Accuracy** | Correct / Total | Balanced classes |\n",
    "| **Precision** | TP / (TP + FP) | Cost of false positives high |\n",
    "| **Recall** | TP / (TP + FN) | Cost of false negatives high |\n",
    "| **F1** | 2Â·PÂ·R / (P+R) | Balance P and R |\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Always shuffle data** before splitting\n",
    "2. **Use cross-validation** for reliable estimates\n",
    "3. **Start simple**, then add complexity\n",
    "4. **Analyze errors** to improve features\n",
    "5. **Remove stopwords** for cleaner features\n",
    "6. **Don't test on training data!**\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore other classifiers (Decision Trees, SVM, etc.)\n",
    "- Try different feature engineering techniques\n",
    "- Build a real application (spam filter, review analyzer)\n",
    "- Section 15: Corpus Management for handling large datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
